{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "non_function_version_gmm_em_expressions_cell_sizes",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOXfam4j9VF0yJjuugay3km",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camlab-bioml/2021_IMC_Jett/blob/main/non_function_version_gmm_em_expressions_cell_sizes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le7qDLI9FM6G"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.distributions as D\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.datasets as datasets"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SahaX89nFlkZ",
        "outputId": "1dfeb3e1-728e-4572-fc4a-792f89d39a10"
      },
      "source": [
        "## create data\n",
        "\n",
        "n_clusters = 3\n",
        "n_features = 2\n",
        "\n",
        "## ground true expressions ##\n",
        "true_expression_means = torch.tensor([\n",
        "    [1, 2],\n",
        "    [4, 3],\n",
        "    [7, 9]\n",
        "])\n",
        "\n",
        "true_expression_covs = torch.tensor([\n",
        "    [[.1, 0], [0, .1]],\n",
        "    [[.1, 0], [0, .1]],\n",
        "    [[.1, 0], [0, .1]]\n",
        "])\n",
        "\n",
        "true_size_means = torch.tensor([.4, .5, .6])\n",
        "\n",
        "print(true_size_means)\n",
        "\n",
        "true_size_stds = torch.tensor([.1, .05, .01])\n",
        "true_size_stds\n",
        "\n",
        "## other ground true for generating data ##\n",
        "d_ws = torch.tensor([.95, .05])\n",
        "z_ws = torch.tensor([1 / 4, 1 / 2, 1 / 4])\n",
        "g_ws = torch.tensor([0.0667, 0.1333, 0.2000, 0.1000, 0.2667, 0.2333])\n",
        "\n",
        "N = 10000\n",
        "gs = np.sum(np.random.choice(len(d_ws), size = N, p = d_ws))\n",
        "zs = N - gs\n",
        "\n",
        "## simulate data\n",
        "x = np.zeros((zs, n_features+4))\n",
        "for i in range(zs):\n",
        "  z = np.random.choice(n_clusters, size = 1, p = z_ws)[0]\n",
        "  x[i] = np.append(np.random.multivariate_normal(true_expression_means[z], true_expression_covs[z]), [np.random.normal(true_size_means[z], true_size_stds[z]), 0, z, z+6])\n",
        "  \n",
        "xxx = np.zeros((gs, n_features+4))\n",
        "for i in range(gs):\n",
        "\n",
        "  g = np.random.choice(6, size = 1, p = g_ws)[0]\n",
        "    \n",
        "  if g == 0:\n",
        "    idx = [0,0]\n",
        "  elif g == 1:\n",
        "    idx = [0,1]\n",
        "  elif g == 2:\n",
        "    idx = [0,2]\n",
        "  elif g == 3:\n",
        "    idx = [1,1]\n",
        "  elif g == 4:\n",
        "    idx = [1,2]\n",
        "  else:\n",
        "    idx = [2,2]\n",
        "  \n",
        "  xxx[i] = np.append(np.random.multivariate_normal( (true_expression_means[idx[0]] + true_expression_means[idx[1]]), (true_expression_covs[idx[0]] + true_expression_covs[idx[1]]) ),\n",
        "                     [np.random.normal( (true_size_means[idx[0]] + true_size_means[idx[1]]), (true_size_stds[idx[0]] + true_size_stds[idx[1]]) ), 1, g, g])\n",
        "  \n",
        "xx = np.append(x, xxx).reshape(N,6)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.4000, 0.5000, 0.6000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgXMyC6UFqiB"
      },
      "source": [
        "## initialization\n",
        "\n",
        "n_obs = N\n",
        "n_features = 2\n",
        "n_clusters = 3\n",
        "\n",
        "#torch.manual_seed(42)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "emu_c = torch.tensor([\n",
        "    [3, 1], # 1 2\n",
        "    [5, 4], # 4 3\n",
        "    [8, 7]\n",
        "]) #, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "smu_c = torch.tensor([.45, .55, .65]) #, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "eco_c = 0.1 * torch.eye(n_features).tile(n_clusters, 1, 1)\n",
        "sco_c = 0.1 * torch.ones(n_clusters, dtype=torch.float)\n",
        "\n",
        "smu_cc = torch.zeros(n_clusters, n_clusters)\n",
        "sco_cc = torch.zeros(n_clusters, n_clusters)\n",
        "\n",
        "emu_cc = torch.zeros(n_clusters, n_clusters, n_features)\n",
        "eco_cc = torch.zeros(n_clusters, n_clusters, n_features, n_features)\n",
        "\n",
        "for j in range(n_clusters):\n",
        "  for k in range(n_clusters):\n",
        "    smu_cc[j,k] = smu_c[j] + smu_c[k]\n",
        "    sco_cc[j,k] = sco_c[j] + sco_c[k]\n",
        "\n",
        "    emu_cc[j,k] = (emu_c[j] + emu_c[k])\n",
        "    eco_cc[j,k] = (eco_c[j] + eco_c[k])\n",
        "\n",
        "#smu_c = torch.tensor(smu_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "#sco_c = torch.tensor(sco_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "#emu_c = torch.tensor(emu_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "#eco_c = torch.tensor(eco_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "#smu_cc = torch.tensor(smu_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "#sco_cc = torch.tensor(sco_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "#emu_cc = torch.tensor(emu_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "#eco_cc = torch.tensor(eco_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "####\n",
        "\n",
        "pi_d0 = torch.tensor(0.9)\n",
        "\n",
        "pi_c = torch.empty(n_clusters).fill_(1. / (n_clusters))\n",
        "\n",
        "pi_cc = torch.triu(torch.ones(n_clusters, n_clusters))\n",
        "pi_cc = pi_cc / torch.sum(pi_cc)\n",
        "pi_cc[pi_cc == 0] = float('NaN')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eAowDrqCJqP"
      },
      "source": [
        "## helper function\n",
        "def _estimate_mean_cov_t1v2(X, S, r_ij, reg=1e-6):\n",
        "\n",
        "  #n, p = X.shape\n",
        "  #n, c = r_ij.shape\n",
        "\n",
        "  smut = torch.zeros(n_clusters)\n",
        "  scot = torch.zeros(n_clusters)\n",
        "\n",
        "  emut = torch.zeros(n_clusters, n_features)\n",
        "  ecot = torch.zeros(n_clusters, n_features, n_features)\n",
        "\n",
        "  n_c = torch.sum(r_ij, dim=0) + reg # (c)\n",
        "\n",
        "  for j in range(n_clusters):\n",
        "    e_n = torch.round(n_c[j])\n",
        "    idx = r_ij[:,j].argsort()[-e_n.int():]\n",
        "    smut[j] = torch.mean(S[idx], 0)\n",
        "    emut[j] = torch.mean(X[idx], 0)\n",
        "    if e_n > 1:\n",
        "      ecot[j] = torch.tensor(np.cov(X[idx].T, ddof=0)) + reg * torch.eye(n_features)\n",
        "      scot[j] = torch.std(S[idx]) + reg\n",
        "    else:\n",
        "      ecot[j] = reg * torch.eye(n_features)\n",
        "      scot[j] = reg\n",
        "  return n_c, smut, scot, emut, ecot\n",
        "\n",
        "\n",
        "def _estimate_mean_cov_t2v2(X, S, r_ijk, reg=1e-6):\n",
        "\n",
        "  #n, p = X.shape\n",
        "  #n, c, c = r_ijk.shape\n",
        "\n",
        "  smut = torch.zeros(n_clusters, n_clusters)\n",
        "  scot = torch.zeros(n_clusters, n_clusters)\n",
        "\n",
        "  emut = torch.zeros(n_clusters, n_clusters, n_features)\n",
        "  ecot = torch.zeros(n_clusters, n_clusters, n_features, n_features)\n",
        "\n",
        "  n_cc = torch.sum(r_ijk, dim=0) + reg # (cxc)\n",
        "\n",
        "  for j in range(n_clusters):\n",
        "    for k in range(n_clusters):\n",
        "      if not torch.isnan(n_cc[j,k]):\n",
        "        e_n = torch.round(n_cc[j,k])\n",
        "        idx = r_ijk[:,j,k].argsort()[-e_n.int():]\n",
        "        smut[j,k] = torch.mean(S[idx], 0)\n",
        "        emut[j,k] = torch.mean(X[idx], 0)\n",
        "        if e_n > 1:\n",
        "          scot[j,k] = torch.std(S[idx]) + reg\n",
        "          ecot[j,k] = torch.tensor(np.cov(X[idx].T, ddof=0)) + reg * torch.eye(n_features)\n",
        "        else:\n",
        "          scot[j,k] = reg\n",
        "          ecot[j,k] = reg * torch.eye(n_features)\n",
        "  return n_cc, smut, scot, emut, ecot\n",
        "\n",
        "def _ics(logL, n_obs, n_features, n_clusters): #, n, p, c\n",
        "  params = ( (((n_features * n_features) - n_features)/2 + 2 * n_features + 3) * (((n_clusters * n_clusters) - n_clusters)/2 + 2 * n_clusters) ) - 1\n",
        "  return 2 * (params - logL), -2 * logL + params * np.log(n_obs)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "061Liyd8cnl9",
        "outputId": "6470e1be-5266-47ec-8a55-932d585312b4"
      },
      "source": [
        "X = torch.tensor(xx[:,:2])\n",
        "S = torch.tensor(xx[:,2])\n",
        "\n",
        "## analytical version\n",
        "n_epochs = 1000\n",
        "tot = 1e-4\n",
        "iter = 0\n",
        "llv = [0.0]\n",
        "\n",
        "log_pi_d0 = torch.log(pi_d0)\n",
        "log_pi_d1 = torch.log(1 - pi_d0)\n",
        "\n",
        "log_pi_c = torch.log(pi_c)\n",
        "log_pi_cc = torch.log(pi_cc)\n",
        "\n",
        "while iter < n_epochs:\n",
        "\n",
        "  ### E-step:\n",
        "  log_post_top0 = torch.zeros(n_clusters, n_obs)\n",
        "  log_post_top1 = torch.zeros(n_clusters, n_clusters, n_obs)\n",
        "\n",
        "  for j in range(n_clusters):\n",
        "  \n",
        "    el0 = D.MultivariateNormal(emu_c[j], eco_c[j]).log_prob(X.float())\n",
        "    sl0 = D.Normal(smu_c[j], sco_c[j]).log_prob(S.float())\n",
        "    log_post_top0[j] = log_pi_d0 + log_pi_c[j] + el0 + sl0\n",
        "    \n",
        "    for k in range(n_clusters):\n",
        "      el1 = D.MultivariateNormal((emu_c[j] + emu_c[k])/2, (eco_c[j] + eco_c[k])/2).log_prob(X.float())\n",
        "      #https://stats.stackexchange.com/questions/99363/mean-of-covariance-matrices\n",
        "      #https://stats.stackexchange.com/questions/214174/calculating-the-covariance-matrix-for-the-mean-of-variables\n",
        "      sl1 = D.Normal(smu_c[j] + smu_c[k], sco_c[j] + sco_c[k]).log_prob(S.float())\n",
        "      \n",
        "      if torch.isnan(pi_cc[j,k]): #lower triangular nan\n",
        "        log_post_top1[j,k] = float(\"-Inf\")\n",
        "      else:\n",
        "        log_post_top1[j,k] = log_pi_d1 + log_pi_cc[j,k] + el1 + sl1\n",
        "\n",
        "  log_post_bot0 = torch.logsumexp(log_post_top0, 0) #n\n",
        "  log_post_z = (log_post_top0 - log_post_bot0).T #nxc (rjk)\n",
        "\n",
        "  log_post_top1 = log_post_top1.reshape(n_clusters * n_clusters, n_obs) #reshape\n",
        "  log_post_bot1 = torch.logsumexp(log_post_top1, 0) #n\n",
        "  log_post_g = (log_post_top1 - log_post_bot1).T #nxc (rijk)\n",
        "\n",
        "  log_post_tot = torch.logsumexp(torch.vstack((log_post_top0, log_post_top1)),0)\n",
        "  loss = -torch.mean(log_post_tot)\n",
        "\n",
        "  log_post_d0 = log_post_bot0 - log_post_tot\n",
        "  log_post_d1 = log_post_bot1 - log_post_tot\n",
        "\n",
        "  log_post_dz = log_post_d0[:,None] + log_post_z\n",
        "  log_post_dg = log_post_d1[:,None] + log_post_g\n",
        "\n",
        "  ### M-step:\n",
        "\n",
        "  log_pi_d0 = torch.logsumexp(log_post_d0, 0) - torch.log(torch.tensor(n_obs))\n",
        "\n",
        "  r_ij = torch.exp(log_post_dz)\n",
        "  n_c, smu_c, sco_c, emu_c, eco_c = _estimate_mean_cov_t1v2(X, S, r_ij)\n",
        "  log_pi_c = torch.log(n_c) - torch.log(torch.tensor(n_obs))\n",
        "\n",
        "  indx = []\n",
        "  for j in range(log_post_dg.shape[1]):\n",
        "    if torch.sum(torch.isinf(log_post_dg[:,j])) == log_post_dg.shape[0]:\n",
        "      indx.append(j)\n",
        "  log_post_dg[:,indx] = float('NaN')\n",
        "\n",
        "  r_ijk = torch.exp(log_post_dg).reshape(n_obs, n_clusters, n_clusters)\n",
        "  n_cc, smu_cc, sco_cc, emu_cc, eco_cc = _estimate_mean_cov_t2v2(X, S, r_ijk)\n",
        "  log_pi_cc = torch.log(n_cc) - torch.log(torch.tensor(n_obs))\n",
        "      \n",
        "  print('Iteration', iter + 1, 'Likelihood: ', -loss, torch.exp(log_pi_d0))\n",
        "\n",
        "  if abs(llv[-1] + loss) < tot:\n",
        "    break\n",
        "      \n",
        "  llv.append(-loss)\n",
        "  iter += 1\n",
        "  \n",
        "aic, bic = _ics(-loss, n_obs, n_features, n_clusters)\n",
        "#return llv[1:], aic, bic"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1 Likelihood:  tensor(-27.5427) tensor(0.6436)\n",
            "Iteration 2 Likelihood:  tensor(-6.5293) tensor(0.9461)\n",
            "Iteration 3 Likelihood:  tensor(-8.8737) tensor(0.9517)\n",
            "Iteration 4 Likelihood:  tensor(-10.2177) tensor(0.9517)\n",
            "Iteration 5 Likelihood:  tensor(-10.4964) tensor(0.9517)\n",
            "Iteration 6 Likelihood:  tensor(-10.4964) tensor(0.9517)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeUaa87994Qe",
        "outputId": "7e2e335e-506f-42ff-b7bb-d71851b7bdc8"
      },
      "source": [
        "torch.exp(log_pi_d0)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9517)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnq7dmHa95z5",
        "outputId": "43a71e8f-d87e-4ced-92c1-00d569d7dc89"
      },
      "source": [
        "torch.exp(log_pi_c)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2290, 0.4848, 0.2380])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQiHlomD966G",
        "outputId": "71b674ba-d323-4d88-ef43-ee7c3653cabe"
      },
      "source": [
        "torch.exp(log_pi_cc)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.5287e-06, 2.8217e-03, 4.9191e-03],\n",
              "        [       nan, 1.4747e-04, 5.7032e-03],\n",
              "        [       nan,        nan, 3.4661e-02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSTJaXEpspFa",
        "outputId": "aee06a62-b966-4ad9-dc8f-9d9558a5a90f"
      },
      "source": [
        "emu_c"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9948, 2.0004],\n",
              "        [4.0021, 2.9967],\n",
              "        [7.0200, 9.0043]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "553jOLO1-CbW",
        "outputId": "ba4a0e91-5bd2-4de6-da3c-1068680b2f32"
      },
      "source": [
        "smu_c"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3986, 0.5006, 0.5999])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45i0Dl8E-CmU",
        "outputId": "7c429fc1-0c11-4643-b768-c1b61dec738c"
      },
      "source": [
        "bic"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(674.9269)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD4APkuUFWXp"
      },
      "source": [
        "## analytical versio (no loop)\n",
        "\n",
        "log_pi_d0 = torch.log(pi_d0)\n",
        "log_pi_d1 = torch.log(1 - pi_d0)\n",
        "\n",
        "log_pi_c = torch.log(pi_c)\n",
        "log_pi_cc = torch.log(pi_cc)\n",
        "\n",
        "### E-step:\n",
        "log_post_top0 = torch.zeros(n_clusters, n_obs)\n",
        "log_post_top1 = torch.zeros(n_clusters, n_clusters, n_obs)\n",
        "\n",
        "for j in range(n_clusters):\n",
        "  \n",
        "  el0 = D.MultivariateNormal(emu_c[j], eco_c[j]).log_prob(X.float())\n",
        "  sl0 = D.Normal(smu_c[j], sco_c[j]).log_prob(S.float())\n",
        "  log_post_top0[j] = log_pi_d0 + log_pi_c[j] + el0 + sl0\n",
        "    \n",
        "  for k in range(n_clusters):\n",
        "    el1 = D.MultivariateNormal((emu_c[j] + emu_c[k])/2, (eco_c[j] + eco_c[k])/2).log_prob(X.float())\n",
        "    #https://stats.stackexchange.com/questions/99363/mean-of-covariance-matrices\n",
        "    #https://stats.stackexchange.com/questions/214174/calculating-the-covariance-matrix-for-the-mean-of-variables\n",
        "    sl1 = D.Normal(smu_c[j] + smu_c[k], sco_c[j] + sco_c[k]).log_prob(S.float())\n",
        "      \n",
        "    #el1 = D.MultivariateNormal(emu_cc[j,k]/2, eco_cc[j,k]/2).log_prob(X.float())\n",
        "    #sl1 = D.Normal(smu_cc[j,k], sco_cc[j,k]).log_prob(S.float())\n",
        "\n",
        "    if torch.isnan(pi_cc[j,k]): #lower triangular nan\n",
        "      log_post_top1[j,k] = float(\"-Inf\")\n",
        "    else:\n",
        "      log_post_top1[j,k] = log_pi_d1 + log_pi_cc[j,k] + el1 + sl1\n",
        "\n",
        "log_post_bot0 = torch.logsumexp(log_post_top0, 0) #n\n",
        "log_post_z = (log_post_top0 - log_post_bot0).T #nxc (rjk)\n",
        "\n",
        "log_post_top1 = log_post_top1.reshape(n_clusters * n_clusters, n_obs) #reshape\n",
        "log_post_bot1 = torch.logsumexp(log_post_top1, 0) #n\n",
        "log_post_g = (log_post_top1 - log_post_bot1).T #nxc (rijk)\n",
        "\n",
        "'''\n",
        "bot = torch.log(torch.exp(log_post_bot0) + torch.exp(log_post_bot1))\n",
        "indices = bot == float(\"-inf\")\n",
        "if torch.sum(indices) > 0:\n",
        "  ## look at which log prob is smaller\n",
        "  ind = log_post_bot0[indices] < log_post_bot1[indices]  \n",
        "  log_post_bot1[indices][ind] = 0\n",
        "  log_post_bot0[indices][~ind] = 0\n",
        "  bot[indices] = 0\n",
        "loss = -torch.mean(bot)\n",
        "  \n",
        "log_post_d0 = log_post_bot0 - bot\n",
        "log_post_d1 = log_post_bot1 - bot\n",
        "'''\n",
        "\n",
        "log_post_tot = torch.logsumexp(torch.vstack((log_post_top0, log_post_top1)),0)\n",
        "loss = -torch.mean(log_post_tot)\n",
        "\n",
        "log_post_d0 = log_post_bot0 - log_post_tot\n",
        "log_post_d1 = log_post_bot1 - log_post_tot\n",
        "\n",
        "log_post_dz = log_post_d0[:,None] + log_post_z\n",
        "log_post_dg = log_post_d1[:,None] + log_post_g\n",
        "\n",
        "### M-step:\n",
        "\n",
        "#pi_d0 = torch.sum(torch.exp(log_post_d0)) / n_obs # one value\n",
        "log_pi_d0 = torch.logsumexp(log_post_d0, 0) - torch.log(torch.tensor(n_obs))\n",
        "\n",
        "r_ij = torch.exp(log_post_dz)\n",
        "n_c, smu_c, sco_c, emu_c, eco_c = _estimate_mean_cov_t1v2(X, S, r_ij)\n",
        "#pi_c = n_c / n_obs # c values\n",
        "log_pi_c = torch.log(n_c) - torch.log(torch.tensor(n_obs))\n",
        "\n",
        "indx = []\n",
        "for j in range(log_post_dg.shape[1]):\n",
        "  if torch.sum(torch.isinf(log_post_dg[:,j])) == log_post_dg.shape[0]:\n",
        "    indx.append(j)\n",
        "log_post_dg[:,indx] = float('NaN')\n",
        "\n",
        "r_ijk = torch.exp(log_post_dg).reshape(n_obs, n_clusters, n_clusters)\n",
        "n_cc, smu_cc, sco_cc, emu_cc, eco_cc = _estimate_mean_cov_t2v2(X, S, r_ijk)\n",
        "#pi_cc = n_cc / n_obs  # cxc matrix  \n",
        "log_pi_cc = torch.log(n_cc) - torch.log(torch.tensor(n_obs))\n",
        "      \n",
        "print('Iteration', iter + 1, 'Likelihood: ', -loss, torch.exp(log_pi_d0))\n",
        "\n",
        "#if abs(llv[-1] + loss) < tot:\n",
        "#  break\n",
        "      \n",
        "llv.append(-loss)\n",
        "iter += 1\n",
        "\n",
        "aic, bic = _ics(-loss, n_obs, n_features, n_clusters)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR8CQz6dYAFi"
      },
      "source": [
        ""
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V475ZRjpYCGg"
      },
      "source": [
        ""
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DKnOGXTYUoH"
      },
      "source": [
        ""
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSkMWrg7SdPM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO_fckWqjAU1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTJ2xUj8Sdlm",
        "outputId": "0c470f8a-cfb4-41fb-ea13-f7d57e2de6e6"
      },
      "source": [
        "## initialization\n",
        "\n",
        "n_obs = N\n",
        "n_features = 2\n",
        "n_clusters = 3\n",
        "\n",
        "#torch.manual_seed(42)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "emu_c = torch.tensor([\n",
        "    [2, 3], # 1 2\n",
        "    [3, 5], # 4 3\n",
        "    [7, 8]\n",
        "], dtype=torch.float) #, requires_grad=True, , device=device)\n",
        "\n",
        "smu_c = torch.tensor([.45, .55, .65], dtype=torch.float) #, requires_grad=True,  device=device)\n",
        "\n",
        "eco_c = 0.1 * torch.eye(n_features).tile(n_clusters, 1, 1)\n",
        "sco_c = 0.1 * torch.ones(n_clusters, dtype=torch.float)\n",
        "\n",
        "smu_cc = torch.zeros(n_clusters, n_clusters, dtype=torch.float)\n",
        "sco_cc = torch.zeros(n_clusters, n_clusters, dtype=torch.float)\n",
        "\n",
        "emu_cc = torch.zeros(n_clusters, n_clusters, n_features, dtype=torch.float)\n",
        "eco_cc = torch.zeros(n_clusters, n_clusters, n_features, n_features, dtype=torch.float)\n",
        "\n",
        "for j in range(n_clusters):\n",
        "  for k in range(n_clusters):\n",
        "    smu_cc[j,k] = smu_c[j] + smu_c[k]\n",
        "    sco_cc[j,k] = sco_c[j] + sco_c[k]\n",
        "\n",
        "    emu_cc[j,k] = (emu_c[j] + emu_c[k])\n",
        "    eco_cc[j,k] = (eco_c[j] + eco_c[k])\n",
        "\n",
        "smu_c = torch.tensor(smu_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "sco_c = torch.tensor(sco_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "      \n",
        "emu_c = torch.tensor(emu_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "eco_c = torch.tensor(eco_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "      \n",
        "smu_cc = torch.tensor(smu_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "sco_cc = torch.tensor(sco_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "      \n",
        "emu_cc = torch.tensor(emu_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "eco_cc = torch.tensor(eco_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "      \n",
        "####\n",
        "\n",
        "pi_d0 = torch.tensor(0.9)\n",
        "\n",
        "pi_c = torch.empty(n_clusters).fill_(1. / (n_clusters))\n",
        "\n",
        "pi_cc = torch.triu(torch.ones(n_clusters, n_clusters))\n",
        "pi_cc = pi_cc / torch.sum(pi_cc)\n",
        "pi_cc[pi_cc == 0] = float('NaN')\n",
        "\n",
        "def _ics(logL, n_obs, n_features, n_clusters): #, n, p, c\n",
        "  params = ( (((n_features * n_features) - n_features)/2 + 2 * n_features + 3) * (((n_clusters * n_clusters) - n_clusters)/2 + 2 * n_clusters) ) - 1\n",
        "  return 2 * (params - logL), -2 * logL + params * np.log(n_obs)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3GfEy3Klpol"
      },
      "source": [
        "## torch.optim version\n",
        "\n",
        "X = torch.tensor(xx[:,:2])\n",
        "S = torch.tensor(xx[:,2])\n",
        "\n",
        "#parameters = [emu_c, eco_c, smu_c, sco_c]\n",
        "#parameters = [emu_cc, eco_cc, smu_cc, sco_cc]\n",
        "parameters = [emu_c, eco_c, smu_c, sco_c, emu_cc, eco_cc, smu_cc, sco_cc]\n",
        "#opt = optim.SGD(parameters, lr=0.01)\n",
        "opt = optim.Adam(parameters, lr=0.01)\n",
        "\n",
        "tot = 1e-4\n",
        "llv = [0.0]\n",
        "\n",
        "log_pi_d0 = torch.log(pi_d0)\n",
        "log_pi_d1 = torch.log(1-pi_d0)\n",
        "log_pi_c = torch.log(pi_c)\n",
        "log_pi_cc = torch.log(pi_cc)\n",
        "\n",
        "iter = 0\n",
        "n_epochs = 500\n",
        "while iter < n_epochs:\n",
        "\n",
        "  log_post_top0 = torch.zeros(n_clusters, n_obs)\n",
        "  log_post_top1 = torch.zeros(n_clusters, n_clusters, n_obs)\n",
        "\n",
        "  for j in range(n_clusters):  \n",
        "    el0 = D.MultivariateNormal(emu_c[j], eco_c[j]).log_prob(X.float())\n",
        "    sl0 = D.Normal(smu_c[j], sco_c[j]).log_prob(S.float())\n",
        "    log_post_top0[j] = log_pi_d0 + log_pi_c[j] + el0 + sl0\n",
        "\n",
        "    for k in range(n_clusters):\n",
        "      el1 = D.MultivariateNormal(emu_cc[j,k]/2, eco_cc[j,k]/2).log_prob(X.float())\n",
        "      sl1 = D.Normal(smu_cc[j,k], sco_cc[j,k]).log_prob(S.float())\n",
        "            \n",
        "      if torch.isnan(pi_cc[j,k]): #lower triangular nan\n",
        "        log_post_top1[j,k] = float(\"-Inf\")\n",
        "      else:\n",
        "        log_post_top1[j,k] = log_pi_d1 + log_pi_cc[j,k] + el1 + sl1\n",
        "\n",
        "  log_post_bot0 = torch.logsumexp(log_post_top0, 0) #n\n",
        "  \n",
        "  log_post_top1 = log_post_top1.reshape(n_clusters * n_clusters, n_obs) #reshape\n",
        "  log_post_bot1 = torch.logsumexp(log_post_top1, 0) #n\n",
        "\n",
        "  log_post_tot = torch.logsumexp(torch.vstack((log_post_top0, log_post_top1)),0)\n",
        "  loss = -torch.mean(log_post_tot)\n",
        "\n",
        "  opt.zero_grad()\n",
        "  loss.backward()\n",
        "  opt.step()\n",
        "  #print(emu_c)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    parameters[0].clamp_(tot)\n",
        "    ##parameters[1].clamp_(tot)\n",
        "    parameters[2].clamp_(tot)\n",
        "    parameters[3].clamp_(tot)\n",
        "    parameters[4].clamp_(tot)\n",
        "    ##parameters[5].clamp_(tot)\n",
        "    parameters[6].clamp_(tot)\n",
        "    parameters[7].clamp_(tot)\n",
        "\n",
        "    eco_c += torch.eye(n_features) * tot\n",
        "    eco_cc += torch.eye(n_features) * tot\n",
        "    \n",
        "    log_post_d0 = log_post_bot0 - log_post_tot\n",
        "    log_post_d1 = log_post_bot1 - log_post_tot\n",
        "\n",
        "    log_post_z = (log_post_top0 - log_post_bot0).T #nxc (rjk)\n",
        "    log_post_g = (log_post_top1 - log_post_bot1).T #nxc (rijk)\n",
        "\n",
        "    log_post_dz = log_post_d0[:,None] + log_post_z\n",
        "    log_post_dg = log_post_d1[:,None] + log_post_g\n",
        "\n",
        "    log_n_c = torch.logsumexp(log_post_dz, 0)\n",
        "    log_pi_c = log_n_c - torch.log(torch.tensor(n_obs))\n",
        "\n",
        "    log_n_cc = torch.logsumexp(log_post_dg, 0).reshape(n_clusters, n_clusters)\n",
        "    log_pi_cc = log_n_cc - torch.log(torch.tensor(n_obs))  # cxc matrix\n",
        "\n",
        "    log_pi_d0 = torch.logsumexp(log_post_d0, 0) - torch.log(torch.tensor(n_obs))\n",
        "\n",
        "  print('Iteration', iter + 1, 'Likelihood: ', -loss, torch.exp(log_pi_d0))\n",
        "\n",
        "  if abs(llv[-1] + loss) < tot:\n",
        "    break\n",
        "      \n",
        "  llv.append(-loss)\n",
        "  iter += 1\n",
        "\n",
        "aic, bic = _ics(-loss, n_obs, n_features, n_clusters)\n",
        "\n",
        "#print(epoch, pi_d0, loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUmlAf07jqpe",
        "outputId": "400649e0-282a-4dc5-d9e0-43b61f00830d"
      },
      "source": [
        "torch.exp(log_pi_d0)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9911)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twaV0WiNkUKm",
        "outputId": "fdf51de5-2eb1-4e6e-d7b5-5b1e4db396ab"
      },
      "source": [
        "torch.exp(log_pi_c)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2292, 0.4844, 0.2775])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFpDgKm_kkZI",
        "outputId": "6204d878-78d1-4457-bf92-b8e674c8fbd2"
      },
      "source": [
        "torch.exp(log_pi_cc)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0032, 0.0056],\n",
              "        [0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3jIdug8VcfW",
        "outputId": "317cad4c-7bdd-4368-85c3-e703e4524f9c"
      },
      "source": [
        "emu_c"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0129, 2.0011],\n",
              "        [4.0010, 3.0177],\n",
              "        [7.4586, 9.4239]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWmH3cD8kxHy",
        "outputId": "36aaa090-43c7-4764-f009-54c4b1c17911"
      },
      "source": [
        "smu_c"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3986, 0.5007, 0.6695], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GSMFDxJ6NRF",
        "outputId": "ccb20101-6d57-4d35-a10b-c0550786dcfd"
      },
      "source": [
        "bic"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(657.4882, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "iWLFYd0SLxAM",
        "outputId": "cb99c8be-f73b-4f44-be76-16260535fc0e"
      },
      "source": [
        "plt.plot(llv[1:])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f095e1d4810>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T856vZGxnkka"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHTHLSqllKTD"
      },
      "source": [
        "## torch.optim version (no loop)\n",
        "\n",
        "X = torch.tensor(xx[:,:2])\n",
        "S = torch.tensor(xx[:,2])\n",
        "\n",
        "#parameters = [emu_c, eco_c, smu_c, sco_c]\n",
        "#parameters = [emu_cc, eco_cc, smu_cc, sco_cc]\n",
        "parameters = [emu_c, eco_c, smu_c, sco_c, emu_cc, eco_cc, smu_cc, sco_cc]\n",
        "opt = optim.SGD(parameters, lr=0.01)\n",
        "#opt = optim.Adam(parameters)\n",
        "\n",
        "tot = 1e-4\n",
        "llv = [0.0]\n",
        "\n",
        "log_pi_d0 = torch.log(pi_d0)\n",
        "log_pi_d1 = torch.log(1-pi_d0)\n",
        "log_pi_c = torch.log(pi_c)\n",
        "log_pi_cc = torch.log(pi_cc)\n",
        "\n",
        "#iter = 0\n",
        "#n_epochs = 500\n",
        "#while iter < n_epochs:\n",
        "\n",
        "log_post_top0 = torch.zeros(n_clusters, n_obs)\n",
        "log_post_top1 = torch.zeros(n_clusters, n_clusters, n_obs)\n",
        "\n",
        "for j in range(n_clusters):  \n",
        "  el0 = D.MultivariateNormal(emu_c[j], eco_c[j]).log_prob(X.float())\n",
        "  sl0 = D.Normal(smu_c[j], sco_c[j]).log_prob(S.float())\n",
        "  log_post_top0[j] = log_pi_d0 + log_pi_c[j] + el0 + sl0\n",
        "\n",
        "  for k in range(n_clusters):\n",
        "    el1 = D.MultivariateNormal(emu_cc[j,k]/2, eco_cc[j,k]/2).log_prob(X.float())\n",
        "    sl1 = D.Normal(smu_cc[j,k], sco_cc[j,k]).log_prob(S.float())\n",
        "            \n",
        "    if torch.isnan(pi_cc[j,k]): #lower triangular nan\n",
        "      log_post_top1[j,k] = float(\"-Inf\")\n",
        "    else:\n",
        "      log_post_top1[j,k] = log_pi_d1 + log_pi_cc[j,k] + el1 + sl1\n",
        "\n",
        "log_post_bot0 = torch.logsumexp(log_post_top0, 0) #n\n",
        "  \n",
        "log_post_top1 = log_post_top1.reshape(n_clusters * n_clusters, n_obs) #reshape\n",
        "log_post_bot1 = torch.logsumexp(log_post_top1, 0) #n\n",
        "\n",
        "log_post_tot = torch.logsumexp(torch.vstack((log_post_top0, log_post_top1)),0)\n",
        "loss = -torch.mean(log_post_tot)\n",
        "\n",
        "#print(emu_c)\n",
        "opt.zero_grad()\n",
        "loss.backward()\n",
        "opt.step()\n",
        "#print(emu_cc)\n",
        "\n",
        "with torch.no_grad():\n",
        "  parameters[0].clamp_(tot)\n",
        "  ##parameters[1].clamp_(tot)\n",
        "  parameters[2].clamp_(tot)\n",
        "  parameters[3].clamp_(tot)\n",
        "  parameters[4].clamp_(tot)\n",
        "  ##parameters[5].clamp_(tot)\n",
        "  parameters[6].clamp_(tot)\n",
        "  parameters[7].clamp_(tot)\n",
        "\n",
        "  log_post_d0 = log_post_bot0 - log_post_tot\n",
        "  log_post_d1 = log_post_bot1 - log_post_tot\n",
        "\n",
        "  log_post_z = (log_post_top0 - log_post_bot0).T #nxc (rjk)\n",
        "  log_post_g = (log_post_top1 - log_post_bot1).T #nxc (rijk)\n",
        "\n",
        "  log_post_dz = log_post_d0[:,None] + log_post_z\n",
        "  log_post_dg = log_post_d1[:,None] + log_post_g\n",
        "\n",
        "  #r_ij = torch.exp(log_post_dz)\n",
        "  #n_c = torch.sum(r_ij, dim=0)\n",
        "  #pi_c = n_c / n_obs  # c values\n",
        "  log_n_c = torch.logsumexp(log_post_dz, 0)\n",
        "  log_pi_c = log_n_c - torch.log(torch.tensor(n_obs))\n",
        "\n",
        "  #r_ijk = torch.exp(log_post_dg).reshape(n_obs, n_clusters, n_clusters)\n",
        "  #n_cc = torch.sum(r_ijk, dim=0) # (cxc)\n",
        "  #pi_cc = n_cc / n_obs  # cxc matrix\n",
        "\n",
        "  log_n_cc = torch.logsumexp(log_post_dg, 0).reshape(n_clusters, n_clusters)\n",
        "  log_pi_cc = log_n_cc - torch.log(torch.tensor(n_obs))  # cxc matrix\n",
        "\n",
        "  #pi_d0 = torch.sum(torch.exp(log_post_d0)) / n_obs # one value\n",
        "  log_pi_d0 = torch.logsumexp(log_post_d0, 0) - torch.log(torch.tensor(n_obs))\n",
        "\n",
        "print('Iteration', iter + 1, 'Likelihood: ', -loss, torch.exp(log_pi_d0))\n",
        "\n",
        "#if abs(llv[-1] + loss) < tot:\n",
        "#  break\n",
        "      \n",
        "llv.append(-loss)\n",
        "iter += 1\n",
        "\n",
        "aic, bic = _ics(-loss, n_obs, n_features, n_clusters)\n",
        "\n",
        "#print(epoch, pi_d0, loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9BY30lrlKdK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjsoVpn6lKnX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSeLT_pnlKwe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxABrzMAlLS-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fruC6plFCfD2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}