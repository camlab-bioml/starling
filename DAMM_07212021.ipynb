{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DAMM_07212021",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNXyNrg63pYuYJttht3JRHV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camlab-bioml/2021_IMC_Jett/blob/main/DAMM_07212021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC3ybb9RaZCM"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.distributions as D\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.datasets as datasets\n",
        "\n",
        "def _ics(logL, n_obs, n_features, n_clusters): #, n, p, c\n",
        "  params = ( (((n_features * n_features) - n_features)/2 + 2 * n_features + 3) * (((n_clusters * n_clusters) - n_clusters)/2 + 2 * n_clusters) ) - 1\n",
        "  return 2 * (params - logL), -2 * logL + params * np.log(n_obs)\n",
        "  \n",
        "def generateData(n_clusters = 3, n_obs = 10000, n_features = 2):\n",
        "\n",
        "  ## set ground true expressions ##\n",
        "\n",
        "  true_expression_means = torch.tensor([\n",
        "      [3, 5],\n",
        "      [6, 7],\n",
        "      [9, 11]\n",
        "  ])\n",
        "  \n",
        "  #true_expression_means = torch.randint(1, 11, (n_clusters, n_features))\n",
        "  #print(true_expression_means)\n",
        "\n",
        "  true_expression_covs = torch.tensor([\n",
        "      [[.1, 0], [0, .1]],\n",
        "      [[.1, 0], [0, .1]],\n",
        "      [[.1, 0], [0, .1]]\n",
        "  ])\n",
        "\n",
        "  true_size_means = torch.tensor([.4, .6, .8])\n",
        "  #true_size_means = torch.rand(n_clusters)\n",
        "  #print(true_size_means)\n",
        "\n",
        "  true_size_stds = torch.tensor([.01, .01, .01])\n",
        "  #true_size_stds\n",
        "\n",
        "  ## other ground true for generating data ##\n",
        "  d_ws = torch.tensor([.95, .05])\n",
        "  \n",
        "  #z_ws = torch.tensor([1 / 4, 1 / 2, 1 / 4])\n",
        "  z_ws = np.random.rand(n_clusters)\n",
        "  z_ws /= z_ws.sum()\n",
        "  #print(z_ws.sum())\n",
        "\n",
        "  #g_ws = torch.tensor([0.0667, 0.1333, 0.2000, 0.1000, 0.2667, 0.2333])\n",
        "  n_events = int((n_clusters * n_clusters - n_clusters)/2 + n_clusters)\n",
        "  g_ws = np.random.rand(n_events)\n",
        "  g_ws /= g_ws.sum()\n",
        "  #print(g_ws.sum())\n",
        "  \n",
        "  gs = np.sum(np.random.choice(2, size = n_obs, p = d_ws))\n",
        "  zs = n_obs - gs\n",
        "\n",
        "  ## simulate data\n",
        "  x = np.zeros((zs, n_features+4))\n",
        "  for i in range(zs):\n",
        "    z = np.random.choice(n_clusters, size = 1, p = z_ws)[0]\n",
        "    x[i] = np.append(np.random.multivariate_normal(true_expression_means[z], true_expression_covs[z]), [np.random.normal(true_size_means[z], true_size_stds[z]), 0, z, z+6])\n",
        "  \n",
        "  xxx = np.zeros((gs, n_features+4))\n",
        "  for i in range(gs):\n",
        "\n",
        "    g = np.random.choice(6, size = 1, p = g_ws)[0]\n",
        "    \n",
        "    if g == 0:\n",
        "      idx = [0,0]\n",
        "    elif g == 1:\n",
        "      idx = [0,1]\n",
        "    elif g == 2:\n",
        "      idx = [0,2]\n",
        "    elif g == 3:\n",
        "      idx = [1,1]\n",
        "    elif g == 4:\n",
        "      idx = [1,2]\n",
        "    else:\n",
        "      idx = [2,2]\n",
        "  \n",
        "    xxx[i] = np.append(np.random.multivariate_normal( (true_expression_means[idx[0]] + true_expression_means[idx[1]]), (true_expression_covs[idx[0]] + true_expression_covs[idx[1]]) ),\n",
        "                     [np.random.normal( (true_size_means[idx[0]] + true_size_means[idx[1]]), (true_size_stds[idx[0]] + true_size_stds[idx[1]]) ), 1, g, g])\n",
        "  \n",
        "  xx = np.append(x, xxx).reshape(n_obs,6)\n",
        "\n",
        "  ## check number of points in each cluster\n",
        "  for i in range(9):\n",
        "    print(sum(xx[:,5] == i)/n_obs)\n",
        "  \n",
        "  print(gs)\n",
        "\n",
        "  return torch.tensor(xx[:,:2]), torch.tensor(xx[:,2])\n",
        "\n",
        "## initialization\n",
        "def initialization(n_clusters, X, S):\n",
        "\n",
        "  n_obs, n_features = X.shape\n",
        "\n",
        "  #torch.manual_seed(seed_num)\n",
        "\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    \n",
        "  #pi_d0 = torch.tensor(0.9)\n",
        "  pi_d0 = torch.tensor(np.random.uniform(.9, 1))\n",
        "  \n",
        "  pi_c = torch.empty(n_clusters).fill_(1. / (n_clusters))\n",
        "  \n",
        "  pi_cc = torch.triu(torch.ones(n_clusters, n_clusters))\n",
        "  pi_cc = pi_cc / torch.sum(pi_cc)\n",
        "  pi_cc[pi_cc == 0] = float('NaN')\n",
        "\n",
        "  emu_c = X[np.random.choice(n_obs, n_clusters, replace=False)].float()\n",
        "\n",
        "  '''\n",
        "  emu_c = torch.tensor([\n",
        "    [2, 6], # 1 2\n",
        "    [5, 8], # 4 3\n",
        "    [9, 10] #7 9\n",
        "  ], dtype=torch.float) #, requires_grad=True, , device=device)\n",
        "  '''\n",
        "\n",
        "  smu_c = S[np.random.choice(n_obs, n_clusters, replace=False)].float()\n",
        "  #smu_c = torch.tensor([.3, .5, .7], dtype=torch.float) #, requires_grad=True,  device=device)\n",
        "\n",
        "  eco_c = 0.1 * torch.eye(n_features).tile(n_clusters, 1, 1)\n",
        "  sco_c = 0.01 * torch.ones(n_clusters, dtype=torch.float)\n",
        "\n",
        "  smu_cc = torch.zeros(n_clusters, n_clusters, dtype=torch.float)\n",
        "  sco_cc = torch.zeros(n_clusters, n_clusters, dtype=torch.float)\n",
        "\n",
        "  emu_cc = torch.zeros(n_clusters, n_clusters, n_features, dtype=torch.float)\n",
        "  eco_cc = torch.zeros(n_clusters, n_clusters, n_features, n_features, dtype=torch.float)\n",
        "\n",
        "  for j in range(n_clusters):\n",
        "    for k in range(n_clusters):\n",
        "      if k >= j:\n",
        "        smu_cc[j,k] = smu_c[j] + smu_c[k]\n",
        "        sco_cc[j,k] = sco_c[j] + sco_c[k]\n",
        "\n",
        "        emu_cc[j,k] = (emu_c[j] + emu_c[k])\n",
        "        eco_cc[j,k] = (eco_c[j] + eco_c[k])\n",
        "\n",
        "  params1 = [emu_c, eco_c, smu_c, sco_c, emu_cc, eco_cc, smu_cc, sco_cc]\n",
        "\n",
        "  smu_c = torch.tensor(smu_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "  sco_c = torch.tensor(sco_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "      \n",
        "  emu_c = torch.tensor(emu_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "  eco_c = torch.tensor(eco_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "      \n",
        "  smu_cc = torch.tensor(smu_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "  sco_cc = torch.tensor(sco_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "      \n",
        "  emu_cc = torch.tensor(emu_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "  eco_cc = torch.tensor(eco_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "  hyperparams = [pi_d0, pi_c, pi_cc]\n",
        "  params2 = [emu_c, eco_c, smu_c, sco_c, emu_cc, eco_cc, smu_cc, sco_cc]\n",
        "\n",
        "  return hyperparams, params1, params2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz_7j-Fvap1t",
        "outputId": "b66231db-8e34-457c-caa8-83a3e278be53"
      },
      "source": [
        "n_clusters = 3\n",
        "n_obs = 10000\n",
        "n_features = 2\n",
        "\n",
        "X, S = generateData(n_clusters, n_obs, n_features)\n",
        "\n",
        "#X = torch.tensor(xx[:,:2])\n",
        "#S = torch.tensor(xx[:,2])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0063\n",
            "0.0078\n",
            "0.0087\n",
            "0.0101\n",
            "0.005\n",
            "0.0085\n",
            "0.2135\n",
            "0.6104\n",
            "0.1297\n",
            "464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSsM2Zzl7L2x"
      },
      "source": [
        "def _estimate_mean_cov_t1v1(X, r_ij, reg=1e-6):\n",
        "\n",
        "  n, p = X.shape\n",
        "  n, c = r_ij.shape\n",
        "\n",
        "  mut = torch.zeros(c, p)\n",
        "  cot = torch.zeros(c, p, p)\n",
        "\n",
        "  n_c = torch.sum(r_ij, dim=0) + reg # (c)\n",
        "\n",
        "  for j in range(c):\n",
        "    e_n = torch.round(n_c[j])\n",
        "    idx = r_ij[:,j].argsort()[-e_n.int():]\n",
        "    mut[j] = torch.mean(X[idx], 0)\n",
        "    if e_n > 1:\n",
        "      cot[j] = torch.tensor(np.cov(X[idx].T, ddof=0)) + reg * torch.eye(p)\n",
        "    else:\n",
        "      cot[j] = reg * torch.eye(p)\n",
        "  return n_c, mut, cot\n",
        "\n",
        "def _estimate_mean_cov_t2v1(X, r_ijk, reg=1e-6):\n",
        "\n",
        "  n, p = X.shape\n",
        "  n, c, c = r_ijk.shape\n",
        "\n",
        "  mut = torch.zeros(c, c, p)\n",
        "  cot = torch.zeros(c, c, p, p)\n",
        "\n",
        "  n_cc = torch.sum(r_ijk, dim=0) + reg # (cxc)\n",
        "\n",
        "  for j in range(c):\n",
        "    for k in range(c):\n",
        "      if not torch.isnan(n_cc[j,k]):\n",
        "        e_n = torch.round(n_cc[j,k])\n",
        "        idx = r_ijk[:,j,k].argsort()[-e_n.int():]\n",
        "        mut[j,k] = torch.mean(X[idx], 0)\n",
        "        if e_n > 1:\n",
        "          cot[j,k] = torch.tensor(np.cov(X[idx].T, ddof=0)) + reg * torch.eye(p)\n",
        "        else:\n",
        "          cot[j,k] = reg * torch.eye(p)\n",
        "  return n_cc, mut, cot\n",
        "\n",
        "## helper function\n",
        "def _estimate_mean_cov_t1v2(X, S, r_ij, reg=1e-6):\n",
        "\n",
        "  #n, p = X.shape\n",
        "  #n, c = r_ij.shape\n",
        "\n",
        "  smut = torch.zeros(n_clusters)\n",
        "  scot = torch.zeros(n_clusters)\n",
        "\n",
        "  emut = torch.zeros(n_clusters, n_features)\n",
        "  ecot = torch.zeros(n_clusters, n_features, n_features)\n",
        "\n",
        "  n_c = torch.sum(r_ij, dim=0) #+ reg # (c)\n",
        "\n",
        "  for j in range(n_clusters):\n",
        "    e_n = torch.round(n_c[j])\n",
        "    idx = r_ij[:,j].argsort()[-e_n.int():]\n",
        "    smut[j] = torch.mean(S[idx], 0)\n",
        "    emut[j] = torch.mean(X[idx], 0)\n",
        "    if e_n > 1:\n",
        "      ecot[j] = torch.tensor(np.cov(X[idx].T, ddof=0)) + reg * torch.eye(n_features)\n",
        "      scot[j] = torch.std(S[idx]) + reg\n",
        "    else:\n",
        "      ecot[j] = reg * torch.eye(n_features)\n",
        "      scot[j] = reg\n",
        "  return n_c, smut, scot, emut, ecot\n",
        "\n",
        "def _estimate_mean_cov_t2v2(X, S, log_rijk, reg=1e-6):\n",
        "\n",
        "  n_obs, n_features = X.shape\n",
        "  n_obs, n_clusters, n_clusters = log_rijk.shape\n",
        "\n",
        "  smut = torch.zeros(n_clusters, n_clusters)\n",
        "  scot = torch.zeros(n_clusters, n_clusters)\n",
        "\n",
        "  emut = torch.zeros(n_clusters, n_clusters, n_features)\n",
        "  ecot = torch.zeros(n_clusters, n_clusters, n_features, n_features)\n",
        "\n",
        "  #n_cc = torch.sum(r_ijk, dim=0) + reg # (cxc)\n",
        "  log_n_cc = torch.logsumexp(log_rijk, dim=0) # (cxc)\n",
        "  #n_cc = torch.exp(log_n_cc) + reg\n",
        "\n",
        "  for j in range(n_clusters):\n",
        "    for k in range(n_clusters):\n",
        "      if not torch.isnan(torch.exp(log_n_cc[j,k])):\n",
        "        e_n = torch.round(torch.exp(log_n_cc[j,k]))\n",
        "        idx = torch.exp(log_rijk[:,j,k]).argsort()[-e_n.int():]\n",
        "        smut[j,k] = torch.mean(S[idx], 0)\n",
        "        emut[j,k] = torch.mean(X[idx], 0)\n",
        "        if e_n > 1:\n",
        "          scot[j,k] = torch.std(S[idx]) + reg\n",
        "          ecot[j,k] = torch.tensor(np.cov(X[idx].T, ddof=0)) + reg * torch.eye(n_features)\n",
        "        else:\n",
        "          scot[j,k] = reg\n",
        "          ecot[j,k] = reg * torch.eye(n_features)\n",
        "  return log_n_cc, smut, scot, emut, ecot"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXyP4fIxpWVH"
      },
      "source": [
        "  n_epochs = 1000\n",
        "  tot = 0.005\n",
        "\n",
        "  import numpy as np\n",
        "  from sklearn.mixture import GaussianMixture"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q5SlgCwGdBu"
      },
      "source": [
        "## GMM\n",
        "torch.set_printoptions(precision=10)\n",
        "\n",
        "for i in range(50):\n",
        "  \n",
        "  hps, ngps, gps = initialization(n_clusters, X, S)\n",
        "  pi_d0 = hps[0]\n",
        "  pi_d1 = 1-hps[0]\n",
        "  pi_c = hps[1]\n",
        "  pi_cc = hps[2]\n",
        "\n",
        "  emu_c = ngps[0]\n",
        "  eco_c = ngps[1]\n",
        "  \n",
        "  ## analytical version 1\n",
        "\n",
        "  iter = 0\n",
        "  qs = [0.0]\n",
        "  ls = [0.0]\n",
        "\n",
        "  while iter < n_epochs:\n",
        "\n",
        "    log_pi = torch.log(pi_c)\n",
        "    \n",
        "    ### E-step:\n",
        "    log_rd0z_top = torch.zeros(n_clusters, n_obs)\n",
        "    \n",
        "    for j in range(n_clusters):\n",
        "  \n",
        "      el0 = D.MultivariateNormal(emu_c[j], eco_c[j]).log_prob(X.float())\n",
        "      #sl0 = D.Normal(smu_c[j], sco_c[j]).log_prob(S.float())\n",
        "      log_rd0z_top[j] = log_pi[j] + el0 #+ sl0\n",
        "    \n",
        "    log_rdzg_norm = log_rd0z_top.logsumexp(0) #shape: n\n",
        "    log_rdz = (log_rd0z_top - log_rdzg_norm).T #shape: nxc\n",
        "    \n",
        "    q1 = log_rd0z_top.T * log_rdz.exp(); q1[torch.isnan(q1)] = 0.0 #p(x,theta'|z=c,d=0)p(z=c,d=0|x,theta')\n",
        "    Q = torch.logsumexp(q1, 1).mean()\n",
        "\n",
        "    #l1 = log_rd0z_top.T + log_rdz\n",
        "    #L1 = torch.logsumexp(l1,1).mean()\n",
        "    L = log_rdzg_norm.mean()\n",
        "\n",
        "    ## M-step:\n",
        "    rdz = torch.exp(log_rdz)\n",
        "    n_c, emu_c, eco_c = _estimate_mean_cov_t1v2(X, rdz)\n",
        "    pi_c = n_c / n_obs\n",
        "\n",
        "    print('Iteration', iter + 1, 'Q: ', Q, 'Likelihood: ', L, pi_c)\n",
        "\n",
        "    if abs(ls[-1] - L) < tot:\n",
        "      break\n",
        "\n",
        "    if iter > 1 and ls[-1] > L:\n",
        "      print(\"something is wrong!\")\n",
        "      break\n",
        "\n",
        "    qs.append(Q)\n",
        "    ls.append(L)\n",
        "    iter += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUNNug84Hegz",
        "outputId": "cfb11dc2-88f1-408d-88d4-e78cfaf9a350"
      },
      "source": [
        "gm = GaussianMixture(n_components=3, random_state=0).fit(X)\n",
        "gm.score(X)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-2.3407317163393464"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "RhOuwaMkF2iZ",
        "outputId": "8b41f676-546e-4a69-e9d5-04c11cffd7b4"
      },
      "source": [
        "plt.plot(ls[1:])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff85c1018d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "APXgHH5UHTin",
        "outputId": "e0d64c97-7956-4d90-b2f4-cd60ec33694b"
      },
      "source": [
        "plt.plot(qs[1:])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff85baff410>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ecaBRM-MIfp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l33Yi5JFH25R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCedYi-UH3Eo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck_mRzA-FxZG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycWWYjyk__nA",
        "outputId": "ccf42c5b-14e3-4f07-e040-2331121f5283"
      },
      "source": [
        "## emu_c, eco_c updates\n",
        "torch.set_printoptions(precision=5)\n",
        "\n",
        "for i in range(10):\n",
        "  \n",
        "  hps, ngps, gps = initialization(n_clusters, X, S)\n",
        "  pi_d0 = hps[0]\n",
        "  pi_d1 = 1-hps[0]\n",
        "  pi_c = hps[1]\n",
        "  pi_cc = hps[2]\n",
        "\n",
        "  emu_c = ngps[0]\n",
        "  eco_c = ngps[1]\n",
        "\n",
        "  iter = 0\n",
        "  qs = [0.0]\n",
        "  ls = [0.0]\n",
        "\n",
        "  #print(emu_c)\n",
        "  while iter < n_epochs:\n",
        "\n",
        "    log_lambda0_pi = torch.log(pi_d0) + torch.log(pi_c)\n",
        "    log_lambda1_tau = torch.log(1 - pi_d0) + torch.log(pi_cc)\n",
        "\n",
        "    ### E-step:\n",
        "    log_rd0z_top = torch.zeros(n_clusters, n_obs)\n",
        "    log_rd1g_top = torch.zeros(n_clusters, n_clusters, n_obs)\n",
        "\n",
        "    for j in range(n_clusters):\n",
        "  \n",
        "      el0 = D.MultivariateNormal(emu_c[j], eco_c[j]).log_prob(X.float())\n",
        "      log_rd0z_top[j] = log_lambda0_pi[j] + el0\n",
        "    \n",
        "      for k in range(n_clusters):\n",
        "        if torch.isnan(log_lambda1_tau[j,k]): #lower triangular nan\n",
        "          log_rd1g_top[j,k] = float(\"NaN\")\n",
        "        else:\n",
        "          el1 = D.MultivariateNormal((emu_c[j] + emu_c[k]), (eco_c[j] + eco_c[k])).log_prob(X.float())\n",
        "          log_rd1g_top[j,k] = log_lambda1_tau[j,k] + el1\n",
        "\n",
        "    log_rd1g_top = log_rd1g_top.reshape(n_clusters * n_clusters, n_obs) #shape: (cxc')xn\n",
        "\n",
        "    ignored_indices = torch.isnan(torch.logsumexp(log_rd1g_top, 1))\n",
        "    assert(ignored_indices.sum() == (n_clusters * n_clusters - n_clusters) / 2)\n",
        "    \n",
        "    log_rdzg_norm = torch.logsumexp(torch.vstack((log_rd0z_top, log_rd1g_top[~ignored_indices])),0) #shape: n\n",
        "    #log_rdzg_norm1 = torch.logsumexp(torch.vstack((torch.logsumexp(log_rd0z_top, 0), torch.logsumexp(log_rd1g_top[~ignored_indices],0))),0)\n",
        "\n",
        "    log_rdz = (log_rd0z_top - log_rdzg_norm).T #shape: nxc\n",
        "    log_rdg = (log_rd1g_top - log_rdzg_norm).T #shape: nx(cxc')\n",
        "\n",
        "    assert(torch.sum(torch.sum(torch.exp(log_rdz),1) + torch.sum(torch.exp(log_rdg[:,~ignored_indices]),1)).round() == n_obs)\n",
        "\n",
        "    q1 = log_rd0z_top.T * log_rdz.exp(); q1[torch.isnan(q1)] = 0.0 #p(x,theta'|z=c,d=0)p(z=c,d=0|x,theta')\n",
        "    q2 = log_rd1g_top[~ignored_indices].T * log_rdg[:,~ignored_indices].exp(); q2[torch.isnan(q2)] = 0.0 #p(x,theta'|g=[c,c'],d=1)p(g=[c,c'],d=1|x,theta')\n",
        "    Q = torch.vstack((torch.logsumexp(q1, 1), torch.logsumexp(q2, 1))).logsumexp(0).mean() # mean(sum_d sum_z(q1) + sum_g(q2))\n",
        "\n",
        "    l1 = log_rd0z_top.T + log_rdz\n",
        "    l2 = log_rd1g_top[~ignored_indices].T + log_rdg[:,~ignored_indices]; #l2[torch.isinf(l2)] = -100\n",
        "    L1 = torch.vstack((torch.logsumexp(l1,1), torch.logsumexp(l2,1))).logsumexp(0).mean()\n",
        "    L = log_rdzg_norm.mean()\n",
        "\n",
        "    ## M-step:\n",
        "    rdz = torch.exp(log_rdz)\n",
        "    n_c, emu_c, eco_c = _estimate_mean_cov_t1v1(X, rdz)\n",
        "    pi_c = n_c / n_obs\n",
        "    pi_d0 = torch.sum(pi_c)\n",
        "\n",
        "    rdg = torch.exp(log_rdg).reshape(n_obs, n_clusters, n_clusters)\n",
        "    n_cc = torch.sum(rdg, dim=0)\n",
        "    pi_cc = n_cc / n_obs\n",
        "    pi_d1 = torch.sum(torch.triu(pi_cc))\n",
        "\n",
        "    if abs(ls[-1] - L) < tot:\n",
        "      break\n",
        "\n",
        "    if pi_d1 < tot:\n",
        "      print(\"d1 is approaching 0! -> change a different initalization values\")\n",
        "      break\n",
        "\n",
        "    if iter > 1 and ls[-1] > L:\n",
        "      print(\"something is wrong!\")\n",
        "      break\n",
        "    \n",
        "    print('Iteration', iter + 1, 'Q: ', Q, 'Likelihood: ', L, L1, 'd0: ', pi_d0)\n",
        "\n",
        "    qs.append(Q)\n",
        "    ls.append(L)\n",
        "    iter += 1\n",
        "\n",
        "  aic, bic = _ics(-L, n_obs, n_features, n_clusters)\n",
        "  print(aic)\n",
        "  #return llv[1:], aic, bic"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:147: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:149: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:150: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:153: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:155: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1 Q:  tensor(2.09485) Likelihood:  tensor(-2.62570) tensor(-2.64206) d0:  tensor(0.93916)\n",
            "Iteration 2 Q:  tensor(2.11450) Likelihood:  tensor(-1.90945) tensor(-1.91248) d0:  tensor(0.95226)\n",
            "Iteration 3 Q:  tensor(2.11554) Likelihood:  tensor(-1.89287) tensor(-1.89402) d0:  tensor(0.95388)\n",
            "tensor(138.21596)\n",
            "Iteration 1 Q:  tensor(2.08234) Likelihood:  tensor(-2.55460) tensor(-2.63539) d0:  tensor(0.86378)\n",
            "Iteration 2 Q:  tensor(2.10533) Likelihood:  tensor(-2.08476) tensor(-2.10718) d0:  tensor(0.93022)\n",
            "Iteration 3 Q:  tensor(2.11356) Likelihood:  tensor(-1.92500) tensor(-1.93026) d0:  tensor(0.95053)\n",
            "Iteration 4 Q:  tensor(2.11546) Likelihood:  tensor(-1.89434) tensor(-1.89558) d0:  tensor(0.95364)\n",
            "tensor(138.21577)\n",
            "Iteration 1 Q:  tensor(2.05660) Likelihood:  tensor(-19.03039) tensor(-19.44042) d0:  tensor(0.49282)\n",
            "Iteration 2 Q:  tensor(2.02784) Likelihood:  tensor(-33.54848) tensor(-33.78198) d0:  tensor(0.49272)\n",
            "something is wrong!\n",
            "tensor(74.18137)\n",
            "Iteration 1 Q:  tensor(1.99628) Likelihood:  tensor(-198.17264) tensor(-198.56351) d0:  tensor(0.98379)\n",
            "Iteration 2 Q:  tensor(2.02731) Likelihood:  tensor(-3.41741) tensor(-3.69360) d0:  tensor(0.98309)\n",
            "Iteration 3 Q:  tensor(2.05686) Likelihood:  tensor(-3.18533) tensor(-3.31779) d0:  tensor(0.97925)\n",
            "Iteration 4 Q:  tensor(2.07444) Likelihood:  tensor(-2.89972) tensor(-2.99386) d0:  tensor(0.96953)\n",
            "Iteration 5 Q:  tensor(2.08179) Likelihood:  tensor(-2.65104) tensor(-2.74198) d0:  tensor(0.96294)\n",
            "Iteration 6 Q:  tensor(2.08519) Likelihood:  tensor(-2.58693) tensor(-2.67041) d0:  tensor(0.96465)\n",
            "Iteration 7 Q:  tensor(2.08711) Likelihood:  tensor(-2.55689) tensor(-2.62884) d0:  tensor(0.96713)\n",
            "Iteration 8 Q:  tensor(2.08936) Likelihood:  tensor(-2.52618) tensor(-2.58436) d0:  tensor(0.96931)\n",
            "Iteration 9 Q:  tensor(2.09183) Likelihood:  tensor(-2.49387) tensor(-2.53688) d0:  tensor(0.97217)\n",
            "Iteration 10 Q:  tensor(2.09452) Likelihood:  tensor(-2.45872) tensor(-2.48668) d0:  tensor(0.97603)\n",
            "Iteration 11 Q:  tensor(2.09606) Likelihood:  tensor(-2.43560) tensor(-2.45606) d0:  tensor(0.97881)\n",
            "Iteration 12 Q:  tensor(2.09665) Likelihood:  tensor(-2.41217) tensor(-2.42935) d0:  tensor(0.98694)\n",
            "d1 is approaching 0! -> change a different initalization values\n",
            "tensor(137.26436)\n",
            "Iteration 1 Q:  tensor(2.09699) Likelihood:  tensor(-4.56732) tensor(-4.61628) d0:  tensor(0.87592)\n",
            "Iteration 2 Q:  tensor(2.10422) Likelihood:  tensor(-4.23119) tensor(-4.26788) d0:  tensor(0.87585)\n",
            "tensor(133.53418)\n",
            "Iteration 1 Q:  tensor(1.96133) Likelihood:  tensor(-21.74407) tensor(-22.34668) d0:  tensor(0.49287)\n",
            "Iteration 2 Q:  tensor(2.05631) Likelihood:  tensor(-29.76861) tensor(-29.95093) d0:  tensor(0.49222)\n",
            "something is wrong!\n",
            "tensor(72.46396)\n",
            "Iteration 1 Q:  tensor(2.08516) Likelihood:  tensor(-31.47033) tensor(-31.47130) d0:  tensor(0.96630)\n",
            "Iteration 2 Q:  tensor(2.09891) Likelihood:  tensor(-2.51954) tensor(-2.52493) d0:  tensor(0.96508)\n",
            "Iteration 3 Q:  tensor(2.09995) Likelihood:  tensor(-2.50672) tensor(-2.51015) d0:  tensor(0.96509)\n",
            "tensor(136.98872)\n",
            "Iteration 1 Q:  tensor(2.09512) Likelihood:  tensor(-4.43407) tensor(-4.43526) d0:  tensor(0.88247)\n",
            "Iteration 2 Q:  tensor(2.11230) Likelihood:  tensor(-3.95363) tensor(-3.95396) d0:  tensor(0.88464)\n",
            "Iteration 3 Q:  tensor(2.11194) Likelihood:  tensor(-3.93669) tensor(-3.93748) d0:  tensor(0.88515)\n",
            "Iteration 4 Q:  tensor(2.11170) Likelihood:  tensor(-3.92244) tensor(-3.92358) d0:  tensor(0.88549)\n",
            "Iteration 5 Q:  tensor(2.11154) Likelihood:  tensor(-3.91728) tensor(-3.91878) d0:  tensor(0.88581)\n",
            "tensor(134.16730)\n",
            "Iteration 1 Q:  tensor(2.08803) Likelihood:  tensor(-3.78854) tensor(-3.95214) d0:  tensor(0.87575)\n",
            "Iteration 2 Q:  tensor(2.09146) Likelihood:  tensor(-4.85898) tensor(-4.99595) d0:  tensor(0.87652)\n",
            "Iteration 3 Q:  tensor(2.08932) Likelihood:  tensor(-4.85333) tensor(-5.00088) d0:  tensor(0.88064)\n",
            "Iteration 4 Q:  tensor(2.08254) Likelihood:  tensor(-3.91466) tensor(-4.09257) d0:  tensor(0.93921)\n",
            "Iteration 5 Q:  tensor(2.08331) Likelihood:  tensor(-2.28414) tensor(-2.44237) d0:  tensor(0.95464)\n",
            "Iteration 6 Q:  tensor(2.08793) Likelihood:  tensor(-2.18241) tensor(-2.32184) d0:  tensor(0.95412)\n",
            "Iteration 7 Q:  tensor(2.09219) Likelihood:  tensor(-2.12525) tensor(-2.24265) d0:  tensor(0.95395)\n",
            "Iteration 8 Q:  tensor(2.09678) Likelihood:  tensor(-2.07898) tensor(-2.17052) d0:  tensor(0.95395)\n",
            "Iteration 9 Q:  tensor(2.10128) Likelihood:  tensor(-2.04451) tensor(-2.10939) d0:  tensor(0.95397)\n",
            "Iteration 10 Q:  tensor(2.10570) Likelihood:  tensor(-2.01886) tensor(-2.05919) d0:  tensor(0.95402)\n",
            "Iteration 11 Q:  tensor(2.11050) Likelihood:  tensor(-1.99557) tensor(-2.01379) d0:  tensor(0.95410)\n",
            "Iteration 12 Q:  tensor(2.11470) Likelihood:  tensor(-1.95987) tensor(-1.96306) d0:  tensor(0.95438)\n",
            "Iteration 13 Q:  tensor(2.11557) Likelihood:  tensor(-1.90515) tensor(-1.90595) d0:  tensor(0.95511)\n",
            "Iteration 14 Q:  tensor(2.11552) Likelihood:  tensor(-1.89253) tensor(-1.89327) d0:  tensor(0.95463)\n",
            "tensor(138.21597)\n",
            "Iteration 1 Q:  tensor(1.97973) Likelihood:  tensor(-23.44857) tensor(-24.00076) d0:  tensor(0.49213)\n",
            "Iteration 2 Q:  tensor(1.97121) Likelihood:  tensor(-34.16293) tensor(-34.56505) d0:  tensor(0.49394)\n",
            "Iteration 3 Q:  tensor(2.04952) Likelihood:  tensor(-20.99320) tensor(-21.17392) d0:  tensor(0.51534)\n",
            "Iteration 4 Q:  tensor(2.05970) Likelihood:  tensor(-6.17473) tensor(-6.33502) d0:  tensor(0.56935)\n",
            "Iteration 5 Q:  tensor(2.06202) Likelihood:  tensor(-4.25513) tensor(-4.41352) d0:  tensor(0.57176)\n",
            "Iteration 6 Q:  tensor(2.06520) Likelihood:  tensor(-3.95444) tensor(-4.09896) d0:  tensor(0.57165)\n",
            "Iteration 7 Q:  tensor(2.06825) Likelihood:  tensor(-3.73184) tensor(-3.85959) d0:  tensor(0.57144)\n",
            "Iteration 8 Q:  tensor(2.07116) Likelihood:  tensor(-3.57207) tensor(-3.68237) d0:  tensor(0.57143)\n",
            "Iteration 9 Q:  tensor(2.07429) Likelihood:  tensor(-3.47519) tensor(-3.56640) d0:  tensor(0.57183)\n",
            "tensor(135.05542)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X_snqfx__6G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WReD6PTJW0P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RGr_nB2LtHK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSrOfhPmKOoQ",
        "outputId": "5f101db9-ecc5-4278-df2f-333b1a23b9d3"
      },
      "source": [
        "## emu_c, eco_c, smu_c, sco_c updates\n",
        "for i in range(10):\n",
        "  \n",
        "  hps, ngps, gps = initialization(n_clusters, X, S)\n",
        "  pi_d0 = hps[0]\n",
        "  pi_d1 = 1-hps[0]\n",
        "  pi_c = hps[1]\n",
        "  pi_cc = hps[2]\n",
        "\n",
        "  emu_c = ngps[0]\n",
        "  eco_c = ngps[1]\n",
        "  smu_c = ngps[2]\n",
        "  sco_c = ngps[3]\n",
        "\n",
        "  iter = 0\n",
        "  qs = [0.0]\n",
        "  ls = [0.0]\n",
        "\n",
        "  #print(emu_c)\n",
        "  while iter < n_epochs:\n",
        "\n",
        "    log_lambda0_pi = torch.log(pi_d0) + torch.log(pi_c)\n",
        "    log_lambda1_tau = torch.log(1 - pi_d0) + torch.log(pi_cc)\n",
        "\n",
        "    ### E-step:\n",
        "    log_rd0z_top = torch.zeros(n_clusters, n_obs)\n",
        "    log_rd1g_top = torch.zeros(n_clusters, n_clusters, n_obs)\n",
        "\n",
        "    for j in range(n_clusters):\n",
        "  \n",
        "      el0 = D.MultivariateNormal(emu_c[j], eco_c[j]).log_prob(X.float())\n",
        "      sl0 = D.Normal(smu_c[j], sco_c[j]).log_prob(S.float())\n",
        "      log_rd0z_top[j] = log_lambda0_pi[j] + el0 + sl0\n",
        "    \n",
        "      for k in range(n_clusters):\n",
        "        if torch.isnan(log_lambda1_tau[j,k]): #lower triangular nan\n",
        "          log_rd1g_top[j,k] = float(\"NaN\")\n",
        "        else:\n",
        "          el1 = D.MultivariateNormal((emu_c[j] + emu_c[k]), (eco_c[j] + eco_c[k])).log_prob(X.float())\n",
        "          sl1 = D.Normal(smu_c[j] + smu_c[k], sco_c[j] + sco_c[k]).log_prob(S.float())\n",
        "          log_rd1g_top[j,k] = log_lambda1_tau[j,k] + el1 + sl1\n",
        "\n",
        "    log_rd1g_top = log_rd1g_top.reshape(n_clusters * n_clusters, n_obs) #shape: (cxc')xn\n",
        "\n",
        "    ignored_indices = torch.isnan(torch.logsumexp(log_rd1g_top, 1))\n",
        "    assert(ignored_indices.sum() == (n_clusters * n_clusters - n_clusters) / 2)\n",
        "    \n",
        "    log_rdzg_norm = torch.logsumexp(torch.vstack((log_rd0z_top, log_rd1g_top[~ignored_indices])),0) #shape: n\n",
        "    #log_rdzg_norm1 = torch.logsumexp(torch.vstack((torch.logsumexp(log_rd0z_top, 0), torch.logsumexp(log_rd1g_top[~ignored_indices],0))),0)\n",
        "\n",
        "    log_rdz = (log_rd0z_top - log_rdzg_norm).T #shape: nxc\n",
        "    log_rdg = (log_rd1g_top - log_rdzg_norm).T #shape: nx(cxc')\n",
        "\n",
        "    assert(torch.sum(torch.sum(torch.exp(log_rdz),1) + torch.sum(torch.exp(log_rdg[:,~ignored_indices]),1)).round() == n_obs)\n",
        "\n",
        "    q1 = log_rd0z_top.T * log_rdz.exp(); q1[torch.isnan(q1)] = 0.0 #p(x,theta'|z=c,d=0)p(z=c,d=0|x,theta')\n",
        "    q2 = log_rd1g_top[~ignored_indices].T * log_rdg[:,~ignored_indices].exp(); q2[torch.isnan(q2)] = 0.0 #p(x,theta'|g=[c,c'],d=1)p(g=[c,c'],d=1|x,theta')\n",
        "    Q = torch.vstack((torch.logsumexp(q1, 1), torch.logsumexp(q2, 1))).logsumexp(0).mean() # mean(sum_d sum_z(q1) + sum_g(q2))\n",
        "\n",
        "    l1 = log_rd0z_top.T + log_rdz\n",
        "    l2 = log_rd1g_top[~ignored_indices].T + log_rdg[:,~ignored_indices]; #l2[torch.isinf(l2)] = -100\n",
        "    L1 = torch.vstack((torch.logsumexp(l1,1), torch.logsumexp(l2,1))).logsumexp(0).mean()\n",
        "    L = log_rdzg_norm.mean()\n",
        "\n",
        "    ## M-step:\n",
        "    rdz = torch.exp(log_rdz)\n",
        "    n_c, smu_c, sco_c, emu_c, eco_c = _estimate_mean_cov_t1v2(X, S, rdz)\n",
        "    pi_c = n_c / n_obs\n",
        "    pi_d0 = torch.sum(pi_c)\n",
        "\n",
        "    rdg = torch.exp(log_rdg).reshape(n_obs, n_clusters, n_clusters)\n",
        "    #n_cc, emu_cc, eco_cc = _estimate_mean_cov_t2v2(X, rdg)\n",
        "    n_cc = torch.sum(rdg, dim=0)\n",
        "    pi_cc = n_cc / n_obs\n",
        "    pi_d1 = torch.sum(torch.triu(pi_cc))\n",
        "\n",
        "    if abs(ls[-1] - L) < tot:\n",
        "      break\n",
        "\n",
        "    if pi_d1 < tot:\n",
        "      print(\"d1 is approaching 0! -> change a different initalization values\")\n",
        "      break\n",
        "\n",
        "    if iter > 1 and ls[-1] > L:\n",
        "      print(\"something is wrong!\")\n",
        "      break\n",
        "\n",
        "    print('Iteration', iter + 1, 'Q: ', Q, 'Likelihood: ', L, L1, 'd0: ', pi_d0)\n",
        "\n",
        "    qs.append(Q)\n",
        "    ls.append(L)\n",
        "    iter += 1\n",
        "\n",
        "  aic, bic = _ics(-L, n_obs, n_features, n_clusters)\n",
        "  print(bic)\n",
        "  #return llv[1:], aic, bic"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:147: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:149: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:150: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:153: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:155: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1 Q:  tensor(2.18476) Likelihood:  tensor(-426.26419) tensor(-426.27420) d0:  tensor(0.96630)\n",
            "Iteration 2 Q:  tensor(2.16420) Likelihood:  tensor(-1.29059) tensor(-1.30396) d0:  tensor(0.96551)\n",
            "Iteration 3 Q:  tensor(2.25265) Likelihood:  tensor(-0.58162) tensor(-0.58868) d0:  tensor(0.96199)\n",
            "Iteration 4 Q:  tensor(2.40571) Likelihood:  tensor(0.26062) tensor(0.26062) d0:  tensor(0.96130)\n",
            "Iteration 5 Q:  tensor(2.65259) Likelihood:  tensor(0.84429) tensor(0.84429) d0:  tensor(0.96130)\n",
            "Iteration 6 Q:  tensor(2.65258) Likelihood:  tensor(0.98078) tensor(0.98078) d0:  tensor(0.96130)\n",
            "Iteration 7 Q:  tensor(2.65183) Likelihood:  tensor(0.99163) tensor(0.98934) d0:  tensor(0.95797)\n",
            "Iteration 8 Q:  tensor(2.66950) Likelihood:  tensor(1.13483) tensor(1.13310) d0:  tensor(0.95088)\n",
            "Iteration 9 Q:  tensor(2.70625) Likelihood:  tensor(1.24186) tensor(1.24156) d0:  tensor(0.95050)\n",
            "tensor(656.41888)\n",
            "Iteration 1 Q:  tensor(2.29727) Likelihood:  tensor(-17.91623) tensor(-17.91641) d0:  tensor(0.49210)\n",
            "Iteration 2 Q:  tensor(2.31651) Likelihood:  tensor(-35.36810) tensor(-35.36829) d0:  tensor(0.49210)\n",
            "Iteration 3 Q:  tensor(2.31654) Likelihood:  tensor(-35.35295) tensor(-35.35314) d0:  tensor(0.49210)\n",
            "tensor(583.22827)\n",
            "Iteration 1 Q:  tensor(2.07613) Likelihood:  tensor(-182.24118) tensor(-182.24724) d0:  tensor(0.95174)\n",
            "Iteration 2 Q:  tensor(2.16820) Likelihood:  tensor(-1.43099) tensor(-1.45608) d0:  tensor(0.96451)\n",
            "Iteration 3 Q:  tensor(2.24344) Likelihood:  tensor(-0.92240) tensor(-0.92450) d0:  tensor(0.96532)\n",
            "Iteration 4 Q:  tensor(2.47152) Likelihood:  tensor(-0.38261) tensor(-0.38485) d0:  tensor(0.96542)\n",
            "tensor(653.16925)\n",
            "Iteration 1 Q:  tensor(2.14382) Likelihood:  tensor(-31.82052) tensor(-31.82088) d0:  tensor(0.49210)\n",
            "Iteration 2 Q:  tensor(2.31509) Likelihood:  tensor(-35.35896) tensor(-35.37273) d0:  tensor(0.49210)\n",
            "Iteration 3 Q:  tensor(2.31511) Likelihood:  tensor(-35.35295) tensor(-35.36672) d0:  tensor(0.49210)\n",
            "tensor(583.22827)\n",
            "Iteration 1 Q:  tensor(2.07772) Likelihood:  tensor(-367.12997) tensor(-367.13327) d0:  tensor(0.57280)\n",
            "Iteration 2 Q:  tensor(2.10390) Likelihood:  tensor(-4.04198) tensor(-4.04629) d0:  tensor(0.57252)\n",
            "tensor(645.84705)\n",
            "Iteration 1 Q:  tensor(2.23483) Likelihood:  tensor(-30.85716) tensor(-30.85763) d0:  tensor(0.49210)\n",
            "Iteration 2 Q:  tensor(2.31816) Likelihood:  tensor(-35.36540) tensor(-35.36540) d0:  tensor(0.49210)\n",
            "Iteration 3 Q:  tensor(2.31820) Likelihood:  tensor(-35.35295) tensor(-35.35295) d0:  tensor(0.49210)\n",
            "tensor(583.22827)\n",
            "Iteration 1 Q:  tensor(2.27875) Likelihood:  tensor(-5.60865) tensor(-5.60867) d0:  tensor(0.86990)\n",
            "Iteration 2 Q:  tensor(2.65738) Likelihood:  tensor(-5.03728) tensor(-5.03729) d0:  tensor(0.86990)\n",
            "tensor(643.85956)\n",
            "Iteration 1 Q:  tensor(2.27067) Likelihood:  tensor(-107.57930) tensor(-107.57930) d0:  tensor(0.96150)\n",
            "Iteration 2 Q:  tensor(2.29896) Likelihood:  tensor(-0.73536) tensor(-0.73878) d0:  tensor(0.95325)\n",
            "Iteration 3 Q:  tensor(2.34739) Likelihood:  tensor(-0.62574) tensor(-0.62760) d0:  tensor(0.95048)\n",
            "Iteration 4 Q:  tensor(2.35997) Likelihood:  tensor(-0.61198) tensor(-0.61397) d0:  tensor(0.95047)\n",
            "tensor(652.71033)\n",
            "Iteration 1 Q:  tensor(2.20557) Likelihood:  tensor(-24.62728) tensor(-24.66805) d0:  tensor(0.49210)\n",
            "Iteration 2 Q:  tensor(2.31753) Likelihood:  tensor(-35.83567) tensor(-35.83567) d0:  tensor(0.49210)\n",
            "Iteration 3 Q:  tensor(2.31819) Likelihood:  tensor(-35.35295) tensor(-35.35295) d0:  tensor(0.49210)\n",
            "tensor(583.22827)\n",
            "Iteration 1 Q:  tensor(2.04469) Likelihood:  tensor(-241.88730) tensor(-241.92101) d0:  tensor(0.96140)\n",
            "Iteration 2 Q:  tensor(2.61188) Likelihood:  tensor(0.70483) tensor(0.69926) d0:  tensor(0.95936)\n",
            "Iteration 3 Q:  tensor(2.65847) Likelihood:  tensor(1.00496) tensor(1.00403) d0:  tensor(0.96130)\n",
            "Iteration 4 Q:  tensor(2.65246) Likelihood:  tensor(1.05625) tensor(1.05591) d0:  tensor(0.96130)\n",
            "tensor(656.04675)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqO7zLN8JW-J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CPe5oiaMyQj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCOO3o1WgO7S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKRU5bZhMya2"
      },
      "source": [
        "## emu_c, eco_c, smu_c, sco_c updates and divide by 2 (no good)\n",
        "for i in range(10):\n",
        "  \n",
        "  hps, ngps, gps = initialization(n_clusters, X, S)\n",
        "  pi_d0 = hps[0]\n",
        "  pi_d1 = 1-hps[0]\n",
        "  pi_c = hps[1]\n",
        "  pi_cc = hps[2]\n",
        "\n",
        "  emu_c = ngps[0]\n",
        "  eco_c = ngps[1]\n",
        "  smu_c = ngps[2]\n",
        "  sco_c = ngps[3]\n",
        "\n",
        "  iter = 0\n",
        "  qs = [0.0]\n",
        "  ls = [0.0]\n",
        "\n",
        "  #print(emu_c)\n",
        "  while iter < n_epochs:\n",
        "\n",
        "    log_lambda0_pi = torch.log(pi_d0) + torch.log(pi_c)\n",
        "    log_lambda1_tau = torch.log(1 - pi_d0) + torch.log(pi_cc)\n",
        "\n",
        "    ### E-step:\n",
        "    log_rd0z_top = torch.zeros(n_clusters, n_obs)\n",
        "    log_rd1g_top = torch.zeros(n_clusters, n_clusters, n_obs)\n",
        "\n",
        "    for j in range(n_clusters):\n",
        "  \n",
        "      el0 = D.MultivariateNormal(emu_c[j], eco_c[j]).log_prob(X.float())\n",
        "      sl0 = D.Normal(smu_c[j], sco_c[j]).log_prob(S.float())\n",
        "      log_rd0z_top[j] = log_lambda0_pi[j] + el0 + sl0\n",
        "    \n",
        "      for k in range(n_clusters):\n",
        "        if torch.isnan(log_lambda1_tau[j,k]): #lower triangular nan\n",
        "          log_rd1g_top[j,k] = float(\"NaN\")\n",
        "        else:\n",
        "          el1 = D.MultivariateNormal((emu_c[j] + emu_c[k]), (eco_c[j] + eco_c[k])).log_prob(X.float())\n",
        "          sl1 = D.Normal((smu_c[j] + smu_c[k])/2, (sco_c[j] + sco_c[k])/2).log_prob(S.float())\n",
        "          log_rd1g_top[j,k] = log_lambda1_tau[j,k] + el1 + sl1\n",
        "\n",
        "    log_rd1g_top = log_rd1g_top.reshape(n_clusters * n_clusters, n_obs) #shape: (cxc')xn\n",
        "\n",
        "    ignored_indices = torch.isnan(torch.logsumexp(log_rd1g_top, 1))\n",
        "    assert(ignored_indices.sum() == (n_clusters * n_clusters - n_clusters) / 2)\n",
        "    \n",
        "    log_rdzg_norm = torch.logsumexp(torch.vstack((log_rd0z_top, log_rd1g_top[~ignored_indices])),0) #shape: n\n",
        "    #log_rdzg_norm1 = torch.logsumexp(torch.vstack((torch.logsumexp(log_rd0z_top, 0), torch.logsumexp(log_rd1g_top[~ignored_indices],0))),0)\n",
        "\n",
        "    log_rdz = (log_rd0z_top - log_rdzg_norm).T #shape: nxc\n",
        "    log_rdg = (log_rd1g_top - log_rdzg_norm).T #shape: nx(cxc')\n",
        "\n",
        "    assert(torch.sum(torch.sum(torch.exp(log_rdz),1) + torch.sum(torch.exp(log_rdg[:,~ignored_indices]),1)).round() == n_obs)\n",
        "\n",
        "    q1 = log_rd0z_top.T * log_rdz.exp(); q1[torch.isnan(q1)] = 0.0 #p(x,theta'|z=c,d=0)p(z=c,d=0|x,theta')\n",
        "    q2 = log_rd1g_top[~ignored_indices].T * log_rdg[:,~ignored_indices].exp(); q2[torch.isnan(q2)] = 0.0 #p(x,theta'|g=[c,c'],d=1)p(g=[c,c'],d=1|x,theta')\n",
        "    Q = torch.vstack((torch.logsumexp(q1, 1), torch.logsumexp(q2, 1))).logsumexp(0).mean() # mean(sum_d sum_z(q1) + sum_g(q2))\n",
        "\n",
        "    l1 = log_rd0z_top.T + log_rdz\n",
        "    l2 = log_rd1g_top[~ignored_indices].T + log_rdg[:,~ignored_indices]; #l2[torch.isinf(l2)] = -100\n",
        "    L1 = torch.vstack((torch.logsumexp(l1,1), torch.logsumexp(l2,1))).logsumexp(0).mean()\n",
        "    L = log_rdzg_norm.mean()\n",
        "\n",
        "    ## M-step:\n",
        "    rdz = torch.exp(log_rdz)\n",
        "    n_c, smu_c, sco_c, emu_c, eco_c = _estimate_mean_cov_t1v2(X, S, rdz)\n",
        "    pi_c = n_c / n_obs\n",
        "    pi_d0 = torch.sum(pi_c)\n",
        "\n",
        "    rdg = torch.exp(log_rdg).reshape(n_obs, n_clusters, n_clusters)\n",
        "    #n_cc, emu_cc, eco_cc = _estimate_mean_cov_t2v2(X, rdg)\n",
        "    n_cc = torch.sum(rdg, dim=0)\n",
        "    pi_cc = n_cc / n_obs\n",
        "    pi_d1 = torch.sum(torch.triu(pi_cc))\n",
        "\n",
        "    if abs(ls[-1] - L) < tot:\n",
        "      break\n",
        "\n",
        "    if pi_d1 < tot:\n",
        "      print(\"d1 is approaching 0! -> change a different initalization values\")\n",
        "      break\n",
        "\n",
        "    if iter > 1 and ls[-1] > L:\n",
        "      print(\"something is wrong!\")\n",
        "      break\n",
        "\n",
        "    print('Iteration', iter + 1, 'Q: ', Q, 'Likelihood: ', L, L1, 'd0: ', pi_d0)\n",
        "\n",
        "    qs.append(Q)\n",
        "    ls.append(L)\n",
        "    iter += 1\n",
        "\n",
        "  aic, bic = _ics(-L, n_obs, n_features, n_clusters)\n",
        "  print(bic)\n",
        "  #return llv[1:], aic, bic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR5Z2oFLPIcc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdpQ3u6pPInf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYi3vsJYPI7f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHNjvFfHMyqy",
        "outputId": "7384baa2-04df-4c90-8fd9-e86f285d276a"
      },
      "source": [
        "## emu_c, eco_c, smu_c, sco_c and\n",
        "## emu_cc, eco_cc, smu_cc, sco_cc updates \n",
        "\n",
        "for i in range(10):\n",
        "  \n",
        "  hps, ngps, gps = initialization(n_clusters, X, S)\n",
        "  pi_d0 = hps[0]\n",
        "  pi_d1 = 1-hps[0]\n",
        "  pi_c = hps[1]\n",
        "  pi_cc = hps[2]\n",
        "\n",
        "  emu_c = ngps[0]\n",
        "  eco_c = ngps[1]\n",
        "  smu_c = ngps[2]\n",
        "  sco_c = ngps[3]\n",
        "\n",
        "  emu_cc = ngps[4]\n",
        "  eco_cc = ngps[5]\n",
        "  smu_cc = ngps[6]\n",
        "  sco_cc = ngps[7]\n",
        "\n",
        "  iter = 0\n",
        "  qs = [0.0]\n",
        "  ls = [0.0]\n",
        "\n",
        "  #print(emu_c)\n",
        "  while iter < n_epochs:\n",
        "\n",
        "    log_lambda0_pi = torch.log(pi_d0) + torch.log(pi_c)\n",
        "    log_lambda1_tau = torch.log(1 - pi_d0) + torch.log(pi_cc)\n",
        "\n",
        "    ### E-step:\n",
        "    log_rd0z_top = torch.zeros(n_clusters, n_obs)\n",
        "    log_rd1g_top = torch.zeros(n_clusters, n_clusters, n_obs)\n",
        "\n",
        "    for j in range(n_clusters):\n",
        "  \n",
        "      el0 = D.MultivariateNormal(emu_c[j], eco_c[j]).log_prob(X.float())\n",
        "      sl0 = D.Normal(smu_c[j], sco_c[j]).log_prob(S.float())\n",
        "      log_rd0z_top[j] = log_lambda0_pi[j] + el0 + sl0\n",
        "    \n",
        "      for k in range(n_clusters):\n",
        "        if torch.isnan(log_lambda1_tau[j,k]): #lower triangular nan\n",
        "          log_rd1g_top[j,k] = float(\"NaN\")\n",
        "        else:\n",
        "          el1 = D.MultivariateNormal(emu_cc[j,k], eco_cc[j,k]).log_prob(X.float())\n",
        "          sl1 = D.Normal(smu_cc[j,k], sco_cc[j,k]).log_prob(S.float())\n",
        "          log_rd1g_top[j,k] = log_lambda1_tau[j,k] + el1 + sl1\n",
        "\n",
        "    log_rd1g_top = log_rd1g_top.reshape(n_clusters * n_clusters, n_obs) #shape: (cxc')xn\n",
        "\n",
        "    ignored_indices = torch.isnan(torch.logsumexp(log_rd1g_top, 1))\n",
        "    assert(ignored_indices.sum() == (n_clusters * n_clusters - n_clusters) / 2)\n",
        "    \n",
        "    log_rdzg_norm = torch.logsumexp(torch.vstack((log_rd0z_top, log_rd1g_top[~ignored_indices])),0) #shape: n\n",
        "    #log_rdzg_norm1 = torch.logsumexp(torch.vstack((torch.logsumexp(log_rd0z_top, 0), torch.logsumexp(log_rd1g_top[~ignored_indices],0))),0)\n",
        "\n",
        "    log_rdz = (log_rd0z_top - log_rdzg_norm).T #shape: nxc\n",
        "    log_rdg = (log_rd1g_top - log_rdzg_norm).T #shape: nx(cxc')\n",
        "\n",
        "    assert(torch.sum(torch.sum(torch.exp(log_rdz),1) + torch.sum(torch.exp(log_rdg[:,~ignored_indices]),1)).round() == n_obs)\n",
        "\n",
        "    q1 = log_rd0z_top.T * log_rdz.exp(); q1[torch.isnan(q1)] = 0.0 #p(x,theta'|z=c,d=0)p(z=c,d=0|x,theta')\n",
        "    q2 = log_rd1g_top[~ignored_indices].T * log_rdg[:,~ignored_indices].exp(); q2[torch.isnan(q2)] = 0.0 #p(x,theta'|g=[c,c'],d=1)p(g=[c,c'],d=1|x,theta')\n",
        "    Q = torch.vstack((torch.logsumexp(q1, 1), torch.logsumexp(q2, 1))).logsumexp(0).mean() # mean(sum_d sum_z(q1) + sum_g(q2))\n",
        "\n",
        "    l1 = log_rd0z_top.T + log_rdz\n",
        "    l2 = log_rd1g_top[~ignored_indices].T + log_rdg[:,~ignored_indices]; #l2[torch.isinf(l2)] = -100\n",
        "    L1 = torch.vstack((torch.logsumexp(l1,1), torch.logsumexp(l2,1))).logsumexp(0).mean()\n",
        "    L = log_rdzg_norm.mean()\n",
        "\n",
        "    ## M-step:\n",
        "    rdz = torch.exp(log_rdz)\n",
        "    n_c, smu_c, sco_c, emu_c, eco_c = _estimate_mean_cov_t1v2(X, S, rdz)\n",
        "    pi_c = n_c / n_obs\n",
        "    pi_d0 = torch.sum(pi_c)\n",
        "\n",
        "    rdg = torch.exp(log_rdg).reshape(n_obs, n_clusters, n_clusters)\n",
        "    n_cc, smu_cc, sco_cc, emu_cc, eco_cc = _estimate_mean_cov_t2v2(X, S, rdg)\n",
        "    #n_cc = torch.sum(rdg, dim=0)\n",
        "    pi_cc = n_cc / n_obs\n",
        "    pi_d1 = torch.sum(torch.triu(pi_cc))\n",
        "\n",
        "    if abs(ls[-1] - L) < tot:\n",
        "      break\n",
        "\n",
        "    if pi_d1 < tot:\n",
        "      print(\"d1 is approaching 0! -> change a different initalization values\")\n",
        "      break\n",
        "\n",
        "    if iter > 1 and ls[-1] > L:\n",
        "      print(\"something is wrong!\")\n",
        "      break\n",
        "\n",
        "    print('Iteration', iter + 1, 'Q: ', Q, 'Likelihood: ', L, L1, 'd0: ', pi_d0)\n",
        "\n",
        "    qs.append(Q)\n",
        "    ls.append(L)\n",
        "    iter += 1\n",
        "\n",
        "  aic, bic = _ics(-L, n_obs, n_features, n_clusters)\n",
        "  print(aic)\n",
        "  #return llv[1:], aic, bic"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:147: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:149: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:150: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:153: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:155: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1 Q:  tensor(2.32263) Likelihood:  tensor(-23.73178) tensor(-23.73534) d0:  tensor(0.55624)\n",
            "Iteration 2 Q:  tensor(2.04002) Likelihood:  tensor(-3.65930) tensor(-4.42582) d0:  tensor(0.57221)\n",
            "Iteration 3 Q:  tensor(2.04654) Likelihood:  tensor(-3.62787) tensor(-4.39383) d0:  tensor(0.57254)\n",
            "tensor(134.74498)\n",
            "Iteration 1 Q:  tensor(2.07375) Likelihood:  tensor(-381.22543) tensor(-381.22931) d0:  tensor(0.57271)\n",
            "Iteration 2 Q:  tensor(1.97723) Likelihood:  tensor(-3.75020) tensor(-4.51585) d0:  tensor(0.57259)\n",
            "Iteration 3 Q:  tensor(2.04649) Likelihood:  tensor(-3.62746) tensor(-4.39341) d0:  tensor(0.57254)\n",
            "tensor(134.74500)\n",
            "Iteration 1 Q:  tensor(2.31144) Likelihood:  tensor(-30.87618) tensor(-30.87679) d0:  tensor(0.49210)\n",
            "Iteration 2 Q:  tensor(1.95540) Likelihood:  tensor(-4.34535) tensor(-5.25536) d0:  tensor(0.49199)\n",
            "tensor(133.30678)\n",
            "Iteration 1 Q:  tensor(1.96386) Likelihood:  tensor(-540.96759) tensor(-541.25555) d0:  tensor(0.96140)\n",
            "Iteration 2 Q:  tensor(2.17482) Likelihood:  tensor(-1.47858) tensor(-1.66162) d0:  tensor(0.95981)\n",
            "Iteration 3 Q:  tensor(2.23680) Likelihood:  tensor(-1.09018) tensor(-1.26005) d0:  tensor(0.95818)\n",
            "tensor(139.82893)\n",
            "Iteration 1 Q:  tensor(2.07840) Likelihood:  tensor(-80.54604) tensor(-80.54771) d0:  tensor(0.57675)\n",
            "Iteration 2 Q:  tensor(1.80174) Likelihood:  tensor(-5.05949) tensor(-5.82730) d0:  tensor(0.58072)\n",
            "Iteration 3 Q:  tensor(1.90394) Likelihood:  tensor(-4.12724) tensor(-4.87938) d0:  tensor(0.58070)\n",
            "Iteration 4 Q:  tensor(2.04532) Likelihood:  tensor(-3.75247) tensor(-4.50641) d0:  tensor(0.57987)\n",
            "tensor(134.49507)\n",
            "Iteration 1 Q:  tensor(2.22475) Likelihood:  tensor(-26.39438) tensor(-26.83019) d0:  tensor(0.49210)\n",
            "Iteration 2 Q:  tensor(1.88213) Likelihood:  tensor(-4.37441) tensor(-5.43340) d0:  tensor(0.49194)\n",
            "Iteration 3 Q:  tensor(1.89358) Likelihood:  tensor(-4.36927) tensor(-5.40270) d0:  tensor(0.49192)\n",
            "tensor(133.26440)\n",
            "Iteration 1 Q:  tensor(2.22195) Likelihood:  tensor(-32.80157) tensor(-32.99669) d0:  tensor(0.49210)\n",
            "Iteration 2 Q:  tensor(1.91701) Likelihood:  tensor(-4.36421) tensor(-5.35734) d0:  tensor(0.49184)\n",
            "tensor(133.26826)\n",
            "Iteration 1 Q:  tensor(2.16985) Likelihood:  tensor(-29.08889) tensor(-29.33583) d0:  tensor(0.49210)\n",
            "Iteration 2 Q:  tensor(1.89982) Likelihood:  tensor(-4.36913) tensor(-5.40550) d0:  tensor(0.49188)\n",
            "tensor(133.26108)\n",
            "Iteration 1 Q:  tensor(2.04216) Likelihood:  tensor(-190.27002) tensor(-190.33885) d0:  tensor(0.96630)\n",
            "Iteration 2 Q:  tensor(2.41858) Likelihood:  tensor(-0.76618) tensor(-0.85698) d0:  tensor(0.96614)\n",
            "Iteration 3 Q:  tensor(2.47896) Likelihood:  tensor(0.01533) tensor(-0.05150) d0:  tensor(0.96324)\n",
            "Iteration 4 Q:  tensor(2.57971) Likelihood:  tensor(0.48480) tensor(0.41036) d0:  tensor(0.95904)\n",
            "Iteration 5 Q:  tensor(2.62094) Likelihood:  tensor(0.56000) tensor(0.47983) d0:  tensor(0.95592)\n",
            "Iteration 6 Q:  tensor(2.63475) Likelihood:  tensor(0.58058) tensor(0.49438) d0:  tensor(0.95227)\n",
            "Iteration 7 Q:  tensor(2.65440) Likelihood:  tensor(0.61278) tensor(0.52406) d0:  tensor(0.95056)\n",
            "Iteration 8 Q:  tensor(2.66251) Likelihood:  tensor(0.61822) tensor(0.52949) d0:  tensor(0.95048)\n",
            "tensor(143.23633)\n",
            "Iteration 1 Q:  tensor(2.20077) Likelihood:  tensor(-20.09318) tensor(-20.09331) d0:  tensor(0.49210)\n",
            "Iteration 2 Q:  tensor(1.95540) Likelihood:  tensor(-4.34535) tensor(-5.25536) d0:  tensor(0.49199)\n",
            "tensor(133.30678)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2ZIZh6TM0uh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWOSJovvM2VJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsGljvhmM2gJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FT4pOnyGAi6x",
        "outputId": "6b7b62c5-eaec-4d3b-d633-45242133e589"
      },
      "source": [
        "## emu_c, eco_c, smu_c, sco_c and\n",
        "## emu_cc, eco_cc, smu_cc, sco_cc updates \n",
        "## divide by 2\n",
        "\n",
        "for i in range(10):\n",
        "  \n",
        "  hps, ngps, gps = initialization(n_clusters, X, S)\n",
        "  pi_d0 = hps[0]\n",
        "  pi_d1 = 1-hps[0]\n",
        "  pi_c = hps[1]\n",
        "  pi_cc = hps[2]\n",
        "\n",
        "  emu_c = ngps[0]\n",
        "  eco_c = ngps[1]\n",
        "  smu_c = ngps[2]\n",
        "  sco_c = ngps[3]\n",
        "\n",
        "  emu_cc = ngps[4]\n",
        "  eco_cc = ngps[5]\n",
        "  smu_cc = ngps[6]\n",
        "  sco_cc = ngps[7]\n",
        "\n",
        "  iter = 0\n",
        "  qs = [0.0]\n",
        "  ls = [0.0]\n",
        "\n",
        "  #print(emu_c)\n",
        "  while iter < n_epochs:\n",
        "\n",
        "    log_lambda0_pi = torch.log(pi_d0) + torch.log(pi_c)\n",
        "    log_lambda1_tau = torch.log(1 - pi_d0) + torch.log(pi_cc)\n",
        "\n",
        "    ### E-step:\n",
        "    log_rd0z_top = torch.zeros(n_clusters, n_obs)\n",
        "    log_rd1g_top = torch.zeros(n_clusters, n_clusters, n_obs)\n",
        "\n",
        "    for j in range(n_clusters):\n",
        "  \n",
        "      el0 = D.MultivariateNormal(emu_c[j], eco_c[j]).log_prob(X.float())\n",
        "      sl0 = D.Normal(smu_c[j], sco_c[j]).log_prob(S.float())\n",
        "      log_rd0z_top[j] = log_lambda0_pi[j] + el0 + sl0\n",
        "    \n",
        "      for k in range(n_clusters):\n",
        "        if torch.isnan(log_lambda1_tau[j,k]): #lower triangular nan\n",
        "          log_rd1g_top[j,k] = float(\"NaN\")\n",
        "        else:\n",
        "          el1 = D.MultivariateNormal(emu_cc[j,k]/2, eco_cc[j,k]/2).log_prob(X.float())\n",
        "          sl1 = D.Normal(smu_cc[j,k], sco_cc[j,k]).log_prob(S.float())\n",
        "          log_rd1g_top[j,k] = log_lambda1_tau[j,k] + el1 + sl1\n",
        "\n",
        "    log_rd1g_top = log_rd1g_top.reshape(n_clusters * n_clusters, n_obs) #shape: (cxc')xn\n",
        "\n",
        "    ignored_indices = torch.isnan(torch.logsumexp(log_rd1g_top, 1))\n",
        "    assert(ignored_indices.sum() == (n_clusters * n_clusters - n_clusters) / 2)\n",
        "    \n",
        "    log_rdzg_norm = torch.logsumexp(torch.vstack((log_rd0z_top, log_rd1g_top[~ignored_indices])),0) #shape: n\n",
        "    #log_rdzg_norm1 = torch.logsumexp(torch.vstack((torch.logsumexp(log_rd0z_top, 0), torch.logsumexp(log_rd1g_top[~ignored_indices],0))),0)\n",
        "\n",
        "    log_rdz = (log_rd0z_top - log_rdzg_norm).T #shape: nxc\n",
        "    log_rdg = (log_rd1g_top - log_rdzg_norm).T #shape: nx(cxc')\n",
        "\n",
        "    assert(torch.sum(torch.sum(torch.exp(log_rdz),1) + torch.sum(torch.exp(log_rdg[:,~ignored_indices]),1)).round() == n_obs)\n",
        "\n",
        "    q1 = log_rd0z_top.T * log_rdz.exp(); q1[torch.isnan(q1)] = 0.0 #p(x,theta'|z=c,d=0)p(z=c,d=0|x,theta')\n",
        "    q2 = log_rd1g_top[~ignored_indices].T * log_rdg[:,~ignored_indices].exp(); q2[torch.isnan(q2)] = 0.0 #p(x,theta'|g=[c,c'],d=1)p(g=[c,c'],d=1|x,theta')\n",
        "    Q = torch.vstack((torch.logsumexp(q1, 1), torch.logsumexp(q2, 1))).logsumexp(0).mean() # mean(sum_d sum_z(q1) + sum_g(q2))\n",
        "\n",
        "    l1 = log_rd0z_top.T + log_rdz\n",
        "    l2 = log_rd1g_top[~ignored_indices].T + log_rdg[:,~ignored_indices]; #l2[torch.isinf(l2)] = -100\n",
        "    L1 = torch.vstack((torch.logsumexp(l1,1), torch.logsumexp(l2,1))).logsumexp(0).mean()\n",
        "    L = log_rdzg_norm.mean()\n",
        "\n",
        "    ## M-step:\n",
        "    rdz = torch.exp(log_rdz)\n",
        "    n_c, smu_c, sco_c, emu_c, eco_c = _estimate_mean_cov_t1v2(X, S, rdz)\n",
        "    pi_c = n_c / n_obs\n",
        "    pi_d0 = torch.sum(pi_c)\n",
        "\n",
        "    rdg = torch.exp(log_rdg).reshape(n_obs, n_clusters, n_clusters)\n",
        "    n_cc, smu_cc, sco_cc, emu_cc, eco_cc = _estimate_mean_cov_t2v2(X, S, rdg)\n",
        "    #n_cc = torch.sum(rdg, dim=0)\n",
        "    pi_cc = n_cc / n_obs\n",
        "    pi_d1 = torch.sum(torch.triu(pi_cc))\n",
        "\n",
        "    if abs(ls[-1] - L) < tot:\n",
        "      break\n",
        "\n",
        "    if pi_d1 < tot:\n",
        "      print(\"d1 is approaching 0! -> change a different initalization values\")\n",
        "      break\n",
        "\n",
        "    if iter > 1 and ls[-1] > L:\n",
        "      print(\"something is wrong!\")\n",
        "      break\n",
        "\n",
        "    print('Iteration', iter + 1, 'Q: ', Q, 'Likelihood: ', L, L1, 'd0: ', pi_d0)\n",
        "\n",
        "    qs.append(Q)\n",
        "    ls.append(L)\n",
        "    iter += 1\n",
        "\n",
        "  aic, bic = _ics(-L, n_obs, n_features, n_clusters)\n",
        "  print(aic)\n",
        "  #return llv[1:], aic, bic"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:147: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:149: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:150: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:153: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:155: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1 Q:  tensor(2.09831) Likelihood:  tensor(-30.75802) tensor(-30.76001) d0:  tensor(0.49210)\n",
            "Iteration 2 Q:  tensor(1.90042) Likelihood:  tensor(-6.85950) tensor(-7.76970) d0:  tensor(0.49193)\n",
            "tensor(128.27779)\n",
            "Iteration 1 Q:  tensor(2.07925) Likelihood:  tensor(-103.69984) tensor(-103.70016) d0:  tensor(0.88055)\n",
            "Iteration 2 Q:  tensor(2.50820) Likelihood:  tensor(-0.94709) tensor(-1.16144) d0:  tensor(0.88044)\n",
            "tensor(140.10538)\n",
            "Iteration 1 Q:  tensor(2.18318) Likelihood:  tensor(-55.65486) tensor(-55.89309) d0:  tensor(0.87206)\n",
            "Iteration 2 Q:  tensor(2.47057) Likelihood:  tensor(-1.04297) tensor(-1.36639) d0:  tensor(0.87374)\n",
            "Iteration 3 Q:  tensor(2.46491) Likelihood:  tensor(-1.01748) tensor(-1.33276) d0:  tensor(0.87702)\n",
            "Iteration 4 Q:  tensor(2.45194) Likelihood:  tensor(-0.97931) tensor(-1.28871) d0:  tensor(0.87964)\n",
            "Iteration 5 Q:  tensor(2.44162) Likelihood:  tensor(-0.96790) tensor(-1.27530) d0:  tensor(0.88023)\n",
            "tensor(140.06624)\n",
            "Iteration 1 Q:  tensor(2.24045) Likelihood:  tensor(-52.08810) tensor(-52.08869) d0:  tensor(0.87322)\n",
            "Iteration 2 Q:  tensor(2.53761) Likelihood:  tensor(-1.01124) tensor(-1.23497) d0:  tensor(0.87552)\n",
            "Iteration 3 Q:  tensor(2.52795) Likelihood:  tensor(-0.97375) tensor(-1.19103) d0:  tensor(0.87896)\n",
            "Iteration 4 Q:  tensor(2.51341) Likelihood:  tensor(-0.95009) tensor(-1.16509) d0:  tensor(0.88014)\n",
            "tensor(140.10472)\n",
            "Iteration 1 Q:  tensor(2.07939) Likelihood:  tensor(-275.48679) tensor(-275.48679) d0:  tensor(0.96150)\n",
            "Iteration 2 Q:  tensor(2.26132) Likelihood:  tensor(-1.78414) tensor(-1.85513) d0:  tensor(0.96050)\n",
            "tensor(138.43193)\n",
            "Iteration 1 Q:  tensor(2.23716) Likelihood:  tensor(-395.26624) tensor(-395.45731) d0:  tensor(0.96630)\n",
            "Iteration 2 Q:  tensor(2.18332) Likelihood:  tensor(-1.83611) tensor(-2.05787) d0:  tensor(0.96359)\n",
            "Iteration 3 Q:  tensor(2.24053) Likelihood:  tensor(-1.75106) tensor(-1.93209) d0:  tensor(0.96231)\n",
            "Iteration 4 Q:  tensor(2.27241) Likelihood:  tensor(-1.69263) tensor(-1.85346) d0:  tensor(0.96158)\n",
            "Iteration 5 Q:  tensor(2.29398) Likelihood:  tensor(-1.64836) tensor(-1.78873) d0:  tensor(0.96080)\n",
            "Iteration 6 Q:  tensor(2.30737) Likelihood:  tensor(-1.61606) tensor(-1.73797) d0:  tensor(0.96054)\n",
            "Iteration 7 Q:  tensor(2.31515) Likelihood:  tensor(-1.59856) tensor(-1.70432) d0:  tensor(0.96053)\n",
            "Iteration 8 Q:  tensor(2.32006) Likelihood:  tensor(-1.58878) tensor(-1.68134) d0:  tensor(0.96053)\n",
            "Iteration 9 Q:  tensor(2.32296) Likelihood:  tensor(-1.58263) tensor(-1.66627) d0:  tensor(0.96053)\n",
            "tensor(138.84171)\n",
            "Iteration 1 Q:  tensor(2.23529) Likelihood:  tensor(-200.49039) tensor(-200.59549) d0:  tensor(0.87610)\n",
            "Iteration 2 Q:  tensor(2.46541) Likelihood:  tensor(-0.91986) tensor(-1.23996) d0:  tensor(0.88036)\n",
            "Iteration 3 Q:  tensor(2.47398) Likelihood:  tensor(-0.90419) tensor(-1.21292) d0:  tensor(0.88037)\n",
            "Iteration 4 Q:  tensor(2.47745) Likelihood:  tensor(-0.89876) tensor(-1.20449) d0:  tensor(0.88038)\n",
            "Iteration 5 Q:  tensor(2.47993) Likelihood:  tensor(-0.89299) tensor(-1.19869) d0:  tensor(0.88039)\n",
            "Iteration 6 Q:  tensor(2.48292) Likelihood:  tensor(-0.88623) tensor(-1.19219) d0:  tensor(0.88040)\n",
            "Iteration 7 Q:  tensor(2.48712) Likelihood:  tensor(-0.87865) tensor(-1.18352) d0:  tensor(0.88041)\n",
            "Iteration 8 Q:  tensor(2.49278) Likelihood:  tensor(-0.86964) tensor(-1.17250) d0:  tensor(0.88043)\n",
            "Iteration 9 Q:  tensor(2.49979) Likelihood:  tensor(-0.85854) tensor(-1.15879) d0:  tensor(0.88045)\n",
            "Iteration 10 Q:  tensor(2.50864) Likelihood:  tensor(-0.84622) tensor(-1.14152) d0:  tensor(0.88047)\n",
            "Iteration 11 Q:  tensor(2.51856) Likelihood:  tensor(-0.83218) tensor(-1.12009) d0:  tensor(0.88049)\n",
            "Iteration 12 Q:  tensor(2.52947) Likelihood:  tensor(-0.81481) tensor(-1.09308) d0:  tensor(0.88054)\n",
            "Iteration 13 Q:  tensor(2.54098) Likelihood:  tensor(-0.79564) tensor(-1.06033) d0:  tensor(0.88059)\n",
            "Iteration 14 Q:  tensor(2.55159) Likelihood:  tensor(-0.77544) tensor(-1.02403) d0:  tensor(0.88065)\n",
            "Iteration 15 Q:  tensor(2.55942) Likelihood:  tensor(-0.75813) tensor(-0.99209) d0:  tensor(0.88065)\n",
            "Iteration 16 Q:  tensor(2.56346) Likelihood:  tensor(-0.74742) tensor(-0.97116) d0:  tensor(0.88066)\n",
            "Iteration 17 Q:  tensor(2.56509) Likelihood:  tensor(-0.74175) tensor(-0.96020) d0:  tensor(0.88066)\n",
            "tensor(140.52280)\n",
            "Iteration 1 Q:  tensor(2.20031) Likelihood:  tensor(-90.83612) tensor(-90.83698) d0:  tensor(0.49210)\n",
            "Iteration 2 Q:  tensor(1.90043) Likelihood:  tensor(-6.85992) tensor(-7.77004) d0:  tensor(0.49193)\n",
            "tensor(128.27779)\n",
            "Iteration 1 Q:  tensor(2.24364) Likelihood:  tensor(-100.81669) tensor(-100.99179) d0:  tensor(0.49210)\n",
            "Iteration 2 Q:  tensor(1.81878) Likelihood:  tensor(-6.89294) tensor(-7.96878) d0:  tensor(0.49181)\n",
            "tensor(128.21980)\n",
            "Iteration 1 Q:  tensor(1.97558) Likelihood:  tensor(-216.89075) tensor(-217.26140) d0:  tensor(0.49210)\n",
            "Iteration 2 Q:  tensor(1.85690) Likelihood:  tensor(-6.87691) tensor(-7.88500) d0:  tensor(0.49185)\n",
            "tensor(128.24562)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAJiCvvtQ8KS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38Xj1TlTQ6-H"
      },
      "source": [
        "## choose between (emu_c/eco_c, smu_c, sco_c) and (emu_c/eco_c, smu_c/sco_c, emu_cc/eco_cc, smu_cc/sco_cc) models (no divide by 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaJz_ZS4jeSZ"
      },
      "source": [
        "## (emu_c/eco_c, smu_c/sco_c, emu_cc/eco_cc, smu_cc/sco_cc) updates (no good)\n",
        "for i in range(10):\n",
        "  \n",
        "  hps, ngps, gps = initialization(n_clusters, X, S)\n",
        "  pi_d0 = hps[0]\n",
        "  pi_d1 = 1-hps[0]\n",
        "  pi_c = hps[1]\n",
        "  pi_cc = hps[2]\n",
        "\n",
        "  opt = optim.Adam(gps)\n",
        "\n",
        "  iter = 0\n",
        "  qs = [0.0]\n",
        "  ls = [0.0]\n",
        "\n",
        "  #print(emu_c)\n",
        "  while iter < n_epochs:\n",
        "\n",
        "    log_lambda0_pi = torch.log(pi_d0) + torch.log(pi_c)\n",
        "    log_lambda1_tau = torch.log(1 - pi_d0) + torch.log(pi_cc)\n",
        "\n",
        "    ### E-step:\n",
        "    log_rd0z_top = torch.zeros(n_clusters, n_obs)\n",
        "    log_rd1g_top = torch.zeros(n_clusters, n_clusters, n_obs)\n",
        "\n",
        "    for j in range(n_clusters):\n",
        "  \n",
        "      el0 = D.MultivariateNormal(gps[0][j], gps[1][j]).log_prob(X.float())\n",
        "      sl0 = D.Normal(gps[2][j], gps[3][j]).log_prob(S.float())\n",
        "      log_rd0z_top[j] = log_lambda0_pi[j] + el0 + sl0\n",
        "    \n",
        "      for k in range(n_clusters):\n",
        "        if torch.isnan(log_lambda1_tau[j,k]): #lower triangular nan\n",
        "          log_rd1g_top[j,k] = float(\"NaN\")\n",
        "        else:\n",
        "          el1 = D.MultivariateNormal(gps[4][j,k], gps[5][j,k]).log_prob(X.float())\n",
        "          sl1 = D.Normal(gps[6][j,k], gps[7][j,k]).log_prob(S.float())\n",
        "          log_rd1g_top[j,k] = log_lambda1_tau[j,k] + el1 + sl1\n",
        "\n",
        "    log_rd1g_top = log_rd1g_top.reshape(n_clusters * n_clusters, n_obs) #shape: (cxc')xn\n",
        "\n",
        "    ignored_indices = torch.isnan(torch.logsumexp(log_rd1g_top, 1))\n",
        "    assert(ignored_indices.sum() == (n_clusters * n_clusters - n_clusters) / 2)\n",
        "    \n",
        "    log_rdzg_norm = torch.logsumexp(torch.vstack((log_rd0z_top, log_rd1g_top[~ignored_indices])),0) #shape: n\n",
        "    #log_rdzg_norm1 = torch.logsumexp(torch.vstack((torch.logsumexp(log_rd0z_top, 0), torch.logsumexp(log_rd1g_top[~ignored_indices],0))),0)\n",
        "\n",
        "    loss = -log_rdzg_norm.mean()\n",
        "\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "      log_rdz = (log_rd0z_top - log_rdzg_norm).T #shape: nxc\n",
        "      log_rdg = (log_rd1g_top - log_rdzg_norm).T #shape: nx(cxc')\n",
        "\n",
        "      assert(torch.sum(torch.sum(torch.exp(log_rdz),1) + torch.sum(torch.exp(log_rdg[:,~ignored_indices]),1)).round() == n_obs)\n",
        "\n",
        "      q1 = log_rd0z_top.T * log_rdz.exp(); q1[torch.isnan(q1)] = 0.0 #p(x,theta'|z=c,d=0)p(z=c,d=0|x,theta')\n",
        "      q2 = log_rd1g_top[~ignored_indices].T * log_rdg[:,~ignored_indices].exp(); q2[torch.isnan(q2)] = 0.0 #p(x,theta'|g=[c,c'],d=1)p(g=[c,c'],d=1|x,theta')\n",
        "      Q = torch.vstack((torch.logsumexp(q1, 1), torch.logsumexp(q2, 1))).logsumexp(0).mean() # mean(sum_d sum_z(q1) + sum_g(q2))\n",
        "\n",
        "      l1 = log_rd0z_top.T + log_rdz\n",
        "      l2 = log_rd1g_top[~ignored_indices].T + log_rdg[:,~ignored_indices]; #l2[torch.isinf(l2)] = -100\n",
        "      L1 = torch.vstack((torch.logsumexp(l1,1), torch.logsumexp(l2,1))).logsumexp(0).mean()\n",
        "\n",
        "      ## M-step:\n",
        "      rdz = torch.exp(log_rdz)\n",
        "      #n_c, smu_c, sco_c, emu_c, eco_c = _estimate_mean_cov_t1v2(X, S, rdz)\n",
        "      n_c = torch.sum(rdz, dim=0)\n",
        "      pi_c = n_c / n_obs\n",
        "      pi_d0 = torch.sum(pi_c)\n",
        "\n",
        "      rdg = torch.exp(log_rdg).reshape(n_obs, n_clusters, n_clusters)\n",
        "      #n_cc, emu_cc, eco_cc = _estimate_mean_cov_t2v2(X, rdg)\n",
        "      n_cc = torch.sum(rdg, dim=0)\n",
        "      pi_cc = n_cc / n_obs\n",
        "      pi_d1 = torch.sum(torch.triu(pi_cc))\n",
        "\n",
        "    if abs(ls[-1] + loss) < tot:\n",
        "      break\n",
        "\n",
        "    if pi_d1 < tot:\n",
        "      print(\"d1 is approaching 0! -> change a different initalization values\")\n",
        "      break\n",
        "\n",
        "    if iter > 1 and ls[-1] > -loss:\n",
        "      print(\"something is wrong!\")\n",
        "      break\n",
        "\n",
        "    qs.append(Q)\n",
        "    ls.append(-loss)\n",
        "    iter += 1\n",
        "  \n",
        "  print('Iteration', iter + 1, 'Q: ', Q, 'Likelihood: ', -loss, L1, 'd0: ', pi_d0)\n",
        "  aic, bic = _ics(loss, n_obs, n_features, n_clusters)\n",
        "  print(bic)\n",
        "  #return llv[1:], aic, bic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQQillaWKJ1n",
        "outputId": "3292ae14-627b-49f6-968c-f33dde1e6d39"
      },
      "source": [
        "## emu_c, eco_c, smu_c, sco_c updates\n",
        "for i in range(10):\n",
        "  \n",
        "  hps, ngps, gps = initialization(n_clusters, X, S)\n",
        "  pi_d0 = hps[0]\n",
        "  pi_d1 = 1-hps[0]\n",
        "  pi_c = hps[1]\n",
        "  pi_cc = hps[2]\n",
        "\n",
        "  opt = optim.Adam(gps[:4])\n",
        "\n",
        "  iter = 0\n",
        "  qs = [0.0]\n",
        "  ls = [0.0]\n",
        "\n",
        "  #print(emu_c)\n",
        "  while iter < n_epochs:\n",
        "\n",
        "    log_lambda0_pi = torch.log(pi_d0) + torch.log(pi_c)\n",
        "    log_lambda1_tau = torch.log(1 - pi_d0) + torch.log(pi_cc)\n",
        "\n",
        "    ### E-step:\n",
        "    log_rd0z_top = torch.zeros(n_clusters, n_obs)\n",
        "    log_rd1g_top = torch.zeros(n_clusters, n_clusters, n_obs)\n",
        "\n",
        "    for j in range(n_clusters):\n",
        "  \n",
        "      el0 = D.MultivariateNormal(gps[0][j], gps[1][j]).log_prob(X.float())\n",
        "      sl0 = D.Normal(gps[2][j], gps[3][j]).log_prob(S.float())\n",
        "      log_rd0z_top[j] = log_lambda0_pi[j] + el0 + sl0\n",
        "    \n",
        "      for k in range(n_clusters):\n",
        "        if torch.isnan(log_lambda1_tau[j,k]): #lower triangular nan\n",
        "          log_rd1g_top[j,k] = float(\"NaN\")\n",
        "        else:\n",
        "          el1 = D.MultivariateNormal((gps[0][j] + gps[0][k]), (gps[1][j] + gps[1][k])).log_prob(X.float())\n",
        "          sl1 = D.Normal(gps[2][j] + gps[2][k], gps[3][j] + gps[3][k]).log_prob(S.float())\n",
        "          log_rd1g_top[j,k] = log_lambda1_tau[j,k] + el1 + sl1\n",
        "\n",
        "    log_rd1g_top = log_rd1g_top.reshape(n_clusters * n_clusters, n_obs) #shape: (cxc')xn\n",
        "\n",
        "    ignored_indices = torch.isnan(torch.logsumexp(log_rd1g_top, 1))\n",
        "    assert(ignored_indices.sum() == (n_clusters * n_clusters - n_clusters) / 2)\n",
        "    \n",
        "    log_rdzg_norm = torch.logsumexp(torch.vstack((log_rd0z_top, log_rd1g_top[~ignored_indices])),0) #shape: n\n",
        "    #log_rdzg_norm1 = torch.logsumexp(torch.vstack((torch.logsumexp(log_rd0z_top, 0), torch.logsumexp(log_rd1g_top[~ignored_indices],0))),0)\n",
        "\n",
        "    loss = -log_rdzg_norm.mean()\n",
        "\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "      log_rdz = (log_rd0z_top - log_rdzg_norm).T #shape: nxc\n",
        "      log_rdg = (log_rd1g_top - log_rdzg_norm).T #shape: nx(cxc')\n",
        "\n",
        "      assert(torch.sum(torch.sum(torch.exp(log_rdz),1) + torch.sum(torch.exp(log_rdg[:,~ignored_indices]),1)).round() == n_obs)\n",
        "\n",
        "      q1 = log_rd0z_top.T * log_rdz.exp(); q1[torch.isnan(q1)] = 0.0 #p(x,theta'|z=c,d=0)p(z=c,d=0|x,theta')\n",
        "      q2 = log_rd1g_top[~ignored_indices].T * log_rdg[:,~ignored_indices].exp(); q2[torch.isnan(q2)] = 0.0 #p(x,theta'|g=[c,c'],d=1)p(g=[c,c'],d=1|x,theta')\n",
        "      Q = torch.vstack((torch.logsumexp(q1, 1), torch.logsumexp(q2, 1))).logsumexp(0).mean() # mean(sum_d sum_z(q1) + sum_g(q2))\n",
        "\n",
        "      l1 = log_rd0z_top.T + log_rdz\n",
        "      l2 = log_rd1g_top[~ignored_indices].T + log_rdg[:,~ignored_indices]; #l2[torch.isinf(l2)] = -100\n",
        "      L1 = torch.vstack((torch.logsumexp(l1,1), torch.logsumexp(l2,1))).logsumexp(0).mean()\n",
        "\n",
        "      ## M-step:\n",
        "      rdz = torch.exp(log_rdz)\n",
        "      #n_c, smu_c, sco_c, emu_c, eco_c = _estimate_mean_cov_t1v2(X, S, rdz)\n",
        "      n_c = torch.sum(rdz, dim=0)\n",
        "      pi_c = n_c / n_obs\n",
        "      pi_d0 = torch.sum(pi_c)\n",
        "\n",
        "      rdg = torch.exp(log_rdg).reshape(n_obs, n_clusters, n_clusters)\n",
        "      #n_cc, emu_cc, eco_cc = _estimate_mean_cov_t2v2(X, rdg)\n",
        "      n_cc = torch.sum(rdg, dim=0)\n",
        "      pi_cc = n_cc / n_obs\n",
        "      pi_d1 = torch.sum(torch.triu(pi_cc))\n",
        "\n",
        "    if abs(ls[-1] + loss) < tot:\n",
        "      break\n",
        "\n",
        "    if pi_d1 < tot:\n",
        "      print(\"d1 is approaching 0! -> change a different initalization values\")\n",
        "      break\n",
        "\n",
        "    if iter > 1 and ls[-1] > -loss:\n",
        "      print(\"something is wrong!\")\n",
        "      break\n",
        "\n",
        "    qs.append(Q)\n",
        "    ls.append(-loss)\n",
        "    iter += 1\n",
        "  \n",
        "  print('Iteration', iter + 1, 'Q: ', Q, 'Likelihood: ', -loss, L1, 'd0: ', pi_d0)\n",
        "  aic, bic = _ics(loss, n_obs, n_features, n_clusters)\n",
        "  print(bic)\n",
        "  #return llv[1:], aic, bic"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:147: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:149: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:150: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:153: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:155: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 295 Q:  tensor(2.1940) Likelihood:  tensor(-2.4868, grad_fn=<NegBackward>) tensor(-2.4869) d0:  tensor(0.8239)\n",
            "tensor(648.9605, grad_fn=<AddBackward0>)\n",
            "Iteration 307 Q:  tensor(2.2197) Likelihood:  tensor(-2.4646, grad_fn=<NegBackward>) tensor(-2.4646) d0:  tensor(0.8239)\n",
            "tensor(649.0049, grad_fn=<AddBackward0>)\n",
            "Iteration 572 Q:  tensor(2.4264) Likelihood:  tensor(-3.7113, grad_fn=<NegBackward>) tensor(-3.7113) d0:  tensor(0.8239)\n",
            "tensor(646.5116, grad_fn=<AddBackward0>)\n",
            "Iteration 370 Q:  tensor(2.2932) Likelihood:  tensor(-3.4288, grad_fn=<NegBackward>) tensor(-3.4355) d0:  tensor(0.8239)\n",
            "tensor(647.0765, grad_fn=<AddBackward0>)\n",
            "Iteration 344 Q:  tensor(2.2814) Likelihood:  tensor(-2.0582, grad_fn=<NegBackward>) tensor(-2.0591) d0:  tensor(0.8239)\n",
            "tensor(649.8177, grad_fn=<AddBackward0>)\n",
            "Iteration 329 Q:  tensor(2.1498) Likelihood:  tensor(-1.9770, grad_fn=<NegBackward>) tensor(-1.9778) d0:  tensor(0.8243)\n",
            "tensor(649.9802, grad_fn=<AddBackward0>)\n",
            "Iteration 302 Q:  tensor(2.2300) Likelihood:  tensor(-2.4640, grad_fn=<NegBackward>) tensor(-2.4640) d0:  tensor(0.8239)\n",
            "tensor(649.0060, grad_fn=<AddBackward0>)\n",
            "Iteration 561 Q:  tensor(2.1857) Likelihood:  tensor(-3.9774, grad_fn=<NegBackward>) tensor(-3.9789) d0:  tensor(0.8267)\n",
            "tensor(645.9792, grad_fn=<AddBackward0>)\n",
            "Iteration 163 Q:  tensor(2.4701) Likelihood:  tensor(-1.0612, grad_fn=<NegBackward>) tensor(-1.0612) d0:  tensor(0.8239)\n",
            "tensor(651.8118, grad_fn=<AddBackward0>)\n",
            "Iteration 526 Q:  tensor(2.5979) Likelihood:  tensor(-2.4305, grad_fn=<NegBackward>) tensor(-2.4423) d0:  tensor(0.9609)\n",
            "tensor(649.0732, grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDdJ5yYyKKBQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "MtwBn4NIh8tF",
        "outputId": "378e9728-f7ba-45cb-dd11-5b11d97e968d"
      },
      "source": [
        "plt.plot(ls[1:])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd1d7708390>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "ZvV8Yb2MFAVd",
        "outputId": "b9e838e5-1284-4c87-fff2-0b4954ecdba1"
      },
      "source": [
        "plt.plot(qs[1:])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd1d765a290>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPNSf7p5lYvn",
        "outputId": "02dc09ea-bb88-40d7-c236-30e600d7c361"
      },
      "source": [
        "pi_d0"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9609)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRW7REX0lapk",
        "outputId": "6d454e63-de8b-441e-d603-cb5a215dcd35"
      },
      "source": [
        "pi_c"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2178, 0.1370, 0.6061])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKGDsPfolb56",
        "outputId": "6b87f56b-c8ed-4b60-ecb2-53e054d67d45"
      },
      "source": [
        "pi_cc"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0068, 0.0058, 0.0000],\n",
              "        [   nan, 0.0085, 0.0042],\n",
              "        [   nan,    nan, 0.0138]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NwI6txaOlHE"
      },
      "source": [
        "0.0063\n",
        "0.0078\n",
        "0.0087\n",
        "0.0101\n",
        "0.005\n",
        "0.0085\n",
        "0.2135\n",
        "0.6104\n",
        "0.1297\n",
        "464"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icxD0qd8ldXD",
        "outputId": "7d17acef-66b6-40da-8469-6daa4515df2c"
      },
      "source": [
        "gps[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.8606,  6.5523],\n",
              "        [ 8.8333, 10.9417],\n",
              "        [ 6.0039,  7.0137]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6nUNm_Bllm7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fd5563b-0225-4a82-ccb8-6a332ca28796"
      },
      "source": [
        "gps[2]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4717, 0.7301, 0.6000], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}