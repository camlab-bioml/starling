{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "non_function_version_gmm_em_expressions_cell_sizes",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPlHHTQrXpAucdMlzWnfDLR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camlab-bioml/2021_IMC_Jett/blob/main/non_function_version_gmm_em_expressions_cell_sizes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le7qDLI9FM6G"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.distributions as D\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.datasets as datasets"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SahaX89nFlkZ",
        "outputId": "1dfeb3e1-728e-4572-fc4a-792f89d39a10"
      },
      "source": [
        "## create data\n",
        "\n",
        "n_clusters = 3\n",
        "n_features = 2\n",
        "\n",
        "## ground true expressions ##\n",
        "true_expression_means = torch.tensor([\n",
        "    [1, 2],\n",
        "    [4, 3],\n",
        "    [7, 9]\n",
        "])\n",
        "\n",
        "true_expression_covs = torch.tensor([\n",
        "    [[.1, 0], [0, .1]],\n",
        "    [[.1, 0], [0, .1]],\n",
        "    [[.1, 0], [0, .1]]\n",
        "])\n",
        "\n",
        "true_size_means = torch.tensor([.4, .5, .6])\n",
        "\n",
        "print(true_size_means)\n",
        "\n",
        "true_size_stds = torch.tensor([.1, .05, .01])\n",
        "true_size_stds\n",
        "\n",
        "## other ground true for generating data ##\n",
        "d_ws = torch.tensor([.95, .05])\n",
        "z_ws = torch.tensor([1 / 4, 1 / 2, 1 / 4])\n",
        "g_ws = torch.tensor([0.0667, 0.1333, 0.2000, 0.1000, 0.2667, 0.2333])\n",
        "\n",
        "N = 10000\n",
        "gs = np.sum(np.random.choice(len(d_ws), size = N, p = d_ws))\n",
        "zs = N - gs\n",
        "\n",
        "## simulate data\n",
        "x = np.zeros((zs, n_features+4))\n",
        "for i in range(zs):\n",
        "  z = np.random.choice(n_clusters, size = 1, p = z_ws)[0]\n",
        "  x[i] = np.append(np.random.multivariate_normal(true_expression_means[z], true_expression_covs[z]), [np.random.normal(true_size_means[z], true_size_stds[z]), 0, z, z+6])\n",
        "  \n",
        "xxx = np.zeros((gs, n_features+4))\n",
        "for i in range(gs):\n",
        "\n",
        "  g = np.random.choice(6, size = 1, p = g_ws)[0]\n",
        "    \n",
        "  if g == 0:\n",
        "    idx = [0,0]\n",
        "  elif g == 1:\n",
        "    idx = [0,1]\n",
        "  elif g == 2:\n",
        "    idx = [0,2]\n",
        "  elif g == 3:\n",
        "    idx = [1,1]\n",
        "  elif g == 4:\n",
        "    idx = [1,2]\n",
        "  else:\n",
        "    idx = [2,2]\n",
        "  \n",
        "  xxx[i] = np.append(np.random.multivariate_normal( (true_expression_means[idx[0]] + true_expression_means[idx[1]]), (true_expression_covs[idx[0]] + true_expression_covs[idx[1]]) ),\n",
        "                     [np.random.normal( (true_size_means[idx[0]] + true_size_means[idx[1]]), (true_size_stds[idx[0]] + true_size_stds[idx[1]]) ), 1, g, g])\n",
        "  \n",
        "xx = np.append(x, xxx).reshape(N,6)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.4000, 0.5000, 0.6000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgXMyC6UFqiB"
      },
      "source": [
        "## initialization\n",
        "\n",
        "n_obs = N\n",
        "n_features = 2\n",
        "n_clusters = 3\n",
        "\n",
        "#torch.manual_seed(42)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "emu_c = torch.tensor([\n",
        "    [3, 1], # 1 2\n",
        "    [5, 4], # 4 3\n",
        "    [8, 7]\n",
        "]) #, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "smu_c = torch.tensor([.45, .55, .65]) #, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "eco_c = 0.1 * torch.eye(n_features).tile(n_clusters, 1, 1)\n",
        "sco_c = 0.1 * torch.ones(n_clusters, dtype=torch.float)\n",
        "\n",
        "smu_cc = torch.zeros(n_clusters, n_clusters)\n",
        "sco_cc = torch.zeros(n_clusters, n_clusters)\n",
        "\n",
        "emu_cc = torch.zeros(n_clusters, n_clusters, n_features)\n",
        "eco_cc = torch.zeros(n_clusters, n_clusters, n_features, n_features)\n",
        "\n",
        "for j in range(n_clusters):\n",
        "  for k in range(n_clusters):\n",
        "    smu_cc[j,k] = smu_c[j] + smu_c[k]\n",
        "    sco_cc[j,k] = sco_c[j] + sco_c[k]\n",
        "\n",
        "    emu_cc[j,k] = (emu_c[j] + emu_c[k])\n",
        "    eco_cc[j,k] = (eco_c[j] + eco_c[k])\n",
        "\n",
        "#smu_c = torch.tensor(smu_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "#sco_c = torch.tensor(sco_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "#emu_c = torch.tensor(emu_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "#eco_c = torch.tensor(eco_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "#smu_cc = torch.tensor(smu_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "#sco_cc = torch.tensor(sco_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "#emu_cc = torch.tensor(emu_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "#eco_cc = torch.tensor(eco_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "####\n",
        "\n",
        "pi_d0 = torch.tensor(0.9)\n",
        "\n",
        "pi_c = torch.empty(n_clusters).fill_(1. / (n_clusters))\n",
        "\n",
        "pi_cc = torch.triu(torch.ones(n_clusters, n_clusters))\n",
        "pi_cc = pi_cc / torch.sum(pi_cc)\n",
        "pi_cc[pi_cc == 0] = float('NaN')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eAowDrqCJqP"
      },
      "source": [
        "## helper function\n",
        "def _estimate_mean_cov_t1v2(X, S, r_ij, reg=1e-6):\n",
        "\n",
        "  #n, p = X.shape\n",
        "  #n, c = r_ij.shape\n",
        "\n",
        "  smut = torch.zeros(n_clusters)\n",
        "  scot = torch.zeros(n_clusters)\n",
        "\n",
        "  emut = torch.zeros(n_clusters, n_features)\n",
        "  ecot = torch.zeros(n_clusters, n_features, n_features)\n",
        "\n",
        "  n_c = torch.sum(r_ij, dim=0) + reg # (c)\n",
        "\n",
        "  for j in range(n_clusters):\n",
        "    e_n = torch.round(n_c[j])\n",
        "    idx = r_ij[:,j].argsort()[-e_n.int():]\n",
        "    smut[j] = torch.mean(S[idx], 0)\n",
        "    emut[j] = torch.mean(X[idx], 0)\n",
        "    if e_n > 1:\n",
        "      ecot[j] = torch.tensor(np.cov(X[idx].T, ddof=0)) + reg * torch.eye(n_features)\n",
        "      scot[j] = torch.std(S[idx]) + reg\n",
        "    else:\n",
        "      ecot[j] = reg * torch.eye(n_features)\n",
        "      scot[j] = reg\n",
        "  return n_c, smut, scot, emut, ecot\n",
        "\n",
        "\n",
        "def _estimate_mean_cov_t2v2(X, S, r_ijk, reg=1e-6):\n",
        "\n",
        "  #n, p = X.shape\n",
        "  #n, c, c = r_ijk.shape\n",
        "\n",
        "  smut = torch.zeros(n_clusters, n_clusters)\n",
        "  scot = torch.zeros(n_clusters, n_clusters)\n",
        "\n",
        "  emut = torch.zeros(n_clusters, n_clusters, n_features)\n",
        "  ecot = torch.zeros(n_clusters, n_clusters, n_features, n_features)\n",
        "\n",
        "  n_cc = torch.sum(r_ijk, dim=0) + reg # (cxc)\n",
        "\n",
        "  for j in range(n_clusters):\n",
        "    for k in range(n_clusters):\n",
        "      if not torch.isnan(n_cc[j,k]):\n",
        "        e_n = torch.round(n_cc[j,k])\n",
        "        idx = r_ijk[:,j,k].argsort()[-e_n.int():]\n",
        "        smut[j,k] = torch.mean(S[idx], 0)\n",
        "        emut[j,k] = torch.mean(X[idx], 0)\n",
        "        if e_n > 1:\n",
        "          scot[j,k] = torch.std(S[idx]) + reg\n",
        "          ecot[j,k] = torch.tensor(np.cov(X[idx].T, ddof=0)) + reg * torch.eye(n_features)\n",
        "        else:\n",
        "          scot[j,k] = reg\n",
        "          ecot[j,k] = reg * torch.eye(n_features)\n",
        "  return n_cc, smut, scot, emut, ecot\n",
        "\n",
        "def _ics(logL, n_obs, n_features, n_clusters): #, n, p, c\n",
        "  params = ( (((n_features * n_features) - n_features)/2 + 2 * n_features + 3) * (((n_clusters * n_clusters) - n_clusters)/2 + 2 * n_clusters) ) - 1\n",
        "  return 2 * (params - logL), -2 * logL + params * np.log(n_obs)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "061Liyd8cnl9",
        "outputId": "6470e1be-5266-47ec-8a55-932d585312b4"
      },
      "source": [
        "X = torch.tensor(xx[:,:2])\n",
        "S = torch.tensor(xx[:,2])\n",
        "\n",
        "## analytical version\n",
        "n_epochs = 1000\n",
        "tot = 1e-4\n",
        "iter = 0\n",
        "llv = [0.0]\n",
        "\n",
        "log_pi_d0 = torch.log(pi_d0)\n",
        "log_pi_d1 = torch.log(1 - pi_d0)\n",
        "\n",
        "log_pi_c = torch.log(pi_c)\n",
        "log_pi_cc = torch.log(pi_cc)\n",
        "\n",
        "while iter < n_epochs:\n",
        "\n",
        "  ### E-step:\n",
        "  log_post_top0 = torch.zeros(n_clusters, n_obs)\n",
        "  log_post_top1 = torch.zeros(n_clusters, n_clusters, n_obs)\n",
        "\n",
        "  for j in range(n_clusters):\n",
        "  \n",
        "    el0 = D.MultivariateNormal(emu_c[j], eco_c[j]).log_prob(X.float())\n",
        "    sl0 = D.Normal(smu_c[j], sco_c[j]).log_prob(S.float())\n",
        "    log_post_top0[j] = log_pi_d0 + log_pi_c[j] + el0 + sl0\n",
        "    \n",
        "    for k in range(n_clusters):\n",
        "      el1 = D.MultivariateNormal((emu_c[j] + emu_c[k])/2, (eco_c[j] + eco_c[k])/2).log_prob(X.float())\n",
        "      #https://stats.stackexchange.com/questions/99363/mean-of-covariance-matrices\n",
        "      #https://stats.stackexchange.com/questions/214174/calculating-the-covariance-matrix-for-the-mean-of-variables\n",
        "      sl1 = D.Normal(smu_c[j] + smu_c[k], sco_c[j] + sco_c[k]).log_prob(S.float())\n",
        "      \n",
        "      if torch.isnan(pi_cc[j,k]): #lower triangular nan\n",
        "        log_post_top1[j,k] = float(\"-Inf\")\n",
        "      else:\n",
        "        log_post_top1[j,k] = log_pi_d1 + log_pi_cc[j,k] + el1 + sl1\n",
        "\n",
        "  log_post_bot0 = torch.logsumexp(log_post_top0, 0) #n\n",
        "  log_post_z = (log_post_top0 - log_post_bot0).T #nxc (rjk)\n",
        "\n",
        "  log_post_top1 = log_post_top1.reshape(n_clusters * n_clusters, n_obs) #reshape\n",
        "  log_post_bot1 = torch.logsumexp(log_post_top1, 0) #n\n",
        "  log_post_g = (log_post_top1 - log_post_bot1).T #nxc (rijk)\n",
        "\n",
        "  log_post_tot = torch.logsumexp(torch.vstack((log_post_top0, log_post_top1)),0)\n",
        "  loss = -torch.mean(log_post_tot)\n",
        "\n",
        "  log_post_d0 = log_post_bot0 - log_post_tot\n",
        "  log_post_d1 = log_post_bot1 - log_post_tot\n",
        "\n",
        "  log_post_dz = log_post_d0[:,None] + log_post_z\n",
        "  log_post_dg = log_post_d1[:,None] + log_post_g\n",
        "\n",
        "  ### M-step:\n",
        "\n",
        "  log_pi_d0 = torch.logsumexp(log_post_d0, 0) - torch.log(torch.tensor(n_obs))\n",
        "\n",
        "  r_ij = torch.exp(log_post_dz)\n",
        "  n_c, smu_c, sco_c, emu_c, eco_c = _estimate_mean_cov_t1v2(X, S, r_ij)\n",
        "  log_pi_c = torch.log(n_c) - torch.log(torch.tensor(n_obs))\n",
        "\n",
        "  indx = []\n",
        "  for j in range(log_post_dg.shape[1]):\n",
        "    if torch.sum(torch.isinf(log_post_dg[:,j])) == log_post_dg.shape[0]:\n",
        "      indx.append(j)\n",
        "  log_post_dg[:,indx] = float('NaN')\n",
        "\n",
        "  r_ijk = torch.exp(log_post_dg).reshape(n_obs, n_clusters, n_clusters)\n",
        "  n_cc, smu_cc, sco_cc, emu_cc, eco_cc = _estimate_mean_cov_t2v2(X, S, r_ijk)\n",
        "  log_pi_cc = torch.log(n_cc) - torch.log(torch.tensor(n_obs))\n",
        "      \n",
        "  print('Iteration', iter + 1, 'Likelihood: ', -loss, torch.exp(log_pi_d0))\n",
        "\n",
        "  if abs(llv[-1] + loss) < tot:\n",
        "    break\n",
        "      \n",
        "  llv.append(-loss)\n",
        "  iter += 1\n",
        "  \n",
        "aic, bic = _ics(-loss, n_obs, n_features, n_clusters)\n",
        "#return llv[1:], aic, bic"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1 Likelihood:  tensor(-27.5427) tensor(0.6436)\n",
            "Iteration 2 Likelihood:  tensor(-6.5293) tensor(0.9461)\n",
            "Iteration 3 Likelihood:  tensor(-8.8737) tensor(0.9517)\n",
            "Iteration 4 Likelihood:  tensor(-10.2177) tensor(0.9517)\n",
            "Iteration 5 Likelihood:  tensor(-10.4964) tensor(0.9517)\n",
            "Iteration 6 Likelihood:  tensor(-10.4964) tensor(0.9517)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeUaa87994Qe",
        "outputId": "7e2e335e-506f-42ff-b7bb-d71851b7bdc8"
      },
      "source": [
        "torch.exp(log_pi_d0)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9517)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnq7dmHa95z5",
        "outputId": "43a71e8f-d87e-4ced-92c1-00d569d7dc89"
      },
      "source": [
        "torch.exp(log_pi_c)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2290, 0.4848, 0.2380])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQiHlomD966G",
        "outputId": "71b674ba-d323-4d88-ef43-ee7c3653cabe"
      },
      "source": [
        "torch.exp(log_pi_cc)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.5287e-06, 2.8217e-03, 4.9191e-03],\n",
              "        [       nan, 1.4747e-04, 5.7032e-03],\n",
              "        [       nan,        nan, 3.4661e-02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSTJaXEpspFa",
        "outputId": "aee06a62-b966-4ad9-dc8f-9d9558a5a90f"
      },
      "source": [
        "emu_c"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9948, 2.0004],\n",
              "        [4.0021, 2.9967],\n",
              "        [7.0200, 9.0043]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "553jOLO1-CbW",
        "outputId": "ba4a0e91-5bd2-4de6-da3c-1068680b2f32"
      },
      "source": [
        "smu_c"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3986, 0.5006, 0.5999])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45i0Dl8E-CmU",
        "outputId": "7c429fc1-0c11-4643-b768-c1b61dec738c"
      },
      "source": [
        "bic"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(674.9269)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD4APkuUFWXp"
      },
      "source": [
        "## analytical versio (no loop)\n",
        "\n",
        "log_pi_d0 = torch.log(pi_d0)\n",
        "log_pi_d1 = torch.log(1 - pi_d0)\n",
        "\n",
        "log_pi_c = torch.log(pi_c)\n",
        "log_pi_cc = torch.log(pi_cc)\n",
        "\n",
        "### E-step:\n",
        "log_post_top0 = torch.zeros(n_clusters, n_obs)\n",
        "log_post_top1 = torch.zeros(n_clusters, n_clusters, n_obs)\n",
        "\n",
        "for j in range(n_clusters):\n",
        "  \n",
        "  el0 = D.MultivariateNormal(emu_c[j], eco_c[j]).log_prob(X.float())\n",
        "  sl0 = D.Normal(smu_c[j], sco_c[j]).log_prob(S.float())\n",
        "  log_post_top0[j] = log_pi_d0 + log_pi_c[j] + el0 + sl0\n",
        "    \n",
        "  for k in range(n_clusters):\n",
        "    el1 = D.MultivariateNormal((emu_c[j] + emu_c[k])/2, (eco_c[j] + eco_c[k])/2).log_prob(X.float())\n",
        "    #https://stats.stackexchange.com/questions/99363/mean-of-covariance-matrices\n",
        "    #https://stats.stackexchange.com/questions/214174/calculating-the-covariance-matrix-for-the-mean-of-variables\n",
        "    sl1 = D.Normal(smu_c[j] + smu_c[k], sco_c[j] + sco_c[k]).log_prob(S.float())\n",
        "      \n",
        "    #el1 = D.MultivariateNormal(emu_cc[j,k]/2, eco_cc[j,k]/2).log_prob(X.float())\n",
        "    #sl1 = D.Normal(smu_cc[j,k], sco_cc[j,k]).log_prob(S.float())\n",
        "\n",
        "    if torch.isnan(pi_cc[j,k]): #lower triangular nan\n",
        "      log_post_top1[j,k] = float(\"-Inf\")\n",
        "    else:\n",
        "      log_post_top1[j,k] = log_pi_d1 + log_pi_cc[j,k] + el1 + sl1\n",
        "\n",
        "log_post_bot0 = torch.logsumexp(log_post_top0, 0) #n\n",
        "log_post_z = (log_post_top0 - log_post_bot0).T #nxc (rjk)\n",
        "\n",
        "log_post_top1 = log_post_top1.reshape(n_clusters * n_clusters, n_obs) #reshape\n",
        "log_post_bot1 = torch.logsumexp(log_post_top1, 0) #n\n",
        "log_post_g = (log_post_top1 - log_post_bot1).T #nxc (rijk)\n",
        "\n",
        "'''\n",
        "bot = torch.log(torch.exp(log_post_bot0) + torch.exp(log_post_bot1))\n",
        "indices = bot == float(\"-inf\")\n",
        "if torch.sum(indices) > 0:\n",
        "  ## look at which log prob is smaller\n",
        "  ind = log_post_bot0[indices] < log_post_bot1[indices]  \n",
        "  log_post_bot1[indices][ind] = 0\n",
        "  log_post_bot0[indices][~ind] = 0\n",
        "  bot[indices] = 0\n",
        "loss = -torch.mean(bot)\n",
        "  \n",
        "log_post_d0 = log_post_bot0 - bot\n",
        "log_post_d1 = log_post_bot1 - bot\n",
        "'''\n",
        "\n",
        "log_post_tot = torch.logsumexp(torch.vstack((log_post_top0, log_post_top1)),0)\n",
        "loss = -torch.mean(log_post_tot)\n",
        "\n",
        "log_post_d0 = log_post_bot0 - log_post_tot\n",
        "log_post_d1 = log_post_bot1 - log_post_tot\n",
        "\n",
        "log_post_dz = log_post_d0[:,None] + log_post_z\n",
        "log_post_dg = log_post_d1[:,None] + log_post_g\n",
        "\n",
        "### M-step:\n",
        "\n",
        "#pi_d0 = torch.sum(torch.exp(log_post_d0)) / n_obs # one value\n",
        "log_pi_d0 = torch.logsumexp(log_post_d0, 0) - torch.log(torch.tensor(n_obs))\n",
        "\n",
        "r_ij = torch.exp(log_post_dz)\n",
        "n_c, smu_c, sco_c, emu_c, eco_c = _estimate_mean_cov_t1v2(X, S, r_ij)\n",
        "#pi_c = n_c / n_obs # c values\n",
        "log_pi_c = torch.log(n_c) - torch.log(torch.tensor(n_obs))\n",
        "\n",
        "indx = []\n",
        "for j in range(log_post_dg.shape[1]):\n",
        "  if torch.sum(torch.isinf(log_post_dg[:,j])) == log_post_dg.shape[0]:\n",
        "    indx.append(j)\n",
        "log_post_dg[:,indx] = float('NaN')\n",
        "\n",
        "r_ijk = torch.exp(log_post_dg).reshape(n_obs, n_clusters, n_clusters)\n",
        "n_cc, smu_cc, sco_cc, emu_cc, eco_cc = _estimate_mean_cov_t2v2(X, S, r_ijk)\n",
        "#pi_cc = n_cc / n_obs  # cxc matrix  \n",
        "log_pi_cc = torch.log(n_cc) - torch.log(torch.tensor(n_obs))\n",
        "      \n",
        "print('Iteration', iter + 1, 'Likelihood: ', -loss, torch.exp(log_pi_d0))\n",
        "\n",
        "#if abs(llv[-1] + loss) < tot:\n",
        "#  break\n",
        "      \n",
        "llv.append(-loss)\n",
        "iter += 1\n",
        "\n",
        "aic, bic = _ics(-loss, n_obs, n_features, n_clusters)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR8CQz6dYAFi"
      },
      "source": [
        ""
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V475ZRjpYCGg"
      },
      "source": [
        ""
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DKnOGXTYUoH"
      },
      "source": [
        ""
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSkMWrg7SdPM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO_fckWqjAU1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTJ2xUj8Sdlm",
        "outputId": "8e036efe-2355-4928-be8a-8f7211182c9c"
      },
      "source": [
        "## initialization\n",
        "\n",
        "n_obs = N\n",
        "n_features = 2\n",
        "n_clusters = 3\n",
        "\n",
        "#torch.manual_seed(42)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "emu_c = torch.tensor([\n",
        "    [2, 3], # 1 2\n",
        "    [3, 5], # 4 3\n",
        "    [7, 8]\n",
        "], dtype=torch.float) #, requires_grad=True, , device=device)\n",
        "\n",
        "smu_c = torch.tensor([.45, .55, .65], dtype=torch.float) #, requires_grad=True,  device=device)\n",
        "\n",
        "eco_c = 0.1 * torch.eye(n_features).tile(n_clusters, 1, 1)\n",
        "sco_c = 0.1 * torch.ones(n_clusters, dtype=torch.float)\n",
        "\n",
        "smu_cc = torch.zeros(n_clusters, n_clusters, dtype=torch.float)\n",
        "sco_cc = torch.zeros(n_clusters, n_clusters, dtype=torch.float)\n",
        "\n",
        "emu_cc = torch.zeros(n_clusters, n_clusters, n_features, dtype=torch.float)\n",
        "eco_cc = torch.zeros(n_clusters, n_clusters, n_features, n_features, dtype=torch.float)\n",
        "\n",
        "for j in range(n_clusters):\n",
        "  for k in range(n_clusters):\n",
        "    smu_cc[j,k] = smu_c[j] + smu_c[k]\n",
        "    sco_cc[j,k] = sco_c[j] + sco_c[k]\n",
        "\n",
        "    emu_cc[j,k] = (emu_c[j] + emu_c[k])\n",
        "    eco_cc[j,k] = (eco_c[j] + eco_c[k])\n",
        "\n",
        "smu_c = torch.tensor(smu_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "sco_c = torch.tensor(sco_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "      \n",
        "emu_c = torch.tensor(emu_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "eco_c = torch.tensor(eco_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "      \n",
        "smu_cc = torch.tensor(smu_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "sco_cc = torch.tensor(sco_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "      \n",
        "emu_cc = torch.tensor(emu_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "eco_cc = torch.tensor(eco_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "      \n",
        "####\n",
        "\n",
        "pi_d0 = torch.tensor(0.9)\n",
        "\n",
        "pi_c = torch.empty(n_clusters).fill_(1. / (n_clusters))\n",
        "\n",
        "pi_cc = torch.triu(torch.ones(n_clusters, n_clusters))\n",
        "pi_cc = pi_cc / torch.sum(pi_cc)\n",
        "pi_cc[pi_cc == 0] = float('NaN')\n",
        "\n",
        "def _ics(logL, n_obs, n_features, n_clusters): #, n, p, c\n",
        "  params = ( (((n_features * n_features) - n_features)/2 + 2 * n_features + 3) * (((n_clusters * n_clusters) - n_clusters)/2 + 2 * n_clusters) ) - 1\n",
        "  return 2 * (params - logL), -2 * logL + params * np.log(n_obs)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3GfEy3Klpol",
        "outputId": "7ecf5d45-4c5e-41b1-a1fc-0d2d1d3b2f2d"
      },
      "source": [
        "## torch.optim version\n",
        "\n",
        "X = torch.tensor(xx[:,:2])\n",
        "S = torch.tensor(xx[:,2])\n",
        "\n",
        "#parameters = [emu_c, eco_c, smu_c, sco_c]\n",
        "#parameters = [emu_cc, eco_cc, smu_cc, sco_cc]\n",
        "parameters = [emu_c, eco_c, smu_c, sco_c, emu_cc, eco_cc, smu_cc, sco_cc]\n",
        "#opt = optim.SGD(parameters, lr=0.01)\n",
        "opt = optim.Adam(parameters)\n",
        "\n",
        "tot = 1e-4\n",
        "llv = [0.0]\n",
        "\n",
        "log_pi_d0 = torch.log(pi_d0)\n",
        "log_pi_d1 = torch.log(1-pi_d0)\n",
        "log_pi_c = torch.log(pi_c)\n",
        "log_pi_cc = torch.log(pi_cc)\n",
        "\n",
        "iter = 0\n",
        "n_epochs = 500\n",
        "while iter < n_epochs:\n",
        "\n",
        "  log_post_top0 = torch.zeros(n_clusters, n_obs)\n",
        "  log_post_top1 = torch.zeros(n_clusters, n_clusters, n_obs)\n",
        "\n",
        "  for j in range(n_clusters):  \n",
        "    el0 = D.MultivariateNormal(emu_c[j], eco_c[j]).log_prob(X.float())\n",
        "    sl0 = D.Normal(smu_c[j], sco_c[j]).log_prob(S.float())\n",
        "    log_post_top0[j] = log_pi_d0 + log_pi_c[j] + el0 + sl0\n",
        "\n",
        "    for k in range(n_clusters):\n",
        "      el1 = D.MultivariateNormal(emu_cc[j,k]/2, eco_cc[j,k]/2).log_prob(X.float())\n",
        "      sl1 = D.Normal(smu_cc[j,k], sco_cc[j,k]).log_prob(S.float())\n",
        "            \n",
        "      if torch.isnan(pi_cc[j,k]): #lower triangular nan\n",
        "        log_post_top1[j,k] = float(\"-Inf\")\n",
        "      else:\n",
        "        log_post_top1[j,k] = log_pi_d1 + log_pi_cc[j,k] + el1 + sl1\n",
        "\n",
        "  log_post_bot0 = torch.logsumexp(log_post_top0, 0) #n\n",
        "  \n",
        "  log_post_top1 = log_post_top1.reshape(n_clusters * n_clusters, n_obs) #reshape\n",
        "  log_post_bot1 = torch.logsumexp(log_post_top1, 0) #n\n",
        "\n",
        "  log_post_tot = torch.logsumexp(torch.vstack((log_post_top0, log_post_top1)),0)\n",
        "  loss = -torch.mean(log_post_tot)\n",
        "\n",
        "  #print(emu_c)\n",
        "  opt.zero_grad()\n",
        "  loss.backward()\n",
        "  opt.step()\n",
        "  #print(emu_cc)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    parameters[0].clamp_(tot)\n",
        "    ##parameters[1].clamp_(tot)\n",
        "    parameters[2].clamp_(tot)\n",
        "    parameters[3].clamp_(tot)\n",
        "    parameters[4].clamp_(tot)\n",
        "    ##parameters[5].clamp_(tot)\n",
        "    parameters[6].clamp_(tot)\n",
        "    parameters[7].clamp_(tot)\n",
        "\n",
        "    eco_c += torch.eye(n_features) * tot\n",
        "    eco_cc += torch.eye(n_features) * tot\n",
        "    \n",
        "    log_post_d0 = log_post_bot0 - log_post_tot\n",
        "    log_post_d1 = log_post_bot1 - log_post_tot\n",
        "\n",
        "    log_post_z = (log_post_top0 - log_post_bot0).T #nxc (rjk)\n",
        "    log_post_g = (log_post_top1 - log_post_bot1).T #nxc (rijk)\n",
        "\n",
        "    log_post_dz = log_post_d0[:,None] + log_post_z\n",
        "    log_post_dg = log_post_d1[:,None] + log_post_g\n",
        "\n",
        "    log_n_c = torch.logsumexp(log_post_dz, 0)\n",
        "    log_pi_c = log_n_c - torch.log(torch.tensor(n_obs))\n",
        "\n",
        "    log_n_cc = torch.logsumexp(log_post_dg, 0).reshape(n_clusters, n_clusters)\n",
        "    log_pi_cc = log_n_cc - torch.log(torch.tensor(n_obs))  # cxc matrix\n",
        "\n",
        "    log_pi_d0 = torch.logsumexp(log_post_d0, 0) - torch.log(torch.tensor(n_obs))\n",
        "\n",
        "  print('Iteration', iter + 1, 'Likelihood: ', -loss, torch.exp(log_pi_d0))\n",
        "\n",
        "  if abs(llv[-1] + loss) < tot:\n",
        "    break\n",
        "      \n",
        "  llv.append(-loss)\n",
        "  iter += 1\n",
        "\n",
        "aic, bic = _ics(-loss, n_obs, n_features, n_clusters)\n",
        "\n",
        "#print(epoch, pi_d0, loss)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1 Likelihood:  tensor(-24.5268, grad_fn=<NegBackward>) tensor(0.9099)\n",
            "Iteration 2 Likelihood:  tensor(-24.1994, grad_fn=<NegBackward>) tensor(0.9477)\n",
            "Iteration 3 Likelihood:  tensor(-23.8127, grad_fn=<NegBackward>) tensor(0.9685)\n",
            "Iteration 4 Likelihood:  tensor(-23.4580, grad_fn=<NegBackward>) tensor(0.9765)\n",
            "Iteration 5 Likelihood:  tensor(-23.1163, grad_fn=<NegBackward>) tensor(0.9810)\n",
            "Iteration 6 Likelihood:  tensor(-22.7787, grad_fn=<NegBackward>) tensor(0.9844)\n",
            "Iteration 7 Likelihood:  tensor(-22.4448, grad_fn=<NegBackward>) tensor(0.9867)\n",
            "Iteration 8 Likelihood:  tensor(-22.1177, grad_fn=<NegBackward>) tensor(0.9881)\n",
            "Iteration 9 Likelihood:  tensor(-21.7992, grad_fn=<NegBackward>) tensor(0.9889)\n",
            "Iteration 10 Likelihood:  tensor(-21.4896, grad_fn=<NegBackward>) tensor(0.9895)\n",
            "Iteration 11 Likelihood:  tensor(-21.1891, grad_fn=<NegBackward>) tensor(0.9899)\n",
            "Iteration 12 Likelihood:  tensor(-20.8977, grad_fn=<NegBackward>) tensor(0.9903)\n",
            "Iteration 13 Likelihood:  tensor(-20.6151, grad_fn=<NegBackward>) tensor(0.9905)\n",
            "Iteration 14 Likelihood:  tensor(-20.3410, grad_fn=<NegBackward>) tensor(0.9908)\n",
            "Iteration 15 Likelihood:  tensor(-20.0754, grad_fn=<NegBackward>) tensor(0.9909)\n",
            "Iteration 16 Likelihood:  tensor(-19.8179, grad_fn=<NegBackward>) tensor(0.9911)\n",
            "Iteration 17 Likelihood:  tensor(-19.5683, grad_fn=<NegBackward>) tensor(0.9912)\n",
            "Iteration 18 Likelihood:  tensor(-19.3262, grad_fn=<NegBackward>) tensor(0.9913)\n",
            "Iteration 19 Likelihood:  tensor(-19.0914, grad_fn=<NegBackward>) tensor(0.9914)\n",
            "Iteration 20 Likelihood:  tensor(-18.8637, grad_fn=<NegBackward>) tensor(0.9914)\n",
            "Iteration 21 Likelihood:  tensor(-18.6428, grad_fn=<NegBackward>) tensor(0.9915)\n",
            "Iteration 22 Likelihood:  tensor(-18.4284, grad_fn=<NegBackward>) tensor(0.9916)\n",
            "Iteration 23 Likelihood:  tensor(-18.2204, grad_fn=<NegBackward>) tensor(0.9916)\n",
            "Iteration 24 Likelihood:  tensor(-18.0186, grad_fn=<NegBackward>) tensor(0.9917)\n",
            "Iteration 25 Likelihood:  tensor(-17.8227, grad_fn=<NegBackward>) tensor(0.9917)\n",
            "Iteration 26 Likelihood:  tensor(-17.6325, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 27 Likelihood:  tensor(-17.4478, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 28 Likelihood:  tensor(-17.2684, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 29 Likelihood:  tensor(-17.0941, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 30 Likelihood:  tensor(-16.9248, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 31 Likelihood:  tensor(-16.7601, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 32 Likelihood:  tensor(-16.5999, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 33 Likelihood:  tensor(-16.4441, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 34 Likelihood:  tensor(-16.2924, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 35 Likelihood:  tensor(-16.1448, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 36 Likelihood:  tensor(-16.0009, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 37 Likelihood:  tensor(-15.8608, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 38 Likelihood:  tensor(-15.7242, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 39 Likelihood:  tensor(-15.5910, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 40 Likelihood:  tensor(-15.4612, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 41 Likelihood:  tensor(-15.3346, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 42 Likelihood:  tensor(-15.2110, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 43 Likelihood:  tensor(-15.0905, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 44 Likelihood:  tensor(-14.9729, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 45 Likelihood:  tensor(-14.8582, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 46 Likelihood:  tensor(-14.7462, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 47 Likelihood:  tensor(-14.6369, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 48 Likelihood:  tensor(-14.5301, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 49 Likelihood:  tensor(-14.4259, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 50 Likelihood:  tensor(-14.3240, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 51 Likelihood:  tensor(-14.2245, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 52 Likelihood:  tensor(-14.1270, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 53 Likelihood:  tensor(-14.0317, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 54 Likelihood:  tensor(-13.9382, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 55 Likelihood:  tensor(-13.8465, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 56 Likelihood:  tensor(-13.7565, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 57 Likelihood:  tensor(-13.6682, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 58 Likelihood:  tensor(-13.5813, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 59 Likelihood:  tensor(-13.4960, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 60 Likelihood:  tensor(-13.4122, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 61 Likelihood:  tensor(-13.3298, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 62 Likelihood:  tensor(-13.2488, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 63 Likelihood:  tensor(-13.1692, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 64 Likelihood:  tensor(-13.0911, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 65 Likelihood:  tensor(-13.0143, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 66 Likelihood:  tensor(-12.9388, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 67 Likelihood:  tensor(-12.8647, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 68 Likelihood:  tensor(-12.7918, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 69 Likelihood:  tensor(-12.7201, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 70 Likelihood:  tensor(-12.6495, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 71 Likelihood:  tensor(-12.5801, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 72 Likelihood:  tensor(-12.5118, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 73 Likelihood:  tensor(-12.4444, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 74 Likelihood:  tensor(-12.3781, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 75 Likelihood:  tensor(-12.3128, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 76 Likelihood:  tensor(-12.2484, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 77 Likelihood:  tensor(-12.1850, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 78 Likelihood:  tensor(-12.1224, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 79 Likelihood:  tensor(-12.0607, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 80 Likelihood:  tensor(-11.9999, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 81 Likelihood:  tensor(-11.9399, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 82 Likelihood:  tensor(-11.8808, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 83 Likelihood:  tensor(-11.8224, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 84 Likelihood:  tensor(-11.7648, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 85 Likelihood:  tensor(-11.7080, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 86 Likelihood:  tensor(-11.6520, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 87 Likelihood:  tensor(-11.5967, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 88 Likelihood:  tensor(-11.5421, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 89 Likelihood:  tensor(-11.4882, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 90 Likelihood:  tensor(-11.4350, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 91 Likelihood:  tensor(-11.3824, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 92 Likelihood:  tensor(-11.3305, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 93 Likelihood:  tensor(-11.2793, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 94 Likelihood:  tensor(-11.2286, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 95 Likelihood:  tensor(-11.1786, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 96 Likelihood:  tensor(-11.1291, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 97 Likelihood:  tensor(-11.0803, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 98 Likelihood:  tensor(-11.0320, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 99 Likelihood:  tensor(-10.9843, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 100 Likelihood:  tensor(-10.9371, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 101 Likelihood:  tensor(-10.8904, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 102 Likelihood:  tensor(-10.8443, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 103 Likelihood:  tensor(-10.7988, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 104 Likelihood:  tensor(-10.7537, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 105 Likelihood:  tensor(-10.7091, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 106 Likelihood:  tensor(-10.6651, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 107 Likelihood:  tensor(-10.6215, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 108 Likelihood:  tensor(-10.5784, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 109 Likelihood:  tensor(-10.5357, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 110 Likelihood:  tensor(-10.4935, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 111 Likelihood:  tensor(-10.4518, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 112 Likelihood:  tensor(-10.4105, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 113 Likelihood:  tensor(-10.3696, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 114 Likelihood:  tensor(-10.3292, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 115 Likelihood:  tensor(-10.2892, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 116 Likelihood:  tensor(-10.2496, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 117 Likelihood:  tensor(-10.2104, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 118 Likelihood:  tensor(-10.1716, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 119 Likelihood:  tensor(-10.1332, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 120 Likelihood:  tensor(-10.0952, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 121 Likelihood:  tensor(-10.0576, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 122 Likelihood:  tensor(-10.0203, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 123 Likelihood:  tensor(-9.9835, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 124 Likelihood:  tensor(-9.9470, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 125 Likelihood:  tensor(-9.9108, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 126 Likelihood:  tensor(-9.8750, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 127 Likelihood:  tensor(-9.8396, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 128 Likelihood:  tensor(-9.8045, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 129 Likelihood:  tensor(-9.7698, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 130 Likelihood:  tensor(-9.7354, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 131 Likelihood:  tensor(-9.7013, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 132 Likelihood:  tensor(-9.6675, grad_fn=<NegBackward>) tensor(0.9920)\n",
            "Iteration 133 Likelihood:  tensor(-9.6341, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 134 Likelihood:  tensor(-9.6010, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 135 Likelihood:  tensor(-9.5681, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 136 Likelihood:  tensor(-9.5356, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 137 Likelihood:  tensor(-9.5035, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 138 Likelihood:  tensor(-9.4716, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 139 Likelihood:  tensor(-9.4400, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 140 Likelihood:  tensor(-9.4087, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 141 Likelihood:  tensor(-9.3776, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 142 Likelihood:  tensor(-9.3469, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 143 Likelihood:  tensor(-9.3165, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 144 Likelihood:  tensor(-9.2863, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 145 Likelihood:  tensor(-9.2564, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 146 Likelihood:  tensor(-9.2267, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 147 Likelihood:  tensor(-9.1974, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 148 Likelihood:  tensor(-9.1682, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 149 Likelihood:  tensor(-9.1394, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 150 Likelihood:  tensor(-9.1108, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 151 Likelihood:  tensor(-9.0824, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 152 Likelihood:  tensor(-9.0543, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 153 Likelihood:  tensor(-9.0265, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 154 Likelihood:  tensor(-8.9989, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 155 Likelihood:  tensor(-8.9715, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 156 Likelihood:  tensor(-8.9444, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 157 Likelihood:  tensor(-8.9175, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 158 Likelihood:  tensor(-8.8908, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 159 Likelihood:  tensor(-8.8643, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 160 Likelihood:  tensor(-8.8381, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 161 Likelihood:  tensor(-8.8121, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 162 Likelihood:  tensor(-8.7863, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 163 Likelihood:  tensor(-8.7607, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 164 Likelihood:  tensor(-8.7354, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 165 Likelihood:  tensor(-8.7102, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 166 Likelihood:  tensor(-8.6853, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 167 Likelihood:  tensor(-8.6605, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 168 Likelihood:  tensor(-8.6360, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 169 Likelihood:  tensor(-8.6116, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 170 Likelihood:  tensor(-8.5875, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 171 Likelihood:  tensor(-8.5635, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 172 Likelihood:  tensor(-8.5398, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 173 Likelihood:  tensor(-8.5162, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 174 Likelihood:  tensor(-8.4928, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 175 Likelihood:  tensor(-8.4696, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 176 Likelihood:  tensor(-8.4466, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 177 Likelihood:  tensor(-8.4238, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 178 Likelihood:  tensor(-8.4011, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 179 Likelihood:  tensor(-8.3786, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 180 Likelihood:  tensor(-8.3563, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 181 Likelihood:  tensor(-8.3342, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 182 Likelihood:  tensor(-8.3122, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 183 Likelihood:  tensor(-8.2904, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 184 Likelihood:  tensor(-8.2688, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 185 Likelihood:  tensor(-8.2473, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 186 Likelihood:  tensor(-8.2260, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 187 Likelihood:  tensor(-8.2049, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 188 Likelihood:  tensor(-8.1839, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 189 Likelihood:  tensor(-8.1631, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 190 Likelihood:  tensor(-8.1424, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 191 Likelihood:  tensor(-8.1219, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 192 Likelihood:  tensor(-8.1015, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 193 Likelihood:  tensor(-8.0813, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 194 Likelihood:  tensor(-8.0612, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 195 Likelihood:  tensor(-8.0413, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 196 Likelihood:  tensor(-8.0215, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 197 Likelihood:  tensor(-8.0019, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 198 Likelihood:  tensor(-7.9824, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 199 Likelihood:  tensor(-7.9630, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 200 Likelihood:  tensor(-7.9438, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 201 Likelihood:  tensor(-7.9247, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 202 Likelihood:  tensor(-7.9057, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 203 Likelihood:  tensor(-7.8869, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 204 Likelihood:  tensor(-7.8682, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 205 Likelihood:  tensor(-7.8497, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 206 Likelihood:  tensor(-7.8312, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 207 Likelihood:  tensor(-7.8129, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 208 Likelihood:  tensor(-7.7947, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 209 Likelihood:  tensor(-7.7767, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 210 Likelihood:  tensor(-7.7588, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 211 Likelihood:  tensor(-7.7410, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 212 Likelihood:  tensor(-7.7233, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 213 Likelihood:  tensor(-7.7057, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 214 Likelihood:  tensor(-7.6882, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 215 Likelihood:  tensor(-7.6709, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 216 Likelihood:  tensor(-7.6537, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 217 Likelihood:  tensor(-7.6366, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 218 Likelihood:  tensor(-7.6196, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 219 Likelihood:  tensor(-7.6027, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 220 Likelihood:  tensor(-7.5859, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 221 Likelihood:  tensor(-7.5693, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 222 Likelihood:  tensor(-7.5527, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 223 Likelihood:  tensor(-7.5363, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 224 Likelihood:  tensor(-7.5199, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 225 Likelihood:  tensor(-7.5037, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 226 Likelihood:  tensor(-7.4875, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 227 Likelihood:  tensor(-7.4715, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 228 Likelihood:  tensor(-7.4556, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 229 Likelihood:  tensor(-7.4397, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 230 Likelihood:  tensor(-7.4240, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 231 Likelihood:  tensor(-7.4084, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 232 Likelihood:  tensor(-7.3928, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 233 Likelihood:  tensor(-7.3774, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 234 Likelihood:  tensor(-7.3620, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 235 Likelihood:  tensor(-7.3468, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 236 Likelihood:  tensor(-7.3316, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 237 Likelihood:  tensor(-7.3165, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 238 Likelihood:  tensor(-7.3015, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 239 Likelihood:  tensor(-7.2867, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 240 Likelihood:  tensor(-7.2719, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 241 Likelihood:  tensor(-7.2571, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 242 Likelihood:  tensor(-7.2425, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 243 Likelihood:  tensor(-7.2280, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 244 Likelihood:  tensor(-7.2135, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 245 Likelihood:  tensor(-7.1991, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 246 Likelihood:  tensor(-7.1849, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 247 Likelihood:  tensor(-7.1707, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 248 Likelihood:  tensor(-7.1565, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 249 Likelihood:  tensor(-7.1425, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 250 Likelihood:  tensor(-7.1285, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 251 Likelihood:  tensor(-7.1146, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 252 Likelihood:  tensor(-7.1008, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 253 Likelihood:  tensor(-7.0871, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 254 Likelihood:  tensor(-7.0735, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 255 Likelihood:  tensor(-7.0599, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 256 Likelihood:  tensor(-7.0464, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 257 Likelihood:  tensor(-7.0330, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 258 Likelihood:  tensor(-7.0196, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 259 Likelihood:  tensor(-7.0063, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 260 Likelihood:  tensor(-6.9931, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 261 Likelihood:  tensor(-6.9800, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 262 Likelihood:  tensor(-6.9669, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 263 Likelihood:  tensor(-6.9539, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 264 Likelihood:  tensor(-6.9410, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 265 Likelihood:  tensor(-6.9282, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 266 Likelihood:  tensor(-6.9154, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 267 Likelihood:  tensor(-6.9027, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 268 Likelihood:  tensor(-6.8900, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 269 Likelihood:  tensor(-6.8774, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 270 Likelihood:  tensor(-6.8649, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 271 Likelihood:  tensor(-6.8525, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 272 Likelihood:  tensor(-6.8401, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 273 Likelihood:  tensor(-6.8277, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 274 Likelihood:  tensor(-6.8155, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 275 Likelihood:  tensor(-6.8033, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 276 Likelihood:  tensor(-6.7911, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 277 Likelihood:  tensor(-6.7791, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 278 Likelihood:  tensor(-6.7671, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 279 Likelihood:  tensor(-6.7551, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 280 Likelihood:  tensor(-6.7432, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 281 Likelihood:  tensor(-6.7314, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 282 Likelihood:  tensor(-6.7196, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 283 Likelihood:  tensor(-6.7079, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 284 Likelihood:  tensor(-6.6962, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 285 Likelihood:  tensor(-6.6846, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 286 Likelihood:  tensor(-6.6731, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 287 Likelihood:  tensor(-6.6616, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 288 Likelihood:  tensor(-6.6501, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 289 Likelihood:  tensor(-6.6388, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 290 Likelihood:  tensor(-6.6274, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 291 Likelihood:  tensor(-6.6162, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 292 Likelihood:  tensor(-6.6050, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 293 Likelihood:  tensor(-6.5938, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 294 Likelihood:  tensor(-6.5827, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 295 Likelihood:  tensor(-6.5716, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 296 Likelihood:  tensor(-6.5606, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 297 Likelihood:  tensor(-6.5497, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 298 Likelihood:  tensor(-6.5388, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 299 Likelihood:  tensor(-6.5279, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 300 Likelihood:  tensor(-6.5171, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 301 Likelihood:  tensor(-6.5064, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 302 Likelihood:  tensor(-6.4957, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 303 Likelihood:  tensor(-6.4850, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 304 Likelihood:  tensor(-6.4744, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 305 Likelihood:  tensor(-6.4639, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 306 Likelihood:  tensor(-6.4533, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 307 Likelihood:  tensor(-6.4429, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 308 Likelihood:  tensor(-6.4325, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 309 Likelihood:  tensor(-6.4221, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 310 Likelihood:  tensor(-6.4118, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 311 Likelihood:  tensor(-6.4015, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 312 Likelihood:  tensor(-6.3913, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 313 Likelihood:  tensor(-6.3811, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 314 Likelihood:  tensor(-6.3710, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 315 Likelihood:  tensor(-6.3609, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 316 Likelihood:  tensor(-6.3508, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 317 Likelihood:  tensor(-6.3408, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 318 Likelihood:  tensor(-6.3309, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 319 Likelihood:  tensor(-6.3209, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 320 Likelihood:  tensor(-6.3111, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 321 Likelihood:  tensor(-6.3012, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 322 Likelihood:  tensor(-6.2914, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 323 Likelihood:  tensor(-6.2817, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 324 Likelihood:  tensor(-6.2720, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 325 Likelihood:  tensor(-6.2623, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 326 Likelihood:  tensor(-6.2527, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 327 Likelihood:  tensor(-6.2431, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 328 Likelihood:  tensor(-6.2336, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 329 Likelihood:  tensor(-6.2241, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 330 Likelihood:  tensor(-6.2146, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 331 Likelihood:  tensor(-6.2052, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 332 Likelihood:  tensor(-6.1958, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 333 Likelihood:  tensor(-6.1864, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 334 Likelihood:  tensor(-6.1771, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 335 Likelihood:  tensor(-6.1679, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 336 Likelihood:  tensor(-6.1586, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 337 Likelihood:  tensor(-6.1494, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 338 Likelihood:  tensor(-6.1403, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 339 Likelihood:  tensor(-6.1312, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 340 Likelihood:  tensor(-6.1221, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 341 Likelihood:  tensor(-6.1130, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 342 Likelihood:  tensor(-6.1040, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 343 Likelihood:  tensor(-6.0951, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 344 Likelihood:  tensor(-6.0861, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 345 Likelihood:  tensor(-6.0772, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 346 Likelihood:  tensor(-6.0684, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 347 Likelihood:  tensor(-6.0595, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 348 Likelihood:  tensor(-6.0507, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 349 Likelihood:  tensor(-6.0420, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 350 Likelihood:  tensor(-6.0333, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 351 Likelihood:  tensor(-6.0246, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 352 Likelihood:  tensor(-6.0159, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 353 Likelihood:  tensor(-6.0073, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 354 Likelihood:  tensor(-5.9987, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 355 Likelihood:  tensor(-5.9902, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 356 Likelihood:  tensor(-5.9816, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 357 Likelihood:  tensor(-5.9732, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 358 Likelihood:  tensor(-5.9647, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 359 Likelihood:  tensor(-5.9563, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 360 Likelihood:  tensor(-5.9479, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 361 Likelihood:  tensor(-5.9395, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 362 Likelihood:  tensor(-5.9312, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 363 Likelihood:  tensor(-5.9229, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 364 Likelihood:  tensor(-5.9146, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 365 Likelihood:  tensor(-5.9064, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 366 Likelihood:  tensor(-5.8982, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 367 Likelihood:  tensor(-5.8900, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 368 Likelihood:  tensor(-5.8819, grad_fn=<NegBackward>) tensor(0.9918)\n",
            "Iteration 369 Likelihood:  tensor(-5.8738, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 370 Likelihood:  tensor(-5.8657, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 371 Likelihood:  tensor(-5.8577, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 372 Likelihood:  tensor(-5.8497, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 373 Likelihood:  tensor(-5.8417, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 374 Likelihood:  tensor(-5.8337, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 375 Likelihood:  tensor(-5.8258, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 376 Likelihood:  tensor(-5.8179, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 377 Likelihood:  tensor(-5.8100, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 378 Likelihood:  tensor(-5.8022, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 379 Likelihood:  tensor(-5.7944, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 380 Likelihood:  tensor(-5.7866, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 381 Likelihood:  tensor(-5.7788, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 382 Likelihood:  tensor(-5.7711, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 383 Likelihood:  tensor(-5.7634, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 384 Likelihood:  tensor(-5.7557, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 385 Likelihood:  tensor(-5.7481, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 386 Likelihood:  tensor(-5.7405, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 387 Likelihood:  tensor(-5.7329, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 388 Likelihood:  tensor(-5.7253, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 389 Likelihood:  tensor(-5.7178, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 390 Likelihood:  tensor(-5.7103, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 391 Likelihood:  tensor(-5.7028, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 392 Likelihood:  tensor(-5.6954, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 393 Likelihood:  tensor(-5.6879, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 394 Likelihood:  tensor(-5.6805, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 395 Likelihood:  tensor(-5.6732, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 396 Likelihood:  tensor(-5.6658, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 397 Likelihood:  tensor(-5.6585, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 398 Likelihood:  tensor(-5.6512, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 399 Likelihood:  tensor(-5.6439, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 400 Likelihood:  tensor(-5.6367, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 401 Likelihood:  tensor(-5.6294, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 402 Likelihood:  tensor(-5.6222, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 403 Likelihood:  tensor(-5.6151, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 404 Likelihood:  tensor(-5.6079, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 405 Likelihood:  tensor(-5.6008, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 406 Likelihood:  tensor(-5.5937, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 407 Likelihood:  tensor(-5.5866, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 408 Likelihood:  tensor(-5.5796, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 409 Likelihood:  tensor(-5.5726, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 410 Likelihood:  tensor(-5.5656, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 411 Likelihood:  tensor(-5.5586, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 412 Likelihood:  tensor(-5.5516, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 413 Likelihood:  tensor(-5.5447, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 414 Likelihood:  tensor(-5.5378, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 415 Likelihood:  tensor(-5.5309, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 416 Likelihood:  tensor(-5.5240, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 417 Likelihood:  tensor(-5.5172, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 418 Likelihood:  tensor(-5.5104, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 419 Likelihood:  tensor(-5.5036, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 420 Likelihood:  tensor(-5.4968, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 421 Likelihood:  tensor(-5.4901, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 422 Likelihood:  tensor(-5.4833, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 423 Likelihood:  tensor(-5.4766, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 424 Likelihood:  tensor(-5.4700, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 425 Likelihood:  tensor(-5.4633, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 426 Likelihood:  tensor(-5.4567, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 427 Likelihood:  tensor(-5.4501, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 428 Likelihood:  tensor(-5.4435, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 429 Likelihood:  tensor(-5.4369, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 430 Likelihood:  tensor(-5.4303, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 431 Likelihood:  tensor(-5.4238, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 432 Likelihood:  tensor(-5.4173, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 433 Likelihood:  tensor(-5.4108, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 434 Likelihood:  tensor(-5.4043, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 435 Likelihood:  tensor(-5.3979, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 436 Likelihood:  tensor(-5.3915, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 437 Likelihood:  tensor(-5.3851, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 438 Likelihood:  tensor(-5.3787, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 439 Likelihood:  tensor(-5.3723, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 440 Likelihood:  tensor(-5.3660, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 441 Likelihood:  tensor(-5.3597, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 442 Likelihood:  tensor(-5.3534, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 443 Likelihood:  tensor(-5.3471, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 444 Likelihood:  tensor(-5.3408, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 445 Likelihood:  tensor(-5.3346, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 446 Likelihood:  tensor(-5.3283, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 447 Likelihood:  tensor(-5.3221, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 448 Likelihood:  tensor(-5.3160, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 449 Likelihood:  tensor(-5.3098, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 450 Likelihood:  tensor(-5.3036, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 451 Likelihood:  tensor(-5.2975, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 452 Likelihood:  tensor(-5.2914, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 453 Likelihood:  tensor(-5.2853, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 454 Likelihood:  tensor(-5.2793, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 455 Likelihood:  tensor(-5.2732, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 456 Likelihood:  tensor(-5.2672, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 457 Likelihood:  tensor(-5.2612, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 458 Likelihood:  tensor(-5.2552, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 459 Likelihood:  tensor(-5.2492, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 460 Likelihood:  tensor(-5.2432, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 461 Likelihood:  tensor(-5.2373, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 462 Likelihood:  tensor(-5.2314, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 463 Likelihood:  tensor(-5.2255, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 464 Likelihood:  tensor(-5.2196, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 465 Likelihood:  tensor(-5.2137, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 466 Likelihood:  tensor(-5.2079, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 467 Likelihood:  tensor(-5.2020, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 468 Likelihood:  tensor(-5.1962, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 469 Likelihood:  tensor(-5.1904, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 470 Likelihood:  tensor(-5.1846, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 471 Likelihood:  tensor(-5.1789, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 472 Likelihood:  tensor(-5.1731, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 473 Likelihood:  tensor(-5.1674, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 474 Likelihood:  tensor(-5.1617, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 475 Likelihood:  tensor(-5.1560, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 476 Likelihood:  tensor(-5.1503, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 477 Likelihood:  tensor(-5.1447, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 478 Likelihood:  tensor(-5.1390, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 479 Likelihood:  tensor(-5.1334, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 480 Likelihood:  tensor(-5.1278, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 481 Likelihood:  tensor(-5.1222, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 482 Likelihood:  tensor(-5.1166, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 483 Likelihood:  tensor(-5.1111, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 484 Likelihood:  tensor(-5.1055, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 485 Likelihood:  tensor(-5.1000, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 486 Likelihood:  tensor(-5.0945, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 487 Likelihood:  tensor(-5.0890, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 488 Likelihood:  tensor(-5.0835, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 489 Likelihood:  tensor(-5.0780, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 490 Likelihood:  tensor(-5.0726, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 491 Likelihood:  tensor(-5.0671, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 492 Likelihood:  tensor(-5.0617, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 493 Likelihood:  tensor(-5.0563, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 494 Likelihood:  tensor(-5.0509, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 495 Likelihood:  tensor(-5.0456, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 496 Likelihood:  tensor(-5.0402, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 497 Likelihood:  tensor(-5.0349, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 498 Likelihood:  tensor(-5.0296, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 499 Likelihood:  tensor(-5.0242, grad_fn=<NegBackward>) tensor(0.9919)\n",
            "Iteration 500 Likelihood:  tensor(-5.0189, grad_fn=<NegBackward>) tensor(0.9919)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUmlAf07jqpe",
        "outputId": "e2dec0a3-c2dd-4f88-ed4f-985ecb20949b"
      },
      "source": [
        "torch.exp(log_pi_d0)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9919)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twaV0WiNkUKm",
        "outputId": "b7ed613c-279a-40da-8fb3-c4f64d112505"
      },
      "source": [
        "torch.exp(log_pi_c)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2315, 0.4829, 0.2775])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFpDgKm_kkZI",
        "outputId": "3e4aadd0-8a43-46bc-be03-fcf9536a5f17"
      },
      "source": [
        "torch.exp(log_pi_cc)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0024, 0.0057],\n",
              "        [0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3jIdug8VcfW",
        "outputId": "ddef94be-8b2a-4b67-ff10-5863816d84f2"
      },
      "source": [
        "emu_c"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.8578, 2.7774],\n",
              "        [3.3223, 4.5454],\n",
              "        [7.0221, 8.3452]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWmH3cD8kxHy",
        "outputId": "680240c7-9e0e-4f5c-9750-7a4bb125be4e"
      },
      "source": [
        "smu_c"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4000, 0.5008, 0.6694], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GSMFDxJ6NRF",
        "outputId": "25893bef-58ad-48b9-d2cc-d81ae8441ef7"
      },
      "source": [
        "bic"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(663.9720, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "iWLFYd0SLxAM",
        "outputId": "563f87a6-c2fb-4231-ae2b-fd23b3061438"
      },
      "source": [
        "plt.plot(llv[1:])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f095e252d50>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHTHLSqllKTD"
      },
      "source": [
        "## torch.optim version (no loop)\n",
        "\n",
        "X = torch.tensor(xx[:,:2])\n",
        "S = torch.tensor(xx[:,2])\n",
        "\n",
        "#parameters = [emu_c, eco_c, smu_c, sco_c]\n",
        "#parameters = [emu_cc, eco_cc, smu_cc, sco_cc]\n",
        "parameters = [emu_c, eco_c, smu_c, sco_c, emu_cc, eco_cc, smu_cc, sco_cc]\n",
        "opt = optim.SGD(parameters, lr=0.01)\n",
        "#opt = optim.Adam(parameters)\n",
        "\n",
        "tot = 1e-4\n",
        "llv = [0.0]\n",
        "\n",
        "log_pi_d0 = torch.log(pi_d0)\n",
        "log_pi_d1 = torch.log(1-pi_d0)\n",
        "log_pi_c = torch.log(pi_c)\n",
        "log_pi_cc = torch.log(pi_cc)\n",
        "\n",
        "#iter = 0\n",
        "#n_epochs = 500\n",
        "#while iter < n_epochs:\n",
        "\n",
        "log_post_top0 = torch.zeros(n_clusters, n_obs)\n",
        "log_post_top1 = torch.zeros(n_clusters, n_clusters, n_obs)\n",
        "\n",
        "for j in range(n_clusters):  \n",
        "  el0 = D.MultivariateNormal(emu_c[j], eco_c[j]).log_prob(X.float())\n",
        "  sl0 = D.Normal(smu_c[j], sco_c[j]).log_prob(S.float())\n",
        "  log_post_top0[j] = log_pi_d0 + log_pi_c[j] + el0 + sl0\n",
        "\n",
        "  for k in range(n_clusters):\n",
        "    el1 = D.MultivariateNormal(emu_cc[j,k]/2, eco_cc[j,k]/2).log_prob(X.float())\n",
        "    sl1 = D.Normal(smu_cc[j,k], sco_cc[j,k]).log_prob(S.float())\n",
        "            \n",
        "    if torch.isnan(pi_cc[j,k]): #lower triangular nan\n",
        "      log_post_top1[j,k] = float(\"-Inf\")\n",
        "    else:\n",
        "      log_post_top1[j,k] = log_pi_d1 + log_pi_cc[j,k] + el1 + sl1\n",
        "\n",
        "log_post_bot0 = torch.logsumexp(log_post_top0, 0) #n\n",
        "  \n",
        "log_post_top1 = log_post_top1.reshape(n_clusters * n_clusters, n_obs) #reshape\n",
        "log_post_bot1 = torch.logsumexp(log_post_top1, 0) #n\n",
        "\n",
        "log_post_tot = torch.logsumexp(torch.vstack((log_post_top0, log_post_top1)),0)\n",
        "loss = -torch.mean(log_post_tot)\n",
        "\n",
        "#print(emu_c)\n",
        "opt.zero_grad()\n",
        "loss.backward()\n",
        "opt.step()\n",
        "#print(emu_cc)\n",
        "\n",
        "with torch.no_grad():\n",
        "  parameters[0].clamp_(tot)\n",
        "  ##parameters[1].clamp_(tot)\n",
        "  parameters[2].clamp_(tot)\n",
        "  parameters[3].clamp_(tot)\n",
        "  parameters[4].clamp_(tot)\n",
        "  ##parameters[5].clamp_(tot)\n",
        "  parameters[6].clamp_(tot)\n",
        "  parameters[7].clamp_(tot)\n",
        "\n",
        "  log_post_d0 = log_post_bot0 - log_post_tot\n",
        "  log_post_d1 = log_post_bot1 - log_post_tot\n",
        "\n",
        "  log_post_z = (log_post_top0 - log_post_bot0).T #nxc (rjk)\n",
        "  log_post_g = (log_post_top1 - log_post_bot1).T #nxc (rijk)\n",
        "\n",
        "  log_post_dz = log_post_d0[:,None] + log_post_z\n",
        "  log_post_dg = log_post_d1[:,None] + log_post_g\n",
        "\n",
        "  #r_ij = torch.exp(log_post_dz)\n",
        "  #n_c = torch.sum(r_ij, dim=0)\n",
        "  #pi_c = n_c / n_obs  # c values\n",
        "  log_n_c = torch.logsumexp(log_post_dz, 0)\n",
        "  log_pi_c = log_n_c - torch.log(torch.tensor(n_obs))\n",
        "\n",
        "  #r_ijk = torch.exp(log_post_dg).reshape(n_obs, n_clusters, n_clusters)\n",
        "  #n_cc = torch.sum(r_ijk, dim=0) # (cxc)\n",
        "  #pi_cc = n_cc / n_obs  # cxc matrix\n",
        "\n",
        "  log_n_cc = torch.logsumexp(log_post_dg, 0).reshape(n_clusters, n_clusters)\n",
        "  log_pi_cc = log_n_cc - torch.log(torch.tensor(n_obs))  # cxc matrix\n",
        "\n",
        "  #pi_d0 = torch.sum(torch.exp(log_post_d0)) / n_obs # one value\n",
        "  log_pi_d0 = torch.logsumexp(log_post_d0, 0) - torch.log(torch.tensor(n_obs))\n",
        "\n",
        "print('Iteration', iter + 1, 'Likelihood: ', -loss, torch.exp(log_pi_d0))\n",
        "\n",
        "#if abs(llv[-1] + loss) < tot:\n",
        "#  break\n",
        "      \n",
        "llv.append(-loss)\n",
        "iter += 1\n",
        "\n",
        "aic, bic = _ics(-loss, n_obs, n_features, n_clusters)\n",
        "\n",
        "#print(epoch, pi_d0, loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9BY30lrlKdK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjsoVpn6lKnX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSeLT_pnlKwe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxABrzMAlLS-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fruC6plFCfD2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}