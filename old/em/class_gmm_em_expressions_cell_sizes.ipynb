{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "class_gmm_em_expressions_cell_sizes",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO14atKJY78hB0z4kj1Ywbm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camlab-bioml/2021_IMC_Jett/blob/main/class_gmm_em_expressions_cell_sizes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB0jYWaLT8fU"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.distributions as D\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.datasets as datasets"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQvSYFm5LX8I"
      },
      "source": [
        "## class version of using analytical and torch.optim updates\n",
        "\n",
        "class GMM(object):\n",
        "\n",
        "  def __init__(self, X, S, emu_c, smu_c, n_clusters=3, grad=False):\n",
        "    self.X = torch.tensor(X)\n",
        "    self.S = torch.tensor(S)\n",
        "    self.emu_c = emu_c\n",
        "    self.smu_c = smu_c\n",
        "\n",
        "    # dimension\n",
        "    self.n_obs, self.n_features = X.shape\n",
        "    self.n_clusters = n_clusters\n",
        "\n",
        "  #def initialization(self, grad=False):\n",
        "\n",
        "    #torch.manual_seed(42)\n",
        "\n",
        "    self.pi_d0 = torch.tensor(0.9)\n",
        "      \n",
        "    self.n_c = torch.tensor(self.n_obs / self.n_clusters).repeat(self.n_clusters)\n",
        "    self.pi_c = self.n_c / self.n_obs\n",
        "    #self.pi_c = torch.zeros(self.n_clusters).fill_(1. / (self.n_clusters))\n",
        "\n",
        "    self.n_cc = torch.triu(torch.ones(self.n_clusters, self.n_clusters)) * torch.tensor(self.n_obs / self.n_clusters**2)\n",
        "    self.n_cc[self.n_cc == 0] = float('NaN')\n",
        "    self.pi_cc = self.n_cc / self.n_obs\n",
        "\n",
        "    #self.pi_cc = torch.triu(torch.ones(self.n_clusters, self.n_clusters))\n",
        "    #self.pi_cc = self.pi_cc / torch.sum(self.pi_cc)\n",
        "    #self.pi_cc[self.pi_cc == 0] = float('NaN')\n",
        "\n",
        "    self.log_post_d0 = torch.zeros(self.n_obs)\n",
        "    self.log_post_d1 = torch.zeros(self.n_obs)\n",
        "    self.log_post_z = torch.zeros(self.n_obs, self.n_clusters)\n",
        "    self.log_post_g = torch.zeros(self.n_obs, self.n_clusters * self.n_clusters)\n",
        "    self.log_post_dz = torch.zeros(self.n_obs, self.n_clusters)\n",
        "    self.log_post_dg = torch.zeros(self.n_obs, self.n_clusters * self.n_clusters)\n",
        "\n",
        "    self.eco_c = 0.1 * torch.eye(self.n_features).tile(self.n_clusters, 1, 1)\n",
        "    self.sco_c = 0.1 * torch.ones(self.n_clusters, dtype=torch.float)\n",
        "\n",
        "    self.smu_cc = torch.zeros(self.n_clusters, self.n_clusters, dtype=torch.float)\n",
        "    self.sco_cc = torch.zeros(self.n_clusters, self.n_clusters, dtype=torch.float)\n",
        "\n",
        "    self.emu_cc = torch.zeros(self.n_clusters, self.n_clusters, self.n_features, dtype=torch.float)\n",
        "    self.eco_cc = torch.zeros(self.n_clusters, self.n_clusters, self.n_features, self.n_features, dtype=torch.float)\n",
        "\n",
        "    for j in range(self.n_clusters):\n",
        "      for k in range(self.n_clusters):\n",
        "        self.smu_cc[j,k] = self.smu_c[j] + self.smu_c[k]\n",
        "        self.sco_cc[j,k] = self.sco_c[j] + self.sco_c[k]\n",
        "\n",
        "        self.emu_cc[j,k] = (self.emu_c[j] + self.emu_c[k])/2\n",
        "        self.eco_cc[j,k] = (self.eco_c[j] + self.eco_c[k])/2\n",
        "\n",
        "    if grad == True:\n",
        "\n",
        "      device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "      self.smu_c = torch.tensor(self.smu_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "      self.sco_c = torch.tensor(self.sco_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "      \n",
        "      self.emu_c = torch.tensor(self.emu_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "      self.eco_c = torch.tensor(self.eco_c, requires_grad=True, dtype=torch.float, device=device)\n",
        "      \n",
        "      ####\n",
        "      \n",
        "      self.smu_cc = torch.tensor(self.smu_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "      self.sco_cc = torch.tensor(self.sco_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "      \n",
        "      self.emu_cc = torch.tensor(self.emu_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "      self.eco_cc = torch.tensor(self.eco_cc, requires_grad=True, dtype=torch.float, device=device)\n",
        "      \n",
        "      ####\n",
        "\n",
        "  def _train(self, grad=False, n_epochs = 1000, tot = 1e-4):\n",
        "\n",
        "    if grad:\n",
        "      #parameters = [self.emu_c, self.eco_c, self.smu_c, self.sco_c]\n",
        "      parameters = [self.emu_c, self.eco_c, self.smu_c, self.sco_c, self.emu_cc, self.eco_cc, self.smu_cc, self.sco_cc]\n",
        "      #opt = optim.SGD(parameters, lr = 0.01)\n",
        "      opt = optim.Adam(parameters, lr = 0.01)\n",
        "\n",
        "    iter = 0\n",
        "    llv = [0.0]\n",
        "    while iter < n_epochs:\n",
        "      \n",
        "      if grad:\n",
        "        loss = self._e_step(grad=True)\n",
        "        self._m_stepO(parameters, opt, loss, tot)\n",
        "      else:\n",
        "        loss = self._e_step(grad=False)\n",
        "        self._m_step()\n",
        "    \n",
        "      print('Iteration', iter + 1, 'Likelihood: ', -loss)\n",
        "\n",
        "      if abs(llv[-1] + loss) < tot:\n",
        "        break\n",
        "      \n",
        "      llv.append(-loss)\n",
        "      iter += 1\n",
        "\n",
        "    aic, bic = self._ics(-loss)\n",
        "    return llv[1:], aic, bic\n",
        "\n",
        "  def _trainT(self, n_epochs = 1000, lr = 0.01, tot = 1e-4):\n",
        "    \n",
        "    #parameters = [self.emu_c, self.eco_c, self.smu_c, self.sco_c]\n",
        "    parameters = [self.emu_c, self.eco_c, self.smu_c, self.sco_c, self.emu_cc, self.eco_cc, self.smu_cc, self.sco_cc]\n",
        "    opt = optim.SGD(parameters, lr=lr)\n",
        "    #opt = optim.Adam(parameters)\n",
        "    \n",
        "    iter = 0\n",
        "    llv = [0.0]\n",
        "    while iter < n_epochs:\n",
        "      loss = self._e_step()\n",
        "      self._m_stepO(parameters, opt, loss, tot)\n",
        "\n",
        "      print('Iteration', iter + 1, 'Likelihood: ', -loss)\n",
        "\n",
        "      if abs(llv[-1] + loss) < tot:\n",
        "        break\n",
        "      \n",
        "      llv.append(-loss)\n",
        "      iter += 1\n",
        "\n",
        "    aic, bic = self._ics(-loss)\n",
        "\n",
        "    return llv[1:], aic, bic\n",
        "\n",
        "  def _trainA(self, itermax=100, tot=1e-4):\n",
        "    \n",
        "    iter = 0\n",
        "    llv = [0.0]\n",
        "    while iter < itermax:\n",
        "      loss = self._e_step()\n",
        "      self._m_step()\n",
        "      #print(self.emu_c)\n",
        "\n",
        "      print('Iteration', iter + 1, 'Likelihood: ', -loss)\n",
        "\n",
        "      if abs(llv[-1] + loss) < tot:\n",
        "        break\n",
        "      \n",
        "      llv.append(-loss)\n",
        "      iter += 1\n",
        "\n",
        "    aic, bic = self._ics(-loss) #, X.shape[0], X.shape[1], len(pi_c))\n",
        "    \n",
        "    return llv[1:], aic, bic\n",
        "\n",
        "  def _ics(self, logL): #, n, p, c\n",
        "    params = ( (((self.n_features * self.n_features) - self.n_features)/2 + 2 * self.n_features + 3) * (((self.n_clusters * self.n_clusters) - self.n_clusters)/2 + 2 * self.n_clusters) ) - 1\n",
        "    return 2 * (params - logL), -2 * logL + params * np.log(self.n_obs)\n",
        "\n",
        "  def _e_step(self, grad=True):\n",
        "\n",
        "    log_pi_d0 = torch.log(self.pi_d0)\n",
        "    log_pi_d1 = torch.log(1 - self.pi_d0)\n",
        "\n",
        "    log_pi_c = torch.log(self.pi_c)\n",
        "    log_pi_cc = torch.log(self.pi_cc)\n",
        "\n",
        "    ### E-step:\n",
        "    log_post_top0 = torch.zeros(self.n_clusters, self.n_obs)\n",
        "    log_post_top1 = torch.zeros(self.n_clusters, self.n_clusters, self.n_obs)\n",
        "\n",
        "    for j in range(self.n_clusters):\n",
        "  \n",
        "      el0 = torch.distributions.MultivariateNormal(self.emu_c[j].float(), self.eco_c[j].float()).log_prob(self.X.float())\n",
        "      sl0 = torch.distributions.Normal(self.smu_c[j].float(), self.sco_c[j].float()).log_prob(self.S.float())\n",
        "      log_post_top0[j] = log_pi_d0 + log_pi_c[j] + el0 + sl0\n",
        "\n",
        "      for k in range(self.n_clusters):\n",
        "        if grad:\n",
        "          el1 = torch.distributions.MultivariateNormal(self.emu_cc[j,k].float()/2, self.eco_cc[j,k].float()/2).log_prob(self.X.float())\n",
        "          sl1 = torch.distributions.Normal(self.smu_cc[j,k].float(), self.sco_cc[j,k].float()).log_prob(self.S.float())\n",
        "        else:\n",
        "          el1 = torch.distributions.MultivariateNormal((self.emu_c[j] + self.emu_c[k]).float()/2, (self.eco_c[j] + self.eco_c[k]).float()/2).log_prob(self.X.float())\n",
        "          #https://stats.stackexchange.com/questions/99363/mean-of-covariance-matrices\n",
        "          #https://stats.stackexchange.com/questions/214174/calculating-the-covariance-matrix-for-the-mean-of-variables\n",
        "          sl1 = torch.distributions.Normal((self.smu_c[j] + self.smu_c[k]).float(), (self.sco_c[j] + self.sco_c[k]).float()).log_prob(self.S.float())\n",
        "        \n",
        "        if torch.isnan(self.pi_cc[j,k]): #lower triangular nan\n",
        "          log_post_top1[j,k] = float(\"-Inf\")\n",
        "        else:\n",
        "          log_post_top1[j,k] = log_pi_d1 + log_pi_cc[j,k] + el1 + sl1\n",
        "\n",
        "    log_post_bot0 = torch.logsumexp(log_post_top0, 0) #n\n",
        "    self.log_post_z = (log_post_top0 - log_post_bot0).T #nxc (rjk)\n",
        "    self.log_post_z[torch.isnan(self.log_post_z)] = 0\n",
        "\n",
        "    log_post_top1 = log_post_top1.reshape(self.n_clusters * self.n_clusters, self.n_obs) #reshape\n",
        "    log_post_bot1 = torch.logsumexp(log_post_top1, 0) #n\n",
        "    self.log_post_g = (log_post_top1 - log_post_bot1).T #nxc (rijk)\n",
        "    self.log_post_g[torch.isnan(self.log_post_g)] = 0\n",
        "\n",
        "    bot = torch.exp(log_post_bot0) + torch.exp(log_post_bot1)\n",
        "\n",
        "    bot[bot==0.0] = 1e-6\n",
        "    bot = torch.log(bot)\n",
        "\n",
        "    loss = -torch.mean(bot)\n",
        "\n",
        "    self.log_post_d0 = log_post_bot0 - bot\n",
        "    self.log_post_d1 = log_post_bot1 - bot\n",
        "\n",
        "    self.log_post_dz = self.log_post_d0[:,None] + self.log_post_z\n",
        "    self.log_post_dg = self.log_post_d1[:,None] + self.log_post_g\n",
        "\n",
        "    return loss #, log_post_d0, log_post_d1, log_post_z, log_post_g, log_post_dz, log_post_dg\n",
        "\n",
        "  def _m_stepO(self, params, opt, loss, tot):\n",
        "\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "      \n",
        "    with torch.no_grad():\n",
        "      params[0].clamp_(0)\n",
        "      params[1].clamp_(tot)\n",
        "      params[2].clamp_(0)\n",
        "      params[3].clamp_(tot)\n",
        "      params[4].clamp_(0)\n",
        "      params[5].clamp_(tot)\n",
        "      params[6].clamp_(tot)\n",
        "      params[7].clamp_(0)\n",
        "\n",
        "      r_ij = torch.exp(self.log_post_dz)\n",
        "      self.n_c = torch.sum(r_ij, dim=0)\n",
        "      self.pi_c = self.n_c / self.n_obs  # c values\n",
        "    \n",
        "      #assert(torch.isnan(pi_c).sum() == 0)\n",
        "      r_ijk = torch.exp(self.log_post_dg).reshape(self.n_obs, self.n_clusters, self.n_clusters)\n",
        "      self.n_cc = torch.sum(r_ijk, dim=0) # (cxc)\n",
        "      self.pi_cc = self.n_cc / self.n_obs  # cxc matrix\n",
        "\n",
        "      self.pi_d0 = torch.sum(torch.exp(self.log_post_d0)) / self.n_obs\n",
        "\n",
        "  def _m_step(self):\n",
        "\n",
        "    self.pi_d0 = torch.sum(torch.exp(self.log_post_d0)) / self.n_obs # one value\n",
        "\n",
        "    r_ij = torch.exp(self.log_post_dz)\n",
        "    self._estimate_mean_cov_t1v2(r_ij)\n",
        "    #n_c, smu_c, sco_c, emu_c, eco_c = _estimate_mean_cov_t1v2(X, S, r_ij)\n",
        "    self.pi_c = self.n_c / self.n_obs # c values\n",
        "\n",
        "    indx = []\n",
        "    for j in range(self.log_post_dg.shape[1]):\n",
        "      if torch.sum(torch.isinf(self.log_post_dg[:,j])) == self.log_post_dg.shape[0]:\n",
        "        indx.append(j)\n",
        "    self.log_post_dg[:,indx] = float('NaN')\n",
        "\n",
        "    r_ijk = torch.exp(self.log_post_dg).reshape(self.n_obs, self.n_clusters, self.n_clusters)\n",
        "    self._estimate_mean_cov_t2v2(r_ijk)\n",
        "    #n_cc, smu_cc, sco_cc, emu_cc, eco_cc = _estimate_mean_cov_t2v2(X, S, r_ijk)\n",
        "    self.pi_cc = self.n_cc / self.n_obs  # cxc matrix  \n",
        "\n",
        "    #return pi_d0, n_c, pi_c, emu_c, eco_c, smu_c, sco_c, n_cc, pi_cc, emu_cc, eco_cc, smu_cc, sco_cc\n",
        "\n",
        "  def _estimate_mean_cov_t1v2(self, r_ij, reg=1e-6):\n",
        "\n",
        "    self.n_c = torch.sum(r_ij, dim=0) + reg # (c)\n",
        "    #print(self.n_c.sum())\n",
        "\n",
        "    for j in range(self.n_clusters):\n",
        "      e_n = torch.round(self.n_c[j])\n",
        "      idx = r_ij[:,j].argsort()[-e_n.int():]\n",
        "      self.smu_c[j] = torch.mean(self.S[idx], 0)\n",
        "      self.emu_c[j] = torch.mean(self.X[idx], 0)\n",
        "      if e_n > 1:\n",
        "        self.sco_c[j] = torch.std(S[idx]) + reg\n",
        "        self.eco_c[j] = torch.tensor(np.cov(self.X[idx].T, ddof=0)) + reg * torch.eye(self.n_features)\n",
        "      else:\n",
        "        self.eco_c[j] = reg * torch.eye(self.n_features)\n",
        "        self.sco_c[j] = reg\n",
        "    #return n_c, smut, scot, emut, ecot\n",
        "  \n",
        "  def _estimate_mean_cov_t2v2(self, r_ijk, reg=1e-6):\n",
        "  \n",
        "    self.n_cc = torch.sum(r_ijk, dim=0) + reg # (cxc)\n",
        "\n",
        "    for j in range(self.n_clusters):\n",
        "      for k in range(self.n_clusters):\n",
        "        if not torch.isnan(self.n_cc[j,k]):\n",
        "          e_n = torch.round(self.n_cc[j,k])\n",
        "          idx = r_ijk[:,j,k].argsort()[-e_n.int():]\n",
        "          self.smu_cc[j,k] = torch.mean(self.S[idx], 0)\n",
        "          self.emu_cc[j,k] = torch.mean(self.X[idx], 0)\n",
        "          if e_n > 1:\n",
        "            self.sco_cc[j,k] = torch.std(self.S[idx]) + reg\n",
        "            self.eco_cc[j,k] = torch.tensor(np.cov(self.X[idx].T, ddof=0)) + reg * torch.eye(self.n_features)\n",
        "          else:\n",
        "            self.sco_cc[j,k] = reg\n",
        "            self.eco_cc[j,k] = reg * torch.eye(self.n_features)\n",
        "    #return n_cc, smut, scot, emut, ecot "
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3BKxX6neYTG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjoZ1PovUVE6",
        "outputId": "1ba41a4e-313c-4b60-e2cf-212a418d4410"
      },
      "source": [
        "## create data\n",
        "\n",
        "n_clusters = 3\n",
        "n_features = 2\n",
        "\n",
        "## ground true expressions ##\n",
        "true_expression_means = torch.tensor([\n",
        "    [1, 2],\n",
        "    [4, 3],\n",
        "    [7, 9]\n",
        "])\n",
        "\n",
        "true_expression_covs = torch.tensor([\n",
        "    [[.1, 0], [0, .1]],\n",
        "    [[.1, 0], [0, .1]],\n",
        "    [[.1, 0], [0, .1]]\n",
        "])\n",
        "\n",
        "true_size_means = torch.tensor([.4, .5, .6])\n",
        "\n",
        "print(true_size_means)\n",
        "\n",
        "true_size_stds = torch.tensor([.1, .05, .01])\n",
        "true_size_stds"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.4000, 0.5000, 0.6000])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1000, 0.0500, 0.0100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4mE_xwUYirp"
      },
      "source": [
        "## other ground true for generating data ##\n",
        "d_ws = torch.tensor([.95, .05])\n",
        "z_ws = torch.tensor([1 / 4, 1 / 2, 1 / 4])\n",
        "g_ws = torch.tensor([0.0667, 0.1333, 0.2000, 0.1000, 0.2667, 0.2333])\n",
        "\n",
        "N = 10000\n",
        "gs = np.sum(np.random.choice(len(d_ws), size = N, p = d_ws))\n",
        "zs = N - gs"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzCIiWHYYkuh"
      },
      "source": [
        "## simulate data\n",
        "x = np.zeros((zs, n_features+4))\n",
        "for i in range(zs):\n",
        "  z = np.random.choice(n_clusters, size = 1, p = z_ws)[0]\n",
        "  x[i] = np.append(np.random.multivariate_normal(true_expression_means[z], true_expression_covs[z]), [np.random.normal(true_size_means[z], true_size_stds[z]), 0, z, z+6])\n",
        "  \n",
        "xxx = np.zeros((gs, n_features+4))\n",
        "for i in range(gs):\n",
        "\n",
        "  g = np.random.choice(6, size = 1, p = g_ws)[0]\n",
        "    \n",
        "  if g == 0:\n",
        "    idx = [0,0]\n",
        "  elif g == 1:\n",
        "    idx = [0,1]\n",
        "  elif g == 2:\n",
        "    idx = [0,2]\n",
        "  elif g == 3:\n",
        "    idx = [1,1]\n",
        "  elif g == 4:\n",
        "    idx = [1,2]\n",
        "  else:\n",
        "    idx = [2,2]\n",
        "  \n",
        "  xxx[i] = np.append(np.random.multivariate_normal( (true_expression_means[idx[0]] + true_expression_means[idx[1]])/2, (true_expression_covs[idx[0]] + true_expression_covs[idx[1]])/2 ),\n",
        "                     [np.random.normal( (true_size_means[idx[0]] + true_size_means[idx[1]]), (true_size_stds[idx[0]] + true_size_stds[idx[1]]) ), 1, g, g])\n",
        "  \n",
        "xx = np.append(x, xxx).reshape(N,6)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io6IlsEfLQuI"
      },
      "source": [
        "X = torch.tensor(xx[:,:2])\n",
        "S = torch.tensor(xx[:,2])\n",
        "\n",
        "emu_c = torch.tensor([\n",
        "  [3, 5], # 1 2\n",
        "  [4, 6],\n",
        "  [6, 8], # 4 3\n",
        "  [8, 10]\n",
        "], dtype=torch.float) #, requires_grad=True,  device=device)\n",
        "\n",
        "smu_c = torch.tensor([.2, .4, .6, .8], dtype=torch.float) #, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "gmm = GMM(X, S, emu_c, smu_c, n_clusters=4, grad=1)\n",
        "lls, aic, bic = gmm._train(grad=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLCqbC_N5zkP",
        "outputId": "7f008711-6e25-4562-b4c3-ed49dba94051"
      },
      "source": [
        "print(aic, bic) #c=2"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(80.5559, grad_fn=<MulBackward0>) tensor(361.7592, grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40wVTFw1wBBl",
        "outputId": "92170ee3-a607-4ff7-d36e-a8a07101b19b"
      },
      "source": [
        "print(aic, bic) #c=3"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(144.4364, grad_fn=<MulBackward0>) tensor(656.3705, grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYTUkGee6wcu",
        "outputId": "43b30ac0-2ac9-4f83-e5d2-73b4d09845af"
      },
      "source": [
        "print(aic, bic) #c=4"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(223.2050, grad_fn=<MulBackward0>) tensor(1023.5528, grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "6tjvU7tchQg7",
        "outputId": "3f39f069-7a6f-4c50-e99d-e4f965639f66"
      },
      "source": [
        "plt.plot(lls)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe9292341d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqFYPGEchRbw",
        "outputId": "de50b2a5-8e66-4a24-9d0d-1a686b425eb1"
      },
      "source": [
        "gmm.pi_d0"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2504)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7U1MYY9iXXD",
        "outputId": "3fef6c63-5a0c-43b5-f3d7-f458bf003b40"
      },
      "source": [
        "gmm.pi_c"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000e+00, 2.2317e-12, 2.3780e-01, 1.2600e-02])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paLOHfKriaYi",
        "outputId": "e2bc94ef-05fb-4245-fa6b-e34fc45d349c"
      },
      "source": [
        "gmm.pi_cc"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2311, 0.0034, 0.0000, 0.4785],\n",
              "        [0.0000, 0.0129, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0237]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brEFDWTuhWhl",
        "outputId": "5f9cc591-d33b-4e65-96b9-e9a17eba147b"
      },
      "source": [
        "gmm.emu_c"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.1342, 4.8726],\n",
              "        [4.1238, 5.8981],\n",
              "        [7.0071, 8.9882],\n",
              "        [6.9992, 9.0240]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3xMP7RwhWrs",
        "outputId": "94daa687-f7fe-4d65-c17e-ee0b93a16f0b"
      },
      "source": [
        "gmm.emu_cc"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.9936,  3.9934],\n",
              "         [ 2.0320,  3.8564],\n",
              "         [ 4.5891,  6.3981],\n",
              "         [ 8.0117,  5.9767]],\n",
              "\n",
              "        [[ 3.5000,  5.5000],\n",
              "         [ 6.5175,  5.4534],\n",
              "         [ 5.0795,  6.9174],\n",
              "         [ 6.1003,  7.9040]],\n",
              "\n",
              "        [[ 4.5000,  6.5000],\n",
              "         [ 5.0000,  7.0000],\n",
              "         [ 6.1003,  7.9040],\n",
              "         [ 7.0680,  8.9579]],\n",
              "\n",
              "        [[ 5.5000,  7.5000],\n",
              "         [ 6.0000,  8.0000],\n",
              "         [ 7.0000,  9.0000],\n",
              "         [ 9.6386, 11.5447]]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d11UZwfGhW04",
        "outputId": "0753516e-d50c-4bf0-db7f-a3648c7ab7bf"
      },
      "source": [
        "gmm.smu_c"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3162, 0.5803, 0.6001, 1.1995], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2OZsffJhRkB",
        "outputId": "2611154a-608f-4e0b-98fa-76642345e803"
      },
      "source": [
        "gmm.smu_cc"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4010, 0.8655, 0.7208, 0.4986],\n",
              "        [0.6000, 0.9517, 0.9207, 1.1027],\n",
              "        [0.8000, 1.0000, 1.1027, 1.3241],\n",
              "        [1.0000, 1.2000, 1.4000, 1.0478]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    }
  ]
}